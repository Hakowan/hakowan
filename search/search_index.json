{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hakowan: A 3D Data Visualization Grammar","text":"<p>Hakowan is a 3D data visualization grammar based on the concept of The Grammar of Graphics. It is designed for creating compelling SIGGRAPH-quality 3D data visualizations with minimal setup. It provides a concise, high-level declarative API in python and is powered by project Lagrange and Mitsuba for data processing and rendering.</p>"},{"location":"#installation","title":"Installation","text":"<p>Hakowan can be installed via <code>pip</code> from PyPI:</p> <pre><code>pip install hakowan\n</code></pre> <p>Note that hakowan requires python 3.11 and above.</p>"},{"location":"#quick-start","title":"Quick start","text":"<p>Let <code>shape.obj</code> be a mesh that you would like to visualize:</p> <pre><code>import hakowan as hkw\n\nbase = hkw.layer(\"shape.obj\")\nhkw.render(base, filename=\"output.exr\")\n</code></pre> <p>The above code creates a single visualization layer using <code>shape.obj</code> as the data. This layer is then rendered into an image named <code>output.exr</code>.</p> <p>Hakowan's grammar decompose a 3D visualization into layers, where each layer provides a specification of one or more of the following items:</p> <ul> <li> <p>Data: consists of the geometry as well as attributes associated with the geometry.</p> </li> <li> <p>Mark: determines the geometry type (e.g. point, curve or surface).</p> </li> <li> <p>Channel: define the mapping from data attributes to the available visual channels.</p> </li> <li> <p>Transform: is the data transformation that should be carried out before visualization.</p> </li> </ul>"},{"location":"#citation","title":"Citation","text":"<pre><code>@software{hakowan,\n    title = {Hakowan: A 3D Data Visualization Grammar},\n    version = {0.1.0},\n    year = 2023,\n}\n</code></pre>"},{"location":"gallery/","title":"Gallery","text":""},{"location":"api/attribute/","title":"Attribute","text":"<p>This page contains <code>hakowan.grammar.scale.attribute.Attribute</code> class specification.</p>"},{"location":"api/attribute/#hakowan.grammar.scale.attribute.AttributeLike","title":"<code>AttributeLike = str | Attribute</code>  <code>module-attribute</code>","text":"<p>Type alias for a attribute-like objects.</p> <ul> <li>A string object will be converted to an attribute with the name set to the string.</li> <li>An attribute object will be unchanged.</li> </ul>"},{"location":"api/attribute/#hakowan.grammar.scale.attribute.Attribute","title":"<code>Attribute</code>  <code>dataclass</code>","text":"<p>An attribute represents a scalar or vector field that is defined on the 3D geometry.</p> <p>An attribute is the 3D equivalent of a column in a table. Each attribute is uniquely identified by the attribute name, which must exists in the data frame, and optionally associated with a scale.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the attribute as it is defined in the data frame.</p> <code>scale</code> <code>ScaleLike | None</code> <p>The scale to be applied to the attribute. <code>None</code> means no scale is used.</p> Note <p>The attribute object can be constructed with <code>hakowan.attribute()</code> function, which is an alias of the constructor of this class.</p> Source code in <code>hakowan/grammar/scale/attribute.py</code> <pre><code>@dataclass(slots=True)\nclass Attribute:\n    \"\"\"An attribute represents a scalar or vector field that is defined on the 3D geometry.\n\n    An attribute is the 3D equivalent of a column in a table. Each attribute is uniquely identified\n    by the attribute name, which must exists in the data frame, and optionally associated with a scale.\n\n    Attributes:\n        name: The name of the attribute as it is defined in the data frame.\n        scale: The scale to be applied to the attribute. `None` means no scale is used.\n\n    Note:\n        The attribute object can be constructed with `hakowan.attribute()` function, which is an\n        alias of the constructor of this class.\n    \"\"\"\n\n    name: str\n    scale: ScaleLike | None = None\n\n    # (internal) The name of the attribute with scale applied.\n    _internal_name: str | None = None\n\n    # (internal) The name of the attribute representing the color field mapped from the scaled attribute.\n    _internal_color_field: str | None = None\n</code></pre>"},{"location":"api/channel/","title":"Channels","text":"<p>This page contains classes defined in <code>hakowan.channel</code> module.</p>"},{"location":"api/channel/#hakowan.grammar.channel.channel.Channel","title":"<code>Channel</code>  <code>dataclass</code>","text":"<p>Channel base class.</p> Source code in <code>hakowan/grammar/channel/channel.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Channel:\n    \"\"\"Channel base class.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/channel/#hakowan.grammar.channel.channel.Position","title":"<code>Position</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Channel</code></p> <p>Position channel</p> <p>This class is used to specify the mapping from an attribute to the position channel. Note that, by default, the vertex coordinates of the data frame is used as the position channel. Thus, this class is mainly useful when we want to use non-vertex-coordinates as the position channel. For example, this method can be used for visualizing a deformed shape when the deformed position is stored as a vertex attribute in the data frame.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>AttributeLike</code> <p>The attribute used to encode the position field.</p> Source code in <code>hakowan/grammar/channel/channel.py</code> <pre><code>@dataclass(slots=True)\nclass Position(Channel):\n    \"\"\"Position channel\n\n    This class is used to specify the mapping from an attribute to the position channel.\n    Note that, by default, the vertex coordinates of the data frame is used as the position\n    channel. Thus, this class is mainly useful when we want to use non-vertex-coordinates as the\n    position channel. For example, this method can be used for visualizing a deformed shape when\n    the deformed position is stored as a vertex attribute in the data frame.\n\n    Attributes:\n        data (AttributeLike): The attribute used to encode the position field.\n    \"\"\"\n\n    data: AttributeLike\n</code></pre>"},{"location":"api/channel/#hakowan.grammar.channel.channel.Normal","title":"<code>Normal</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Channel</code></p> <p>Normal channel</p> <p>This class is used to specify the mapping from an attribute to the normal channel. By default, Hakowan will automatically compute the normal field from the geometry if normal channel is not specified. This class is useful for ensure the visualization uses a pre-defined normal field.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>AttributeLike</code> <p>The attribute used to encode the normal field.</p> Source code in <code>hakowan/grammar/channel/channel.py</code> <pre><code>@dataclass(slots=True)\nclass Normal(Channel):\n    \"\"\"Normal channel\n\n    This class is used to specify the mapping from an attribute to the normal channel.\n    By default, Hakowan will automatically compute the normal field from the geometry if normal\n    channel is not specified. This class is useful for ensure the visualization uses a pre-defined\n    normal field.\n\n    Attributes:\n        data (AttributeLike): The attribute used to encode the normal field.\n    \"\"\"\n\n    data: AttributeLike\n</code></pre>"},{"location":"api/channel/#hakowan.grammar.channel.channel.Size","title":"<code>Size</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Channel</code></p> <p>Size channel</p> <p>This class is used to specify the mapping from an attribute or value to the size channel. If a value is used, all elements will have the same size. Note that size is defined in the same unit as the input geometry.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>AttributeLike | float</code> <p>The attribute or value used to encode the size field.</p> Source code in <code>hakowan/grammar/channel/channel.py</code> <pre><code>@dataclass(slots=True)\nclass Size(Channel):\n    \"\"\"Size channel\n\n    This class is used to specify the mapping from an attribute or value to the size channel. If a\n    value is used, all elements will have the same size. Note that size is defined in the same unit\n    as the input geometry.\n\n    Attributes:\n        data (AttributeLike | float): The attribute or value used to encode the size field.\n    \"\"\"\n\n    data: AttributeLike | float\n</code></pre>"},{"location":"api/channel/#hakowan.grammar.channel.channel.VectorField","title":"<code>VectorField</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Channel</code></p> <p>Vector field channel</p> <p>This class is used to specify the mapping from an attribute to the vector field channel.</p> <p>A vector field can be define over the vertices or facets of the geometry. The vector field must have the same dimension as the geometry.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>AttributeLike</code> <p>The attribute used to encode the vector field.</p> <code>refinement_level</code> <code>int</code> <p>The refinement level of the vector field. This parameter is used to control the density of the vector field. The default value is 0.</p> <code>style</code> <code>CurveStyle | None</code> <p>The style of the vector field. If None, the default style will be used.</p> <code>end_type</code> <code>str</code> <p>The type of the vector field end. The default value is \"point\".</p> Source code in <code>hakowan/grammar/channel/channel.py</code> <pre><code>@dataclass(slots=True)\nclass VectorField(Channel):\n    \"\"\"Vector field channel\n\n    This class is used to specify the mapping from an attribute to the vector field channel.\n\n    A vector field can be define over the vertices or facets of the geometry. The vector field must\n    have the same dimension as the geometry.\n\n    Attributes:\n        data (AttributeLike): The attribute used to encode the vector field.\n        refinement_level (int): The refinement level of the vector field. This parameter is used to\n            control the density of the vector field. The default value is 0.\n        style (CurveStyle | None): The style of the vector field. If None, the default style will\n            be used.\n        end_type (str): The type of the vector field end. The default value is \"point\".\n    \"\"\"\n\n    data: AttributeLike\n    refinement_level: int = 0\n    style: CurveStyle | None = None\n    end_type: str = \"point\"\n</code></pre>"},{"location":"api/channel/#hakowan.grammar.channel.channel.Covariance","title":"<code>Covariance</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Channel</code></p> <p>Covariance channel</p> <p>This class is used to specify the mapping from an attribute to the covariance matrix channel. The covariance channel only applies to point mark. It is represented as a per-vertex 3x3 symmetric matrix, which defines the stretch and rotation of the point marks.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>AttributeLike</code> <p>The attribute used to encode the covariance matrix.</p> <code>full</code> <code>bool</code> <p>(bool): If True, the full covariance matrix is stored in the attribute. If False, its \"square root\", M, is stored. The full covariance matrix is \u2211 := M @ M^T. The matrix M represenst the stretch and rotation transform applied on each mark.</p> Source code in <code>hakowan/grammar/channel/channel.py</code> <pre><code>@dataclass(slots=True)\nclass Covariance(Channel):\n    \"\"\"Covariance channel\n\n    This class is used to specify the mapping from an attribute to the covariance matrix channel.\n    The covariance channel only applies to point mark. It is represented as a per-vertex 3x3\n    symmetric matrix, which defines the stretch and rotation of the point marks.\n\n    Attributes:\n        data (AttributeLike): The attribute used to encode the covariance matrix.\n        full: (bool): If True, the full covariance matrix is stored in the attribute.\n            If False, its \"square root\", M, is stored. The full covariance matrix is \u2211 := M @ M^T.\n            The matrix M represenst the stretch and rotation transform applied on each mark.\n    \"\"\"\n\n    data: AttributeLike\n    full: bool = False\n</code></pre>"},{"location":"api/channel/#hakowan.grammar.channel.channel.Shape","title":"<code>Shape</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Channel</code></p> <p>Shape channel</p> <p>This class is used to specify the mapping from an attribute to the shape channel. This channel is only used for point mark.</p> <p>Attributes:</p> Name Type Description <code>base_shape</code> <code>str</code> <p>The base shape used to represent a point. Options include \"sphere\", \"disk\" and \"cube\". The default value is \"sphere\".</p> <code>orientation</code> <code>AttributeLike | None</code> <p>The attribute used to encode the normal orientation of the shape. If None, orientation will be identity (i.e. normal along z-axis).</p> Source code in <code>hakowan/grammar/channel/channel.py</code> <pre><code>@dataclass(slots=True)\nclass Shape(Channel):\n    \"\"\"Shape channel\n\n    This class is used to specify the mapping from an attribute to the shape channel.\n    This channel is only used for point mark.\n\n    Attributes:\n        base_shape (str): The base shape used to represent a point.\n            Options include \"sphere\", \"disk\" and \"cube\".\n            The default value is \"sphere\".\n        orientation (AttributeLike | None): The attribute used to encode the normal orientation\n            of the shape. If None, orientation will be identity (i.e. normal along z-axis).\n    \"\"\"\n\n    base_shape: str = \"sphere\"\n    orientation: Optional[AttributeLike] = None\n</code></pre>"},{"location":"api/channel/#hakowan.grammar.channel.channel.BumpMap","title":"<code>BumpMap</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Channel</code></p> <p>Bump map channel</p> <p>This class specifies the bump map channel.</p> <p>Attributes:</p> Name Type Description <code>texture</code> <code>TextureLike | None</code> <p>The texture used to encode the bump map.</p> <code>scale</code> <code>float</code> <p>The scale of the bump map. The default value is 1.0.</p> Source code in <code>hakowan/grammar/channel/channel.py</code> <pre><code>@dataclass(slots=True)\nclass BumpMap(Channel):\n    \"\"\"Bump map channel\n\n    This class specifies the bump map channel.\n\n    Attributes:\n        texture (TextureLike | None): The texture used to encode the bump map.\n        scale (float): The scale of the bump map. The default value is 1.0.\n    \"\"\"\n\n    texture: TextureLike\n    scale: float = 1.0\n</code></pre>"},{"location":"api/channel/#hakowan.grammar.channel.channel.NormalMap","title":"<code>NormalMap</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Channel</code></p> <p>Normal map channel</p> <p>This class specifies the normal map channel.</p> <p>Attributes:</p> Name Type Description <code>texture</code> <code>TextureLike | None</code> <p>The texture used to encode the normal map.</p> Source code in <code>hakowan/grammar/channel/channel.py</code> <pre><code>@dataclass(slots=True)\nclass NormalMap(Channel):\n    \"\"\"Normal map channel\n\n    This class specifies the normal map channel.\n\n    Attributes:\n        texture (TextureLike | None): The texture used to encode the normal map.\n    \"\"\"\n\n    texture: TextureLike\n</code></pre>"},{"location":"api/color/","title":"Color","text":"<p>This page contains classes defined in <code>hakowan.common.color</code> module.</p>"},{"location":"api/color/#hakowan.common.color.ColorLike","title":"<code>ColorLike = float | int | str | tuple | list</code>  <code>module-attribute</code>","text":"<p>Color-like type alias is types that can be converted to a color.</p>"},{"location":"api/color/#hakowan.common.color.Color","title":"<code>Color</code>","text":"<p>A minimal representation of color.</p> Source code in <code>hakowan/common/color.py</code> <pre><code>class Color:\n    \"\"\"A minimal representation of color.\"\"\"\n\n    @classmethod\n    def from_hex(cls, hex_color):\n        \"\"\"Construct color from hex.\"\"\"\n        c = hex_color.lstrip(\"#\")\n        assert len(c) == 6\n        return Color(\n            int(c[0:2], 16) / 255.0,\n            int(c[2:4], 16) / 255.0,\n            int(c[4:6], 16) / 255.0,\n        )\n\n    def __init__(self, red=0.0, green=0.0, blue=0.0):\n        \"\"\"Construct color from RGB.\"\"\"\n        self.color = np.array([red, green, blue])\n\n    def __getitem__(self, i):\n        \"\"\"Get color channel.\"\"\"\n        return self.color[i]\n\n    def __add__(self, other):\n        \"\"\"Add two colors.\"\"\"\n        c = self.color + other.color\n        return Color(*c)\n\n    def __mul__(self, scale):\n        \"\"\"Multiply color by a scalar.\"\"\"\n        c = self.color * scale\n        return Color(*c)\n\n    def __rmul__(self, scale):\n        \"\"\"Multiply color by a scalar.\"\"\"\n        return self.__mul__(scale)\n\n    def __eq__(self, other):\n        \"\"\"Check if two colors are equal.\"\"\"\n        return np.all(self.color == other.color)\n\n    def __ne__(self, other):\n        \"\"\"Check if two colors are not equal.\"\"\"\n        return not self == other\n\n    def __iter__(self):\n        \"\"\"Iterate over color channels.\"\"\"\n        return self.color.__iter__()\n\n    def __repr__(self):\n        \"\"\"String representation of color.\"\"\"\n        return f\"Color ({self.red}, {self.green}, {self.blue})\"\n\n    @property\n    def red(self):\n        \"\"\"Red channel.\"\"\"\n        return self.color[0]\n\n    @property\n    def green(self):\n        \"\"\"Green channel\"\"\"\n        return self.color[1]\n\n    @property\n    def blue(self):\n        \"\"\"Blue channel\"\"\"\n        return self.color[2]\n\n    @property\n    def data(self):\n        \"\"\"Raw data\"\"\"\n        return self.color\n</code></pre>"},{"location":"api/color/#hakowan.common.color.Color.red","title":"<code>red</code>  <code>property</code>","text":"<p>Red channel.</p>"},{"location":"api/color/#hakowan.common.color.Color.green","title":"<code>green</code>  <code>property</code>","text":"<p>Green channel</p>"},{"location":"api/color/#hakowan.common.color.Color.blue","title":"<code>blue</code>  <code>property</code>","text":"<p>Blue channel</p>"},{"location":"api/color/#hakowan.common.color.Color.data","title":"<code>data</code>  <code>property</code>","text":"<p>Raw data</p>"},{"location":"api/color/#hakowan.common.color.Color.from_hex","title":"<code>from_hex(hex_color)</code>  <code>classmethod</code>","text":"<p>Construct color from hex.</p> Source code in <code>hakowan/common/color.py</code> <pre><code>@classmethod\ndef from_hex(cls, hex_color):\n    \"\"\"Construct color from hex.\"\"\"\n    c = hex_color.lstrip(\"#\")\n    assert len(c) == 6\n    return Color(\n        int(c[0:2], 16) / 255.0,\n        int(c[2:4], 16) / 255.0,\n        int(c[4:6], 16) / 255.0,\n    )\n</code></pre>"},{"location":"api/color/#hakowan.common.color.Color.__init__","title":"<code>__init__(red=0.0, green=0.0, blue=0.0)</code>","text":"<p>Construct color from RGB.</p> Source code in <code>hakowan/common/color.py</code> <pre><code>def __init__(self, red=0.0, green=0.0, blue=0.0):\n    \"\"\"Construct color from RGB.\"\"\"\n    self.color = np.array([red, green, blue])\n</code></pre>"},{"location":"api/color/#hakowan.common.color.Color.__getitem__","title":"<code>__getitem__(i)</code>","text":"<p>Get color channel.</p> Source code in <code>hakowan/common/color.py</code> <pre><code>def __getitem__(self, i):\n    \"\"\"Get color channel.\"\"\"\n    return self.color[i]\n</code></pre>"},{"location":"api/color/#hakowan.common.color.Color.__add__","title":"<code>__add__(other)</code>","text":"<p>Add two colors.</p> Source code in <code>hakowan/common/color.py</code> <pre><code>def __add__(self, other):\n    \"\"\"Add two colors.\"\"\"\n    c = self.color + other.color\n    return Color(*c)\n</code></pre>"},{"location":"api/color/#hakowan.common.color.Color.__mul__","title":"<code>__mul__(scale)</code>","text":"<p>Multiply color by a scalar.</p> Source code in <code>hakowan/common/color.py</code> <pre><code>def __mul__(self, scale):\n    \"\"\"Multiply color by a scalar.\"\"\"\n    c = self.color * scale\n    return Color(*c)\n</code></pre>"},{"location":"api/color/#hakowan.common.color.Color.__rmul__","title":"<code>__rmul__(scale)</code>","text":"<p>Multiply color by a scalar.</p> Source code in <code>hakowan/common/color.py</code> <pre><code>def __rmul__(self, scale):\n    \"\"\"Multiply color by a scalar.\"\"\"\n    return self.__mul__(scale)\n</code></pre>"},{"location":"api/color/#hakowan.common.color.Color.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Check if two colors are equal.</p> Source code in <code>hakowan/common/color.py</code> <pre><code>def __eq__(self, other):\n    \"\"\"Check if two colors are equal.\"\"\"\n    return np.all(self.color == other.color)\n</code></pre>"},{"location":"api/color/#hakowan.common.color.Color.__ne__","title":"<code>__ne__(other)</code>","text":"<p>Check if two colors are not equal.</p> Source code in <code>hakowan/common/color.py</code> <pre><code>def __ne__(self, other):\n    \"\"\"Check if two colors are not equal.\"\"\"\n    return not self == other\n</code></pre>"},{"location":"api/color/#hakowan.common.color.Color.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over color channels.</p> Source code in <code>hakowan/common/color.py</code> <pre><code>def __iter__(self):\n    \"\"\"Iterate over color channels.\"\"\"\n    return self.color.__iter__()\n</code></pre>"},{"location":"api/color/#hakowan.common.color.Color.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of color.</p> Source code in <code>hakowan/common/color.py</code> <pre><code>def __repr__(self):\n    \"\"\"String representation of color.\"\"\"\n    return f\"Color ({self.red}, {self.green}, {self.blue})\"\n</code></pre>"},{"location":"api/colormap/","title":"Color map","text":"<p>This page contains classes defined in <code>hakowan.common.colormap</code> module.</p>"},{"location":"api/colormap/#hakowan.common.colormap.colormap.ColorMap","title":"<code>ColorMap</code>","text":"<p>A color map is a function that linearly interpolate a set of color samples.</p> Source code in <code>hakowan/common/colormap/colormap.py</code> <pre><code>class ColorMap:\n    \"\"\"A color map is a function that linearly interpolate a set of color\n    samples.\"\"\"\n\n    def __init__(self, samples: npt.NDArray):\n        \"\"\"Construct color map from color samples.\n\n        Args:\n            samples: A numpy array of shape (n, 3). Each row is a color sample.\n        \"\"\"\n        assert len(samples) &gt;= 2, \"Color map must have at least 2 samples.\"\n        self.samples = samples\n\n    def __call__(self, value: float):\n        \"\"\"Evaluate color map at a value between 0 and 1.\n\n        Args:\n            value: A value between 0 and 1.\n\n        Returns:\n            (Color): The interpolated color.\n        \"\"\"\n        value = max(0.0, min(1.0, value))\n\n        n = len(self.samples) - 1\n        i0 = math.floor(n * value)\n        i1 = math.ceil(n * value)\n\n        t = n * value - i0\n        c0 = self.samples[i0]\n        c1 = self.samples[i1]\n\n        c = c0 * (1 - t) + c1 * t\n        return Color(*c)\n\n    def num_colors(self):\n        \"\"\"Number of color samples stored in this color map.\n\n        Returns:\n            (int): Number of colors in the color map.\n        \"\"\"\n        return len(self.samples)\n</code></pre>"},{"location":"api/colormap/#hakowan.common.colormap.colormap.ColorMap.__init__","title":"<code>__init__(samples)</code>","text":"<p>Construct color map from color samples.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>NDArray</code> <p>A numpy array of shape (n, 3). Each row is a color sample.</p> required Source code in <code>hakowan/common/colormap/colormap.py</code> <pre><code>def __init__(self, samples: npt.NDArray):\n    \"\"\"Construct color map from color samples.\n\n    Args:\n        samples: A numpy array of shape (n, 3). Each row is a color sample.\n    \"\"\"\n    assert len(samples) &gt;= 2, \"Color map must have at least 2 samples.\"\n    self.samples = samples\n</code></pre>"},{"location":"api/colormap/#hakowan.common.colormap.colormap.ColorMap.__call__","title":"<code>__call__(value)</code>","text":"<p>Evaluate color map at a value between 0 and 1.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float</code> <p>A value between 0 and 1.</p> required <p>Returns:</p> Type Description <code>Color</code> <p>The interpolated color.</p> Source code in <code>hakowan/common/colormap/colormap.py</code> <pre><code>def __call__(self, value: float):\n    \"\"\"Evaluate color map at a value between 0 and 1.\n\n    Args:\n        value: A value between 0 and 1.\n\n    Returns:\n        (Color): The interpolated color.\n    \"\"\"\n    value = max(0.0, min(1.0, value))\n\n    n = len(self.samples) - 1\n    i0 = math.floor(n * value)\n    i1 = math.ceil(n * value)\n\n    t = n * value - i0\n    c0 = self.samples[i0]\n    c1 = self.samples[i1]\n\n    c = c0 * (1 - t) + c1 * t\n    return Color(*c)\n</code></pre>"},{"location":"api/colormap/#hakowan.common.colormap.colormap.ColorMap.num_colors","title":"<code>num_colors()</code>","text":"<p>Number of color samples stored in this color map.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of colors in the color map.</p> Source code in <code>hakowan/common/colormap/colormap.py</code> <pre><code>def num_colors(self):\n    \"\"\"Number of color samples stored in this color map.\n\n    Returns:\n        (int): Number of colors in the color map.\n    \"\"\"\n    return len(self.samples)\n</code></pre>"},{"location":"api/config/","title":"Configuration","text":"<p>This page contains class defined in the <code>hkw.setup</code> module.</p>"},{"location":"api/config/#config","title":"Config","text":""},{"location":"api/config/#hakowan.setup.config.Config","title":"<code>Config</code>  <code>dataclass</code>","text":"<p>Configuration for rendering.</p> <p>Attributes:</p> Name Type Description <code>sensor</code> <code>Sensor</code> <p>Sensor settings.</p> <code>film</code> <code>Film</code> <p>Film settings.</p> <code>sampler</code> <code>Sampler</code> <p>Sampler settings.</p> <code>emitters</code> <code>list[Emitter]</code> <p>Emitter settings.</p> <code>integrator</code> <code>Integrator</code> <p>Integrator settings.</p> <code>render_passes</code> <code>set[str]</code> <p>Set of active render passes.  Recognised values:</p> <ul> <li><code>\"albedo\"</code>    \u2013 diffuse color without shading.</li> <li><code>\"depth\"</code>     \u2013 depth buffer.</li> <li><code>\"normal\"</code>    \u2013 shading-normal pass.</li> <li><code>\"facet_id\"</code>  \u2013 per-face index encoded as RGB (Blender only).</li> </ul> <p>The convenience properties :attr:<code>albedo</code>, :attr:<code>depth</code>, :attr:<code>normal</code>, and :attr:<code>facet_id</code> are thin aliases that add or remove the corresponding string from this set.</p> Source code in <code>hakowan/setup/config.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Config:\n    \"\"\"Configuration for rendering.\n\n    Attributes:\n        sensor: Sensor settings.\n        film: Film settings.\n        sampler: Sampler settings.\n        emitters: Emitter settings.\n        integrator: Integrator settings.\n        render_passes: Set of active render passes.  Recognised values:\n\n            - ``\"albedo\"``    \u2013 diffuse color without shading.\n            - ``\"depth\"``     \u2013 depth buffer.\n            - ``\"normal\"``    \u2013 shading-normal pass.\n            - ``\"facet_id\"``  \u2013 per-face index encoded as RGB (Blender only).\n\n            The convenience properties :attr:`albedo`, :attr:`depth`,\n            :attr:`normal`, and :attr:`facet_id` are thin aliases that add or\n            remove the corresponding string from this set.\n    \"\"\"\n\n    sensor: Sensor = field(default_factory=Perspective)\n    film: Film = field(default_factory=Film)\n    sampler: Sampler = field(default_factory=Independent)\n    emitters: list[Emitter] = field(default_factory=lambda: [Envmap()])\n    integrator: Integrator = field(default_factory=Path)\n    _render_passes: set[str] = field(default_factory=set)\n\n    def z_up(self):\n        \"\"\"Update configuration for z-up coordinate system.\"\"\"\n        self.sensor.location = np.array([0, -5, 0])\n        self.sensor.up = np.array([0, 0, 1])\n        for emitter in self.emitters:\n            if isinstance(emitter, Envmap):\n                emitter.up = np.array([0, 0, 1])\n                emitter.rotation = 180.0\n\n    def z_down(self):\n        \"\"\"Update configuration for z-down coordinate system.\"\"\"\n        self.sensor.location = np.array([0, 5, 0])\n        self.sensor.up = np.array([0, 0, -1])\n        for emitter in self.emitters:\n            if isinstance(emitter, Envmap):\n                emitter.up = np.array([0, 0, -1])\n                emitter.rotation = 180.0\n\n    def y_up(self):\n        \"\"\"Update configuration for y-up coordinate system.\"\"\"\n        self.sensor.location = np.array([0, 0, 5])\n        self.sensor.up = np.array([0, 1, 0])\n        for emitter in self.emitters:\n            if isinstance(emitter, Envmap):\n                emitter.up = np.array([0, 1, 0])\n                emitter.rotation = 180.0\n\n    def y_down(self):\n        \"\"\"Update configuration for y-down coordinate system.\"\"\"\n        self.sensor.location = np.array([0, 0, -5])\n        self.sensor.up = np.array([0, -1, 0])\n        for emitter in self.emitters:\n            if isinstance(emitter, Envmap):\n                emitter.up = np.array([0, -1, 0])\n                emitter.rotation = 180.0\n\n    # ------------------------------------------------------------------ #\n    # render_passes \u2013 primary interface                                    #\n    # ------------------------------------------------------------------ #\n\n    @property\n    def render_passes(self) -&gt; set[str]:\n        \"\"\"Set of active render passes.\n\n        Valid pass names are ``\"albedo\"``, ``\"depth\"``, ``\"normal\"``, and\n        ``\"facet_id\"``.  Assigning a new collection replaces the entire set\n        and re-synchronises the Mitsuba AOV integrator accordingly.\n\n        Example::\n\n            config.render_passes = {\"albedo\", \"depth\"}\n        \"\"\"\n        return self._render_passes\n\n    @render_passes.setter\n    def render_passes(self, value: set[str] | list[str]):\n        \"\"\"Replace the active render-pass set and re-sync AOV integrator.\"\"\"\n        self._render_passes = set(value)\n        self.__sync_aovs()\n\n    # ------------------------------------------------------------------ #\n    # Convenience boolean aliases                                          #\n    # ------------------------------------------------------------------ #\n\n    @property\n    def albedo(self) -&gt; bool:\n        \"\"\"Whether the albedo pass is active.  Alias for ``\"albedo\" in render_passes``.\"\"\"\n        return \"albedo\" in self._render_passes\n\n    @albedo.setter\n    def albedo(self, value: bool):\n        \"\"\"Add or remove the albedo pass.  Also updates the Mitsuba AOV integrator.\"\"\"\n        if value:\n            self._render_passes.add(\"albedo\")\n        else:\n            self._render_passes.discard(\"albedo\")\n        self.__sync_aovs()\n\n    @property\n    def depth(self) -&gt; bool:\n        \"\"\"Whether the depth pass is active.  Alias for ``\"depth\" in render_passes``.\"\"\"\n        return \"depth\" in self._render_passes\n\n    @depth.setter\n    def depth(self, value: bool):\n        \"\"\"Add or remove the depth pass.  Also updates the Mitsuba AOV integrator.\"\"\"\n        if value:\n            self._render_passes.add(\"depth\")\n        else:\n            self._render_passes.discard(\"depth\")\n        self.__sync_aovs()\n\n    @property\n    def normal(self) -&gt; bool:\n        \"\"\"Whether the shading-normal pass is active.  Alias for ``\"normal\" in render_passes``.\"\"\"\n        return \"normal\" in self._render_passes\n\n    @normal.setter\n    def normal(self, value: bool):\n        \"\"\"Add or remove the normal pass.  Also updates the Mitsuba AOV integrator.\"\"\"\n        if value:\n            self._render_passes.add(\"normal\")\n        else:\n            self._render_passes.discard(\"normal\")\n        self.__sync_aovs()\n\n    @property\n    def facet_id(self) -&gt; bool:\n        \"\"\"Whether the facet-ID pass is active.  Alias for ``\"facet_id\" in render_passes``.\n\n        When active the Blender backend performs a second render after the\n        main one.  Every mesh face is colored with the RGB encoding of its\n        zero-based index (R = high byte, G = mid byte, B = low byte) using a\n        flat Emission shader so lighting has no effect.  The output is written\n        to ``&lt;stem&gt;_facet_id&lt;ext&gt;`` with gamma correction, temporal blending,\n        and pixel filtering all disabled so pixel values can be decoded\n        directly::\n\n            fid = (R &lt;&lt; 16) | (G &lt;&lt; 8) | B\n\n        Background pixels have ``A = 0`` and can be masked out.  Supports up\n        to 2**24 \u2212 1 \u2248 16.7 M faces.\n        \"\"\"\n        return \"facet_id\" in self._render_passes\n\n    @facet_id.setter\n    def facet_id(self, value: bool):\n        \"\"\"Add or remove the facet-ID pass.\"\"\"\n        if value:\n            self._render_passes.add(\"facet_id\")\n        else:\n            self._render_passes.discard(\"facet_id\")\n\n    # ------------------------------------------------------------------ #\n    # Internal helpers                                                     #\n    # ------------------------------------------------------------------ #\n\n    def __sync_aovs(self):\n        \"\"\"Rebuild the Mitsuba AOV integrator from the current render-pass set.\n\n        Strips any existing AOV wrapper and re-adds only the passes that are\n        currently active, ensuring the integrator always reflects the exact\n        state of ``_render_passes``.\n        \"\"\"\n        # Strip the AOV wrapper (if any) to start from the base integrator.\n        if isinstance(self.integrator, AOV):\n            self.integrator = self.integrator.integrator or Path()\n\n        # Re-add AOVs for every active pass that has a Mitsuba counterpart.\n        _pass_to_aov = {\n            \"albedo\": \"albedo:albedo\",\n            \"depth\": \"depth:depth\",\n            \"normal\": \"sh_normal:sh_normal\",\n        }\n        for pass_name, aov_str in _pass_to_aov.items():\n            if pass_name in self._render_passes:\n                if not isinstance(self.integrator, AOV):\n                    self.integrator = AOV(aovs=[aov_str], integrator=self.integrator)\n                elif aov_str not in self.integrator.aovs:\n                    self.integrator.aovs.append(aov_str)\n</code></pre>"},{"location":"api/config/#hakowan.setup.config.Config.albedo","title":"<code>albedo</code>  <code>property</code> <code>writable</code>","text":"<p>Whether the albedo pass is active.  Alias for <code>\"albedo\" in render_passes</code>.</p>"},{"location":"api/config/#hakowan.setup.config.Config.depth","title":"<code>depth</code>  <code>property</code> <code>writable</code>","text":"<p>Whether the depth pass is active.  Alias for <code>\"depth\" in render_passes</code>.</p>"},{"location":"api/config/#hakowan.setup.config.Config.facet_id","title":"<code>facet_id</code>  <code>property</code> <code>writable</code>","text":"<p>Whether the facet-ID pass is active.  Alias for <code>\"facet_id\" in render_passes</code>.</p> <p>When active the Blender backend performs a second render after the main one.  Every mesh face is colored with the RGB encoding of its zero-based index (R = high byte, G = mid byte, B = low byte) using a flat Emission shader so lighting has no effect.  The output is written to <code>&lt;stem&gt;_facet_id&lt;ext&gt;</code> with gamma correction, temporal blending, and pixel filtering all disabled so pixel values can be decoded directly::</p> <pre><code>fid = (R &lt;&lt; 16) | (G &lt;&lt; 8) | B\n</code></pre> <p>Background pixels have <code>A = 0</code> and can be masked out.  Supports up to 2**24 \u2212 1 \u2248 16.7 M faces.</p>"},{"location":"api/config/#hakowan.setup.config.Config.normal","title":"<code>normal</code>  <code>property</code> <code>writable</code>","text":"<p>Whether the shading-normal pass is active.  Alias for <code>\"normal\" in render_passes</code>.</p>"},{"location":"api/config/#hakowan.setup.config.Config.render_passes","title":"<code>render_passes</code>  <code>property</code> <code>writable</code>","text":"<p>Set of active render passes.</p> <p>Valid pass names are <code>\"albedo\"</code>, <code>\"depth\"</code>, <code>\"normal\"</code>, and <code>\"facet_id\"</code>.  Assigning a new collection replaces the entire set and re-synchronises the Mitsuba AOV integrator accordingly.</p> <p>Example::</p> <pre><code>config.render_passes = {\"albedo\", \"depth\"}\n</code></pre>"},{"location":"api/config/#hakowan.setup.config.Config.__sync_aovs","title":"<code>__sync_aovs()</code>","text":"<p>Rebuild the Mitsuba AOV integrator from the current render-pass set.</p> <p>Strips any existing AOV wrapper and re-adds only the passes that are currently active, ensuring the integrator always reflects the exact state of <code>_render_passes</code>.</p> Source code in <code>hakowan/setup/config.py</code> <pre><code>def __sync_aovs(self):\n    \"\"\"Rebuild the Mitsuba AOV integrator from the current render-pass set.\n\n    Strips any existing AOV wrapper and re-adds only the passes that are\n    currently active, ensuring the integrator always reflects the exact\n    state of ``_render_passes``.\n    \"\"\"\n    # Strip the AOV wrapper (if any) to start from the base integrator.\n    if isinstance(self.integrator, AOV):\n        self.integrator = self.integrator.integrator or Path()\n\n    # Re-add AOVs for every active pass that has a Mitsuba counterpart.\n    _pass_to_aov = {\n        \"albedo\": \"albedo:albedo\",\n        \"depth\": \"depth:depth\",\n        \"normal\": \"sh_normal:sh_normal\",\n    }\n    for pass_name, aov_str in _pass_to_aov.items():\n        if pass_name in self._render_passes:\n            if not isinstance(self.integrator, AOV):\n                self.integrator = AOV(aovs=[aov_str], integrator=self.integrator)\n            elif aov_str not in self.integrator.aovs:\n                self.integrator.aovs.append(aov_str)\n</code></pre>"},{"location":"api/config/#hakowan.setup.config.Config.y_down","title":"<code>y_down()</code>","text":"<p>Update configuration for y-down coordinate system.</p> Source code in <code>hakowan/setup/config.py</code> <pre><code>def y_down(self):\n    \"\"\"Update configuration for y-down coordinate system.\"\"\"\n    self.sensor.location = np.array([0, 0, -5])\n    self.sensor.up = np.array([0, -1, 0])\n    for emitter in self.emitters:\n        if isinstance(emitter, Envmap):\n            emitter.up = np.array([0, -1, 0])\n            emitter.rotation = 180.0\n</code></pre>"},{"location":"api/config/#hakowan.setup.config.Config.y_up","title":"<code>y_up()</code>","text":"<p>Update configuration for y-up coordinate system.</p> Source code in <code>hakowan/setup/config.py</code> <pre><code>def y_up(self):\n    \"\"\"Update configuration for y-up coordinate system.\"\"\"\n    self.sensor.location = np.array([0, 0, 5])\n    self.sensor.up = np.array([0, 1, 0])\n    for emitter in self.emitters:\n        if isinstance(emitter, Envmap):\n            emitter.up = np.array([0, 1, 0])\n            emitter.rotation = 180.0\n</code></pre>"},{"location":"api/config/#hakowan.setup.config.Config.z_down","title":"<code>z_down()</code>","text":"<p>Update configuration for z-down coordinate system.</p> Source code in <code>hakowan/setup/config.py</code> <pre><code>def z_down(self):\n    \"\"\"Update configuration for z-down coordinate system.\"\"\"\n    self.sensor.location = np.array([0, 5, 0])\n    self.sensor.up = np.array([0, 0, -1])\n    for emitter in self.emitters:\n        if isinstance(emitter, Envmap):\n            emitter.up = np.array([0, 0, -1])\n            emitter.rotation = 180.0\n</code></pre>"},{"location":"api/config/#hakowan.setup.config.Config.z_up","title":"<code>z_up()</code>","text":"<p>Update configuration for z-up coordinate system.</p> Source code in <code>hakowan/setup/config.py</code> <pre><code>def z_up(self):\n    \"\"\"Update configuration for z-up coordinate system.\"\"\"\n    self.sensor.location = np.array([0, -5, 0])\n    self.sensor.up = np.array([0, 0, 1])\n    for emitter in self.emitters:\n        if isinstance(emitter, Envmap):\n            emitter.up = np.array([0, 0, 1])\n            emitter.rotation = 180.0\n</code></pre>"},{"location":"api/config/#emitter","title":"Emitter","text":""},{"location":"api/config/#hakowan.setup.emitter.Emitter","title":"<code>Emitter</code>  <code>dataclass</code>","text":"<p>Emitter dataclass contains lighting-related settings.</p> Source code in <code>hakowan/setup/emitter.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Emitter:\n    \"\"\"Emitter dataclass contains lighting-related settings.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/config/#hakowan.setup.emitter.Envmap","title":"<code>Envmap</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Emitter</code></p> <p>Environment light (i.e. image-based lighting).</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>Path</code> <p>Path to the environment light image file.</p> <code>scale</code> <code>float</code> <p>Scaling factor to be applied to the environment light.</p> <code>up</code> <code>list</code> <p>Up vector of the environment light.</p> <code>rotation</code> <code>float</code> <p>Rotation angle of the environment light around the up direction.</p> Source code in <code>hakowan/setup/emitter.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Envmap(Emitter):\n    \"\"\"Environment light (i.e. image-based lighting).\n\n    Attributes:\n        filename: Path to the environment light image file.\n        scale: Scaling factor to be applied to the environment light.\n        up: Up vector of the environment light.\n        rotation: Rotation angle of the environment light around the up direction.\n    \"\"\"\n\n    filename: Path = field(\n        default_factory=lambda: Path(__file__).parents[1] / \"envmaps\" / \"museum.exr\"\n    )\n    scale: float = 1.0\n    up: list = field(default_factory=lambda: [0, 1, 0])\n    rotation: float = 180.0\n</code></pre>"},{"location":"api/config/#hakowan.setup.emitter.Point","title":"<code>Point</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Emitter</code></p> <p>Point light source.</p> <p>Attributes:</p> Name Type Description <code>intensity</code> <code>Color | float</code> <p>Light intensity.</p> <code>position</code> <code>list[float]</code> <p>Light position.</p> Source code in <code>hakowan/setup/emitter.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Point(Emitter):\n    \"\"\"Point light source.\n\n    Attributes:\n        intensity: Light intensity.\n        position: Light position.\n    \"\"\"\n\n    intensity: Color | float\n    position: list[float]\n</code></pre>"},{"location":"api/config/#film","title":"Film","text":""},{"location":"api/config/#hakowan.setup.film.Film","title":"<code>Film</code>  <code>dataclass</code>","text":"<p>Film dataclass stores specifications of the output image.</p> <p>Attributes:</p> Name Type Description <code>width</code> <code>int</code> <p>Width of the output image in pixels.</p> <code>height</code> <code>int</code> <p>Height of the output image in pixels.</p> <code>file_format</code> <code>str</code> <p>File format of the output image.</p> <code>pixel_format</code> <code>str</code> <p>Pixel format of the output image.</p> <code>component_format</code> <code>str</code> <p>Component format of the output image.</p> <code>crop_offset</code> <code>NDArray | None</code> <p>Offset of the crop window in pixels.</p> <code>crop_size</code> <code>NDArray | None</code> <p>Size of the crop window in pixels.</p> <p>Together, <code>width</code> and <code>height</code> specify the output image resolution. <code>crop_offset</code> and <code>crop_size</code> defines a crop region. If either is <code>None</code>, no cropping is performed. <code>file_format</code>, <code>pixel_format</code> and <code>component_format</code> are for advanced user only. The default values should work in most cases.</p> Source code in <code>hakowan/setup/film.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Film:\n    \"\"\"Film dataclass stores specifications of the output image.\n\n    Attributes:\n        width: Width of the output image in pixels.\n        height: Height of the output image in pixels.\n        file_format: File format of the output image.\n        pixel_format: Pixel format of the output image.\n        component_format: Component format of the output image.\n        crop_offset: Offset of the crop window in pixels.\n        crop_size: Size of the crop window in pixels.\n\n    Together, `width` and `height` specify the output image resolution.\n    `crop_offset` and `crop_size` defines a crop region. If either is `None`, no cropping is performed.\n    `file_format`, `pixel_format` and `component_format` are for advanced user only. The default\n    values should work in most cases.\n    \"\"\"\n\n    width: int = 1024\n    height: int = 800\n    file_format: str = \"openexr\"\n    pixel_format: str = \"rgba\"\n    component_format: str = \"float16\"\n    crop_offset: npt.NDArray | None = None\n    crop_size: npt.NDArray | None = None\n</code></pre>"},{"location":"api/config/#integrator","title":"Integrator","text":""},{"location":"api/config/#hakowan.setup.integrator.AOV","title":"<code>AOV</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Integrator</code></p> <p>Arbitrary output variable (AOV) integrator.</p> <p>Attributes:</p> Name Type Description <code>aovs</code> <code>list[str]</code> <p>List of AOVs to render.</p> <code>integrator</code> <code>Integrator | None</code> <p>Integrator to use for rendering AOVs.</p> Note <p>See Mitsuba doc for supported AOV types and other details.</p> Source code in <code>hakowan/setup/integrator.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass AOV(Integrator):\n    \"\"\"Arbitrary output variable (AOV) integrator.\n\n    Attributes:\n        aovs: List of AOVs to render.\n        integrator: Integrator to use for rendering AOVs.\n\n    Note:\n        See\n        [Mitsuba\n        doc](https://mitsuba.readthedocs.io/en/stable/src/generated/plugins_integrators.html#arbitrary-output-variables-integrator-aov)\n        for supported AOV types and other details.\n    \"\"\"\n\n    aovs: list[str]\n    integrator: Integrator | None = None\n</code></pre>"},{"location":"api/config/#hakowan.setup.integrator.Direct","title":"<code>Direct</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Integrator</code></p> <p>Direct integrator.</p> <p>Attributes:</p> Name Type Description <code>shading_samples</code> <code>int | None</code> <p>Number of shading samples.</p> <code>emitter_samples</code> <code>int | None</code> <p>Number of emitter samples.</p> <code>bsdf_samples</code> <code>int | None</code> <p>Number of BSDF samples.</p> Note <p>See Mitsuba doc for more details.</p> Source code in <code>hakowan/setup/integrator.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Direct(Integrator):\n    \"\"\"Direct integrator.\n\n    Attributes:\n        shading_samples: Number of shading samples.\n        emitter_samples: Number of emitter samples.\n        bsdf_samples: Number of BSDF samples.\n\n    Note:\n        See\n        [Mitsuba doc](https://mitsuba.readthedocs.io/en/stable/src/generated/plugins_integrators.html#direct-illumination-integrator-direct)\n        for more details.\n    \"\"\"\n\n    shading_samples: int | None = None\n    emitter_samples: int | None = None\n    bsdf_samples: int | None = None\n</code></pre>"},{"location":"api/config/#hakowan.setup.integrator.Integrator","title":"<code>Integrator</code>  <code>dataclass</code>","text":"<p>Integrator dataclass contains parameters of various rendering techniques.</p> <p>Attributes:</p> Name Type Description <code>hide_emitters</code> <code>bool</code> <p>Whether to hide emitters from the camera.</p> Source code in <code>hakowan/setup/integrator.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Integrator:\n    \"\"\"Integrator dataclass contains parameters of various rendering techniques.\n\n    Attributes:\n        hide_emitters: Whether to hide emitters from the camera.\n    \"\"\"\n\n    hide_emitters: bool = True\n</code></pre>"},{"location":"api/config/#hakowan.setup.integrator.Path","title":"<code>Path</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Integrator</code></p> <p>Path integrator.</p> <p>Attributes:</p> Name Type Description <code>max_depth</code> <code>int</code> <p>Maximum path depth. (-1 for unlimited)</p> <code>rr_depth</code> <code>int</code> <p>Depth at which Russian roulette starts.</p> Note <p>This integrator should work well for most surface-based scenes. See Mitsuba doc for more details.</p> Source code in <code>hakowan/setup/integrator.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Path(Integrator):\n    \"\"\"Path integrator.\n\n    Attributes:\n        max_depth: Maximum path depth. (-1 for unlimited)\n        rr_depth: Depth at which Russian roulette starts.\n\n    Note:\n        This integrator should work well for most surface-based scenes.\n        See\n        [Mitsuba\n        doc](https://mitsuba.readthedocs.io/en/stable/src/generated/plugins_integrators.html#path-tracer-path)\n        for more details.\n    \"\"\"\n\n    max_depth: int = -1\n    rr_depth: int = 5\n</code></pre>"},{"location":"api/config/#hakowan.setup.integrator.VolPath","title":"<code>VolPath</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Integrator</code></p> <p>Volumetric path integrator.</p> <p>Attributes:</p> Name Type Description <code>max_depth</code> <code>int</code> <p>Maximum path depth. (-1 for unlimited)</p> <code>rr_depth</code> <code>int</code> <p>Depth at which Russian roulette starts.</p> Note <p>This integrator should work well for most volume-based scenes. For example, if dielectric material is involved, <code>VolPath</code> integrator sometimes produces better results than <code>Path</code> integrator.</p> <p>See Mitsuba doc for more details.</p> Source code in <code>hakowan/setup/integrator.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass VolPath(Integrator):\n    \"\"\"Volumetric path integrator.\n\n    Attributes:\n        max_depth: Maximum path depth. (-1 for unlimited)\n        rr_depth: Depth at which Russian roulette starts.\n\n    Note:\n        This integrator should work well for most volume-based scenes. For example, if dielectric\n        material is involved, `VolPath` integrator sometimes produces better results than `Path`\n        integrator.\n\n        See\n        [Mitsuba\n        doc](https://mitsuba.readthedocs.io/en/stable/src/generated/plugins_integrators.html#volumetric-path-tracer-volpath)\n        for more details.\n    \"\"\"\n\n    max_depth: int = -1\n    rr_depth: int = 5\n</code></pre>"},{"location":"api/config/#hakowan.setup.integrator.VolPathMIS","title":"<code>VolPathMIS</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Integrator</code></p> <p>Volumetric path integrator with spectral MIS.</p> <p>Attributes:</p> Name Type Description <code>max_depth</code> <code>int</code> <p>Maximum path depth. (-1 for unlimited)</p> <code>rr_depth</code> <code>int</code> <p>Depth at which Russian roulette starts.</p> Note <p>See Mitsuba doc for more details.</p> Source code in <code>hakowan/setup/integrator.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass VolPathMIS(Integrator):\n    \"\"\"Volumetric path integrator with spectral MIS.\n\n    Attributes:\n        max_depth: Maximum path depth. (-1 for unlimited)\n        rr_depth: Depth at which Russian roulette starts.\n\n    Note:\n        See\n        [Mitsuba\n        doc](https://mitsuba.readthedocs.io/en/stable/src/generated/plugins_integrators.html#volumetric-path-tracer-with-spectral-mis-volpathmis)\n        for more details.\n    \"\"\"\n\n    max_depth: int = -1\n    rr_depth: int = 5\n</code></pre>"},{"location":"api/config/#sampler","title":"Sampler","text":""},{"location":"api/config/#hakowan.setup.sampler.Independent","title":"<code>Independent</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Sampler</code></p> <p>Independent sampler.</p> Note <p>See Mitsuba doc for more details.</p> Source code in <code>hakowan/setup/sampler.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Independent(Sampler):\n    \"\"\"Independent sampler.\n\n    Note:\n        See\n        [Mitsuba\n        doc](https://mitsuba.readthedocs.io/en/stable/src/generated/plugins_samplers.html#independent-sampler-independent)\n        for more details.\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/config/#hakowan.setup.sampler.Sampler","title":"<code>Sampler</code>  <code>dataclass</code>","text":"<p>Sampler dataclass contains sampling-related settings.</p> <p>Attributes:</p> Name Type Description <code>sample_count</code> <code>int</code> <p>Number of samples per pixel.</p> <code>seed</code> <code>int</code> <p>Seed for random number generate.</p> Source code in <code>hakowan/setup/sampler.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Sampler:\n    \"\"\"Sampler dataclass contains sampling-related settings.\n\n    Attributes:\n        sample_count: Number of samples per pixel.\n        seed: Seed for random number generate.\n    \"\"\"\n\n    sample_count: int = 256  # Samples per pixel.\n    seed: int = 0\n</code></pre>"},{"location":"api/config/#hakowan.setup.sampler.Stratified","title":"<code>Stratified</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Sampler</code></p> <p>Stratified sampler.</p> <p>Attributes:</p> Name Type Description <code>jitter</code> <code>bool</code> <p>Whether to jitter the samples.</p> Note <p>See Mitsuba doc for more details.</p> Source code in <code>hakowan/setup/sampler.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Stratified(Sampler):\n    \"\"\"Stratified sampler.\n\n    Attributes:\n        jitter: Whether to jitter the samples.\n\n    Note:\n        See [Mitsuba\n        doc](https://mitsuba.readthedocs.io/en/stable/src/generated/plugins_samplers.html#stratified-sampler-stratified)\n        for more details.\n    \"\"\"\n\n    jitter: bool = True\n</code></pre>"},{"location":"api/config/#sensor","title":"Sensor","text":""},{"location":"api/config/#hakowan.setup.sensor.Orthographic","title":"<code>Orthographic</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Sensor</code></p> <p>Orthographic camera dataclass.</p> Source code in <code>hakowan/setup/sensor.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Orthographic(Sensor):\n    \"\"\"Orthographic camera dataclass.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/config/#hakowan.setup.sensor.Perspective","title":"<code>Perspective</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Sensor</code></p> <p>Perspective camera dataclass.</p> <p>Attributes:</p> Name Type Description <code>fov</code> <code>float</code> <p>Field of view in degrees.</p> <code>fov_axis</code> <code>str</code> <p>Axis to which fov is applied. Can be \"x\" or \"y\" or \"diagonal\" or \"smaller\" or \"larger\".</p> Source code in <code>hakowan/setup/sensor.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Perspective(Sensor):\n    \"\"\"Perspective camera dataclass.\n\n    Attributes:\n        fov: Field of view in degrees.\n        fov_axis: Axis to which fov is applied. Can be \"x\" or \"y\" or \"diagonal\" or \"smaller\" or \"larger\".\n    \"\"\"\n\n    fov: float = 28.8415  # degrees\n    fov_axis: str = \"smaller\"\n</code></pre>"},{"location":"api/config/#hakowan.setup.sensor.Sensor","title":"<code>Sensor</code>  <code>dataclass</code>","text":"<p>Sensor dataclass contains camera-related settings.</p> <p>Attributes:</p> Name Type Description <code>location</code> <code>list</code> <p>Camera location in world space.</p> <code>target</code> <code>list</code> <p>Camera look-at location in world space.</p> <code>up</code> <code>list</code> <p>Camera up vector in world space.</p> <code>near_clip</code> <code>float</code> <p>Near clipping plane distance.</p> <code>far_clip</code> <code>float</code> <p>Far clipping plane distance.</p> Source code in <code>hakowan/setup/sensor.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Sensor:\n    \"\"\"Sensor dataclass contains camera-related settings.\n\n    Attributes:\n        location: Camera location in world space.\n        target: Camera look-at location in world space.\n        up: Camera up vector in world space.\n        near_clip: Near clipping plane distance.\n        far_clip: Far clipping plane distance.\n    \"\"\"\n\n    location: list = field(default_factory=lambda: [0, 0, 5])\n    target: list = field(default_factory=lambda: [0, 0, 0])\n    up: list = field(default_factory=lambda: [0, 1, 0])\n    near_clip: float = 1e-2\n    far_clip: float = 1e4\n</code></pre>"},{"location":"api/config/#hakowan.setup.sensor.ThinLens","title":"<code>ThinLens</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Perspective</code></p> <p>Thin lens camera dataclass.</p> <p>Attributes:</p> Name Type Description <code>aperture_radius</code> <code>float</code> <p>Radius of the aperture in world space.</p> <code>focus_distance</code> <code>float</code> <p>Distance to the focal plane in world space.</p> Source code in <code>hakowan/setup/sensor.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass ThinLens(Perspective):\n    \"\"\"Thin lens camera dataclass.\n\n    Attributes:\n        aperture_radius: Radius of the aperture in world space.\n        focus_distance: Distance to the focal plane in world space.\n    \"\"\"\n\n    aperture_radius: float = 0.1\n    focus_distance: float = 0.0\n</code></pre>"},{"location":"api/curve_style/","title":"Curve style","text":""},{"location":"api/curve_style/#hakowan.grammar.channel.curvestyle.CurveStyle","title":"<code>CurveStyle</code>  <code>dataclass</code>","text":"<p>Curve style base class.</p> Source code in <code>hakowan/grammar/channel/curvestyle.py</code> <pre><code>@dataclass\nclass CurveStyle:\n    \"\"\"Curve style base class.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/curve_style/#hakowan.grammar.channel.curvestyle.Bend","title":"<code>Bend</code>  <code>dataclass</code>","text":"<p>               Bases: <code>CurveStyle</code></p> <p>Curve bending style.</p> <p>Attributes:</p> Name Type Description <code>direction</code> <code>AttributeLike</code> <p>The attribute used to encode the bending direction.</p> <code>bend_type</code> <code>str</code> <p>The type of bending (options are 's', 'r', 'n'). The default value is 'n'.</p> Source code in <code>hakowan/grammar/channel/curvestyle.py</code> <pre><code>@dataclass\nclass Bend(CurveStyle):\n    \"\"\"Curve bending style.\n\n    Attributes:\n        direction (AttributeLike): The attribute used to encode the bending direction.\n        bend_type (str): The type of bending (options are 's', 'r', 'n'). The default value is 'n'.\n    \"\"\"\n\n    direction: AttributeLike\n    bend_type: str = \"n\"\n</code></pre>"},{"location":"api/data/","title":"Data","text":"<p>This page contains classes defined in <code>hakowan.dataclass</code> module.</p>"},{"location":"api/data/#hakowan.grammar.dataframe.dataframe.DataFrameLike","title":"<code>DataFrameLike = str | Path | lagrange.SurfaceMesh | DataFrame</code>  <code>module-attribute</code>","text":"<p>Type alias for objects that can be converted to a DataFrame.</p> <ul> <li>A string or a Path object is interpreted as a path to a file that contains a mesh object. A <code>DataFrame</code> object will be created with the loaded mesh.</li> <li>A SurfaceMesh object will create a DataFrame object with the mesh object.</li> <li>A DataFrame object will be unchanged.</li> </ul>"},{"location":"api/data/#hakowan.grammar.dataframe.dataframe.DataFrame","title":"<code>DataFrame</code>  <code>dataclass</code>","text":"<p>DataFrame represents data that are stored on a 3D surface.</p> <p>A DataFrame contains a reference to a SurfaceMesh object, which defines the 3D geometry where data are stored. The mesh object also contains a set of attributes, which can be thought of as columns in traditional table-based data representation. Each attribute defines data values associated with mesh vertices, edges, facets, etc.</p> <p>Attributes:</p> Name Type Description <code>mesh</code> <code>SurfaceMesh</code> <p>A SurfaceMesh object that defines the 3D geometry where data are stored.</p> <code>roi_box</code> <code>ArrayLike | None</code> <p>A box defining the region of interest. If None, the entire mesh is considered.</p> Source code in <code>hakowan/grammar/dataframe/dataframe.py</code> <pre><code>@dataclass(slots=True)\nclass DataFrame:\n    \"\"\"DataFrame represents data that are stored on a 3D surface.\n\n    A DataFrame contains a reference to a SurfaceMesh object, which defines the 3D geometry where\n    data are stored. The mesh object also contains a set of attributes, which can be thought of as\n    columns in traditional table-based data representation. Each attribute defines data values\n    associated with mesh vertices, edges, facets, etc.\n\n    Attributes:\n        mesh: A SurfaceMesh object that defines the 3D geometry where data are stored.\n        roi_box: A box defining the region of interest. If None, the entire mesh is considered.\n    \"\"\"\n\n    mesh: lagrange.SurfaceMesh\n    roi_box: npt.ArrayLike | None = None\n</code></pre>"},{"location":"api/layer/","title":"Layer","text":"<p>This page contains classes from <code>hakowan.grammar.layer</code> module.</p>"},{"location":"api/layer/#hakowan.grammar.layer.layer.Layer","title":"<code>Layer</code>  <code>dataclass</code>","text":"<p>Layer contains the specification of data, mark, channels and transform.</p> Note <p><code>hakowan.layer()</code> method is an alias of the constructor of this class.</p> Source code in <code>hakowan/grammar/layer/layer.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Layer:\n    \"\"\"Layer contains the specification of data, mark, channels and transform.\n\n    Note:\n        `hakowan.layer()` method is an alias of the constructor of this class.\n    \"\"\"\n\n    _spec: LayerSpec = field(default_factory=LayerSpec)\n    _children: list[\"Layer\"] = field(default_factory=list)\n\n    def __init__(\n        self,\n        data: DataFrameLike | None = None,\n        *,\n        mark: Mark | None = None,\n        channels: list[Channel] | None = None,\n        transform: Transform | None = None,\n    ):\n        \"\"\"Constructor of Layer.\n\n        Args:\n            data (DataFrameLike | None, optional): The data component of\n                the layer.\n            mark (Mark|None, optional): The mark component of the layer.\n            channels (list[Channel], optional): The channels of the layer.\n            transform (Transform, optional): The transform component of the layer.\n\n        Returns:\n            (Layer): The constructed layer object.\n        \"\"\"\n        self._spec = LayerSpec()\n        self._children = []\n\n        if data is not None:\n            self.data(data, in_place=True)\n        if mark is not None:\n            self.mark(mark, in_place=True)\n        if transform is not None:\n            self.transform(transform, in_place=True)\n        if channels is not None:\n            self._spec.channels = channels\n\n    def __add__(self, other: \"Layer\") -&gt; \"Layer\":\n        \"\"\"Combine two layers into a composite layer.\n\n        Args:\n            other (Layer): The other layer to be combined with.\n\n        Returns:\n            (Layer): The composite layer.\n        \"\"\"\n        parent = Layer()\n        parent._children = [self, other]\n        return parent\n\n    def __get_working_layer(self, in_place: bool = False) -&gt; \"Layer\":\n        if in_place:\n            return self\n        else:\n            l = Layer()\n            l._children = [self]\n            return l\n\n    def data(\n        self,\n        data: DataFrameLike,\n        *,\n        roi_box: npt.ArrayLike | None = None,\n        in_place: bool = False,\n    ) -&gt; \"Layer\":\n        \"\"\"Overwrite the data component of this layer.\n\n        Args:\n            data (DataFrameLike): The new data component.\n            roi_box (npt.ArrayLike, optional): The region of interest box of the data.\n            in_place (bool, optional): Whether to modify the current layer in place or create new\n                layer. Defaults to False (i.e. create a new layer).\n\n        Returns:\n            result (Layer): The layer object with data component overwritten.\n        \"\"\"\n        l = self.__get_working_layer(in_place)\n        match data:\n            case str() | Path():\n                mesh = lagrange.io.load_mesh(data, quiet=True, stitch_vertices=True)  # type: ignore\n                l._spec.data = DataFrame(mesh=mesh, roi_box=roi_box)\n            case lagrange.SurfaceMesh():\n                l._spec.data = DataFrame(mesh=data, roi_box=roi_box)\n            case DataFrame():\n                l._spec.data = data\n                if roi_box is not None:\n                    l._spec.data.roi_box = roi_box\n            case _:\n                raise TypeError(f\"Unsupported data type: {type(data)}!\")\n        return l\n\n    def mark(self, mark: Mark | str, *, in_place: bool = False) -&gt; \"Layer\":\n        \"\"\"Overwrite the mark component of this layer.\n\n        Args:\n            mark (Mark | str): The new mark component.\n            in_place (bool, optional): Whether to modify the current layer in place or create new\n                layer. Defaults to False (i.e. create a new layer).\n\n        Returns:\n            result (Layer): The layer object with mark component overwritten.\n        \"\"\"\n        l = self.__get_working_layer(in_place)\n        match mark:\n            case Mark():\n                l._spec.mark = mark\n            case \"point\" | \"Point\" | \"POINT\":\n                l._spec.mark = Mark.Point\n            case \"curve\" | \"Curve\" | \"CURVE\":\n                l._spec.mark = Mark.Curve\n            case \"surface\" | \"Surface\" | \"SURFACE\":\n                l._spec.mark = Mark.Surface\n            case _:\n                raise ValueError(f\"Unsupported mark type: {mark}!\")\n        return l\n\n    def channel(\n        self,\n        *,\n        position: Position | str | None = None,\n        normal: Normal | str | None = None,\n        size: float | str | Size | None = None,\n        shape: str | Shape | None = None,\n        vector_field: VectorField | str | None = None,\n        covariance: Covariance | str | None = None,\n        material: Material | None = None,\n        bump_map: BumpMap | TextureLike | None = None,\n        normal_map: NormalMap | TextureLike | None = None,\n        in_place: bool = False,\n    ) -&gt; \"Layer\":\n        \"\"\"Overwrite a channel component of this layer.\n\n        Args:\n            position (Position | str, optional): The new position channel.\n            normal (Normal | str, optional): The new normal channel.\n            size (float | str | Size, optional): The new size channel.\n            vector_field (VectorField | str, optional): The new vector field channel.\n            material (Material, optional): The new material channel.\n            bump_map (BumpMap | TextureLike, optional): The new bump map channel.\n            normal_map (NormalMap | TextureLike, optional): The new normal map channel.\n            in_place (bool, optional): Whether to modify the current layer in place or create new\n                layer. Defaults to False (i.e. create a new layer).\n\n        Returns:\n            result (Layer): The layer object with the channel component overwritten.\n        \"\"\"\n        l = self.__get_working_layer(in_place)\n\n        convert = (\n            lambda value, cls: cls(data=Attribute(name=value))\n            if isinstance(value, str)\n            else value\n        )\n        if position is not None:\n            assert isinstance(position, (Position, str)), (\n                f\"Unsupported position type: {type(position)}!\"\n            )\n            l._spec.channels.append(convert(position, Position))\n        if normal is not None:\n            assert isinstance(normal, (Normal, str)), (\n                f\"Unsupported normal type: {type(normal)}!\"\n            )\n            l._spec.channels.append(convert(normal, Normal))\n        if size is not None:\n            if isinstance(size, (int, float)):\n                l._spec.channels.append(Size(data=float(size)))\n            else:\n                assert isinstance(size, (Size, str)), (\n                    f\"Unsupported size type: {type(size)}!\"\n                )\n                l._spec.channels.append(convert(size, Size))\n        if shape is not None:\n            if isinstance(shape, str):\n                l._spec.channels.append(Shape(base_shape=shape))\n            else:\n                assert isinstance(shape, Shape), (\n                    f\"Unsupported shape type: {type(shape)}!\"\n                )\n                l._spec.channels.append(shape)\n        if vector_field is not None:\n            assert isinstance(vector_field, (VectorField, str)), (\n                f\"Unsupported vector_field type: {type(vector_field)}!\"\n            )\n            l._spec.channels.append(convert(vector_field, VectorField))\n        if covariance is not None:\n            assert isinstance(covariance, (Covariance, str)), (\n                f\"Unsupported covariance type: {type(covariance)}!\"\n            )\n            l._spec.channels.append(convert(covariance, Covariance))\n        if material is not None:\n            l._spec.channels.append(material)\n        if bump_map is not None:\n            if isinstance(bump_map, BumpMap):\n                l._spec.channels.append(bump_map)\n            else:\n                l._spec.channels.append(BumpMap(bump_map))\n        if normal_map is not None:\n            if isinstance(normal_map, NormalMap):\n                l._spec.channels.append(normal_map)\n            else:\n                l._spec.channels.append(NormalMap(normal_map))\n        return l\n\n    def material(self, type: str, *args, in_place: bool = False, **kwargs) -&gt; \"Layer\":\n        \"\"\"Overwrite material for this layer.\n\n        Args:\n            type (str): The material type.\n            in_place (bool, optional): Whether to modify the current layer in place or create new\n                layer. Defaults to False (i.e. create a new layer).\n            *args: Variable length argument list that will be forwarded to material constructor.\n            **kwargs: Arbitrary keyword arguments that will be forwarded to material constructor.\n\n        Returns:\n            result (Layer): The layer object with the channel component overwritten.\n        \"\"\"\n        l = self.__get_working_layer(in_place)\n        match type:\n            case \"diffuse\" | \"Diffuse\" | \"DIFFUSE\":\n                l._spec.channels.append(Diffuse(*args, **kwargs))\n            case \"conductor\" | \"Conductor\" | \"CONDUCTOR\":\n                l._spec.channels.append(Conductor(*args, **kwargs))\n            case \"rough_conductor\" | \"RoughConductor\" | \"ROUGH_CONDUCTOR\":\n                l._spec.channels.append(RoughConductor(*args, **kwargs))\n            case \"plastic\" | \"Plastic\" | \"PLASTIC\":\n                l._spec.channels.append(Plastic(*args, **kwargs))\n            case \"rough_plastic\" | \"RoughPlastic\" | \"ROUGH_PLASTIC\":\n                l._spec.channels.append(RoughPlastic(*args, **kwargs))\n            case \"principled\" | \"Principled\" | \"PRINCIPLED\":\n                l._spec.channels.append(Principled(*args, **kwargs))\n            case \"thin_principled\" | \"ThinPrincipled\" | \"THIN_PRINCIPLED\":\n                l._spec.channels.append(ThinPrincipled(*args, **kwargs))\n            case \"dielectric\" | \"Dielectric\" | \"DIELECTRIC\":\n                l._spec.channels.append(Dielectric(*args, **kwargs))\n            case \"thin_dielectric\" | \"ThinDielectric\" | \"THIN_DIELECTRIC\":\n                l._spec.channels.append(ThinDielectric(*args, **kwargs))\n            case \"rough_dielectric\" | \"RoughDielectric\" | \"ROUGH_DIELECTRIC\":\n                l._spec.channels.append(RoughDielectric(*args, **kwargs))\n            case \"hair\" | \"Hair\" | \"HAIR\":\n                l._spec.channels.append(Hair(*args, **kwargs))\n            case _:\n                raise ValueError(f\"Unsupported material type: {type}!\")\n        return l\n\n    def transform(self, transform: Transform, *, in_place: bool = False) -&gt; \"Layer\":\n        \"\"\"Overwrite the transform component of this layer.\n\n        Args:\n            transform (Transform): The new transform component.\n            in_place (bool, optional): Whether to modify the current layer in place or create new\n                layer. Defaults to False (i.e. create a new layer).\n\n        Returns:\n            result (Layer): The layer object with transform component overwritten.\n        \"\"\"\n        l = self.__get_working_layer(in_place)\n        l._spec.transform = transform\n        return l\n\n    def rotate(\n        self, axis: npt.ArrayLike, angle: float, in_place: bool = False\n    ) -&gt; \"Layer\":\n        \"\"\"Update the transform component of the current layer by applying a rotation.\n\n        Args:\n            axis (npt.ArrayLike): The unit rotation axis.\n            angle (float): The rotation angle (in radians).\n            in_place (bool, optional): Whether to modify the current layer in place or create new\n                layer. Defaults to False (i.e. create a new layer).\n\n        Returns:\n            result (Layer): The layer object with transform component updated.\n        \"\"\"\n        l = self.__get_working_layer(in_place)\n        v = np.array(axis, dtype=np.float64)\n        I = np.eye(3)\n        H = np.outer(v, v)\n        S = np.cross(I, v)\n        M = I * np.cos(angle) + S * np.sin(angle) + H * (1 - np.cos(angle))\n        if l._spec.transform is None:\n            l._spec.transform = Affine(M)\n        else:\n            l._spec.transform *= Affine(M)\n        return l\n\n    def translate(self, offset: npt.ArrayLike, in_place: bool = False) -&gt; \"Layer\":\n        \"\"\"Update the transform component of the current layer by applying a translation.\n\n        Args:\n            offset (npt.ArrayLike): The translation offset.\n            in_place (bool, optional): Whether to modify the current layer in place or create new\n                layer. Defaults to False (i.e. create a new layer).\n\n        Returns:\n            result (Layer): The layer object with transform component updated.\n        \"\"\"\n        l = self.__get_working_layer(in_place)\n        M = np.eye(4)\n        M[:3, 3] = np.array(offset, dtype=np.float64)\n\n        if l._spec.transform is None:\n            l._spec.transform = Affine(M)\n        else:\n            l._spec.transform *= Affine(M)\n        return l\n\n    def scale(self, factor: float, in_place: bool = False) -&gt; \"Layer\":\n        \"\"\"Update the transform component of the current layer by applying uniform scaling.\n\n        Args:\n            factor (float): The scaling factor.\n            in_place (bool, optional): Whether to modify the current layer in place or create new\n                layer. Defaults to False (i.e. create a new layer).\n\n        Returns:\n            result (Layer): The layer object with transform component updated.\n        \"\"\"\n        l = self.__get_working_layer(in_place)\n        M = np.eye(4)\n        M[0, 0] = M[1, 1] = M[2, 2] = factor\n        if l._spec.transform is None:\n            l._spec.transform = Affine(M)\n        else:\n            l._spec.transform *= Affine(M)\n        return l\n\n    @property\n    def children(self) -&gt; list[\"Layer\"]:\n        \"\"\"Get the child layers of this layer.\"\"\"\n        return self._children\n\n    @children.setter\n    def children(self, value: Sequence[\"Layer\"]) -&gt; None:\n        \"\"\"Set the child layers of this layer.\"\"\"\n        self._children = list(value)\n</code></pre>"},{"location":"api/layer/#hakowan.grammar.layer.layer.Layer.children","title":"<code>children</code>  <code>property</code> <code>writable</code>","text":"<p>Get the child layers of this layer.</p>"},{"location":"api/layer/#hakowan.grammar.layer.layer.Layer.__add__","title":"<code>__add__(other)</code>","text":"<p>Combine two layers into a composite layer.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Layer</code> <p>The other layer to be combined with.</p> required <p>Returns:</p> Type Description <code>Layer</code> <p>The composite layer.</p> Source code in <code>hakowan/grammar/layer/layer.py</code> <pre><code>def __add__(self, other: \"Layer\") -&gt; \"Layer\":\n    \"\"\"Combine two layers into a composite layer.\n\n    Args:\n        other (Layer): The other layer to be combined with.\n\n    Returns:\n        (Layer): The composite layer.\n    \"\"\"\n    parent = Layer()\n    parent._children = [self, other]\n    return parent\n</code></pre>"},{"location":"api/layer/#hakowan.grammar.layer.layer.Layer.__init__","title":"<code>__init__(data=None, *, mark=None, channels=None, transform=None)</code>","text":"<p>Constructor of Layer.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrameLike | None</code> <p>The data component of the layer.</p> <code>None</code> <code>mark</code> <code>Mark | None</code> <p>The mark component of the layer.</p> <code>None</code> <code>channels</code> <code>list[Channel]</code> <p>The channels of the layer.</p> <code>None</code> <code>transform</code> <code>Transform</code> <p>The transform component of the layer.</p> <code>None</code> <p>Returns:</p> Type Description <code>Layer</code> <p>The constructed layer object.</p> Source code in <code>hakowan/grammar/layer/layer.py</code> <pre><code>def __init__(\n    self,\n    data: DataFrameLike | None = None,\n    *,\n    mark: Mark | None = None,\n    channels: list[Channel] | None = None,\n    transform: Transform | None = None,\n):\n    \"\"\"Constructor of Layer.\n\n    Args:\n        data (DataFrameLike | None, optional): The data component of\n            the layer.\n        mark (Mark|None, optional): The mark component of the layer.\n        channels (list[Channel], optional): The channels of the layer.\n        transform (Transform, optional): The transform component of the layer.\n\n    Returns:\n        (Layer): The constructed layer object.\n    \"\"\"\n    self._spec = LayerSpec()\n    self._children = []\n\n    if data is not None:\n        self.data(data, in_place=True)\n    if mark is not None:\n        self.mark(mark, in_place=True)\n    if transform is not None:\n        self.transform(transform, in_place=True)\n    if channels is not None:\n        self._spec.channels = channels\n</code></pre>"},{"location":"api/layer/#hakowan.grammar.layer.layer.Layer.channel","title":"<code>channel(*, position=None, normal=None, size=None, shape=None, vector_field=None, covariance=None, material=None, bump_map=None, normal_map=None, in_place=False)</code>","text":"<p>Overwrite a channel component of this layer.</p> <p>Parameters:</p> Name Type Description Default <code>position</code> <code>Position | str</code> <p>The new position channel.</p> <code>None</code> <code>normal</code> <code>Normal | str</code> <p>The new normal channel.</p> <code>None</code> <code>size</code> <code>float | str | Size</code> <p>The new size channel.</p> <code>None</code> <code>vector_field</code> <code>VectorField | str</code> <p>The new vector field channel.</p> <code>None</code> <code>material</code> <code>Material</code> <p>The new material channel.</p> <code>None</code> <code>bump_map</code> <code>BumpMap | TextureLike</code> <p>The new bump map channel.</p> <code>None</code> <code>normal_map</code> <code>NormalMap | TextureLike</code> <p>The new normal map channel.</p> <code>None</code> <code>in_place</code> <code>bool</code> <p>Whether to modify the current layer in place or create new layer. Defaults to False (i.e. create a new layer).</p> <code>False</code> <p>Returns:</p> Name Type Description <code>result</code> <code>Layer</code> <p>The layer object with the channel component overwritten.</p> Source code in <code>hakowan/grammar/layer/layer.py</code> <pre><code>def channel(\n    self,\n    *,\n    position: Position | str | None = None,\n    normal: Normal | str | None = None,\n    size: float | str | Size | None = None,\n    shape: str | Shape | None = None,\n    vector_field: VectorField | str | None = None,\n    covariance: Covariance | str | None = None,\n    material: Material | None = None,\n    bump_map: BumpMap | TextureLike | None = None,\n    normal_map: NormalMap | TextureLike | None = None,\n    in_place: bool = False,\n) -&gt; \"Layer\":\n    \"\"\"Overwrite a channel component of this layer.\n\n    Args:\n        position (Position | str, optional): The new position channel.\n        normal (Normal | str, optional): The new normal channel.\n        size (float | str | Size, optional): The new size channel.\n        vector_field (VectorField | str, optional): The new vector field channel.\n        material (Material, optional): The new material channel.\n        bump_map (BumpMap | TextureLike, optional): The new bump map channel.\n        normal_map (NormalMap | TextureLike, optional): The new normal map channel.\n        in_place (bool, optional): Whether to modify the current layer in place or create new\n            layer. Defaults to False (i.e. create a new layer).\n\n    Returns:\n        result (Layer): The layer object with the channel component overwritten.\n    \"\"\"\n    l = self.__get_working_layer(in_place)\n\n    convert = (\n        lambda value, cls: cls(data=Attribute(name=value))\n        if isinstance(value, str)\n        else value\n    )\n    if position is not None:\n        assert isinstance(position, (Position, str)), (\n            f\"Unsupported position type: {type(position)}!\"\n        )\n        l._spec.channels.append(convert(position, Position))\n    if normal is not None:\n        assert isinstance(normal, (Normal, str)), (\n            f\"Unsupported normal type: {type(normal)}!\"\n        )\n        l._spec.channels.append(convert(normal, Normal))\n    if size is not None:\n        if isinstance(size, (int, float)):\n            l._spec.channels.append(Size(data=float(size)))\n        else:\n            assert isinstance(size, (Size, str)), (\n                f\"Unsupported size type: {type(size)}!\"\n            )\n            l._spec.channels.append(convert(size, Size))\n    if shape is not None:\n        if isinstance(shape, str):\n            l._spec.channels.append(Shape(base_shape=shape))\n        else:\n            assert isinstance(shape, Shape), (\n                f\"Unsupported shape type: {type(shape)}!\"\n            )\n            l._spec.channels.append(shape)\n    if vector_field is not None:\n        assert isinstance(vector_field, (VectorField, str)), (\n            f\"Unsupported vector_field type: {type(vector_field)}!\"\n        )\n        l._spec.channels.append(convert(vector_field, VectorField))\n    if covariance is not None:\n        assert isinstance(covariance, (Covariance, str)), (\n            f\"Unsupported covariance type: {type(covariance)}!\"\n        )\n        l._spec.channels.append(convert(covariance, Covariance))\n    if material is not None:\n        l._spec.channels.append(material)\n    if bump_map is not None:\n        if isinstance(bump_map, BumpMap):\n            l._spec.channels.append(bump_map)\n        else:\n            l._spec.channels.append(BumpMap(bump_map))\n    if normal_map is not None:\n        if isinstance(normal_map, NormalMap):\n            l._spec.channels.append(normal_map)\n        else:\n            l._spec.channels.append(NormalMap(normal_map))\n    return l\n</code></pre>"},{"location":"api/layer/#hakowan.grammar.layer.layer.Layer.data","title":"<code>data(data, *, roi_box=None, in_place=False)</code>","text":"<p>Overwrite the data component of this layer.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrameLike</code> <p>The new data component.</p> required <code>roi_box</code> <code>ArrayLike</code> <p>The region of interest box of the data.</p> <code>None</code> <code>in_place</code> <code>bool</code> <p>Whether to modify the current layer in place or create new layer. Defaults to False (i.e. create a new layer).</p> <code>False</code> <p>Returns:</p> Name Type Description <code>result</code> <code>Layer</code> <p>The layer object with data component overwritten.</p> Source code in <code>hakowan/grammar/layer/layer.py</code> <pre><code>def data(\n    self,\n    data: DataFrameLike,\n    *,\n    roi_box: npt.ArrayLike | None = None,\n    in_place: bool = False,\n) -&gt; \"Layer\":\n    \"\"\"Overwrite the data component of this layer.\n\n    Args:\n        data (DataFrameLike): The new data component.\n        roi_box (npt.ArrayLike, optional): The region of interest box of the data.\n        in_place (bool, optional): Whether to modify the current layer in place or create new\n            layer. Defaults to False (i.e. create a new layer).\n\n    Returns:\n        result (Layer): The layer object with data component overwritten.\n    \"\"\"\n    l = self.__get_working_layer(in_place)\n    match data:\n        case str() | Path():\n            mesh = lagrange.io.load_mesh(data, quiet=True, stitch_vertices=True)  # type: ignore\n            l._spec.data = DataFrame(mesh=mesh, roi_box=roi_box)\n        case lagrange.SurfaceMesh():\n            l._spec.data = DataFrame(mesh=data, roi_box=roi_box)\n        case DataFrame():\n            l._spec.data = data\n            if roi_box is not None:\n                l._spec.data.roi_box = roi_box\n        case _:\n            raise TypeError(f\"Unsupported data type: {type(data)}!\")\n    return l\n</code></pre>"},{"location":"api/layer/#hakowan.grammar.layer.layer.Layer.mark","title":"<code>mark(mark, *, in_place=False)</code>","text":"<p>Overwrite the mark component of this layer.</p> <p>Parameters:</p> Name Type Description Default <code>mark</code> <code>Mark | str</code> <p>The new mark component.</p> required <code>in_place</code> <code>bool</code> <p>Whether to modify the current layer in place or create new layer. Defaults to False (i.e. create a new layer).</p> <code>False</code> <p>Returns:</p> Name Type Description <code>result</code> <code>Layer</code> <p>The layer object with mark component overwritten.</p> Source code in <code>hakowan/grammar/layer/layer.py</code> <pre><code>def mark(self, mark: Mark | str, *, in_place: bool = False) -&gt; \"Layer\":\n    \"\"\"Overwrite the mark component of this layer.\n\n    Args:\n        mark (Mark | str): The new mark component.\n        in_place (bool, optional): Whether to modify the current layer in place or create new\n            layer. Defaults to False (i.e. create a new layer).\n\n    Returns:\n        result (Layer): The layer object with mark component overwritten.\n    \"\"\"\n    l = self.__get_working_layer(in_place)\n    match mark:\n        case Mark():\n            l._spec.mark = mark\n        case \"point\" | \"Point\" | \"POINT\":\n            l._spec.mark = Mark.Point\n        case \"curve\" | \"Curve\" | \"CURVE\":\n            l._spec.mark = Mark.Curve\n        case \"surface\" | \"Surface\" | \"SURFACE\":\n            l._spec.mark = Mark.Surface\n        case _:\n            raise ValueError(f\"Unsupported mark type: {mark}!\")\n    return l\n</code></pre>"},{"location":"api/layer/#hakowan.grammar.layer.layer.Layer.material","title":"<code>material(type, *args, in_place=False, **kwargs)</code>","text":"<p>Overwrite material for this layer.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>str</code> <p>The material type.</p> required <code>in_place</code> <code>bool</code> <p>Whether to modify the current layer in place or create new layer. Defaults to False (i.e. create a new layer).</p> <code>False</code> <code>*args</code> <p>Variable length argument list that will be forwarded to material constructor.</p> <code>()</code> <code>**kwargs</code> <p>Arbitrary keyword arguments that will be forwarded to material constructor.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>result</code> <code>Layer</code> <p>The layer object with the channel component overwritten.</p> Source code in <code>hakowan/grammar/layer/layer.py</code> <pre><code>def material(self, type: str, *args, in_place: bool = False, **kwargs) -&gt; \"Layer\":\n    \"\"\"Overwrite material for this layer.\n\n    Args:\n        type (str): The material type.\n        in_place (bool, optional): Whether to modify the current layer in place or create new\n            layer. Defaults to False (i.e. create a new layer).\n        *args: Variable length argument list that will be forwarded to material constructor.\n        **kwargs: Arbitrary keyword arguments that will be forwarded to material constructor.\n\n    Returns:\n        result (Layer): The layer object with the channel component overwritten.\n    \"\"\"\n    l = self.__get_working_layer(in_place)\n    match type:\n        case \"diffuse\" | \"Diffuse\" | \"DIFFUSE\":\n            l._spec.channels.append(Diffuse(*args, **kwargs))\n        case \"conductor\" | \"Conductor\" | \"CONDUCTOR\":\n            l._spec.channels.append(Conductor(*args, **kwargs))\n        case \"rough_conductor\" | \"RoughConductor\" | \"ROUGH_CONDUCTOR\":\n            l._spec.channels.append(RoughConductor(*args, **kwargs))\n        case \"plastic\" | \"Plastic\" | \"PLASTIC\":\n            l._spec.channels.append(Plastic(*args, **kwargs))\n        case \"rough_plastic\" | \"RoughPlastic\" | \"ROUGH_PLASTIC\":\n            l._spec.channels.append(RoughPlastic(*args, **kwargs))\n        case \"principled\" | \"Principled\" | \"PRINCIPLED\":\n            l._spec.channels.append(Principled(*args, **kwargs))\n        case \"thin_principled\" | \"ThinPrincipled\" | \"THIN_PRINCIPLED\":\n            l._spec.channels.append(ThinPrincipled(*args, **kwargs))\n        case \"dielectric\" | \"Dielectric\" | \"DIELECTRIC\":\n            l._spec.channels.append(Dielectric(*args, **kwargs))\n        case \"thin_dielectric\" | \"ThinDielectric\" | \"THIN_DIELECTRIC\":\n            l._spec.channels.append(ThinDielectric(*args, **kwargs))\n        case \"rough_dielectric\" | \"RoughDielectric\" | \"ROUGH_DIELECTRIC\":\n            l._spec.channels.append(RoughDielectric(*args, **kwargs))\n        case \"hair\" | \"Hair\" | \"HAIR\":\n            l._spec.channels.append(Hair(*args, **kwargs))\n        case _:\n            raise ValueError(f\"Unsupported material type: {type}!\")\n    return l\n</code></pre>"},{"location":"api/layer/#hakowan.grammar.layer.layer.Layer.rotate","title":"<code>rotate(axis, angle, in_place=False)</code>","text":"<p>Update the transform component of the current layer by applying a rotation.</p> <p>Parameters:</p> Name Type Description Default <code>axis</code> <code>ArrayLike</code> <p>The unit rotation axis.</p> required <code>angle</code> <code>float</code> <p>The rotation angle (in radians).</p> required <code>in_place</code> <code>bool</code> <p>Whether to modify the current layer in place or create new layer. Defaults to False (i.e. create a new layer).</p> <code>False</code> <p>Returns:</p> Name Type Description <code>result</code> <code>Layer</code> <p>The layer object with transform component updated.</p> Source code in <code>hakowan/grammar/layer/layer.py</code> <pre><code>def rotate(\n    self, axis: npt.ArrayLike, angle: float, in_place: bool = False\n) -&gt; \"Layer\":\n    \"\"\"Update the transform component of the current layer by applying a rotation.\n\n    Args:\n        axis (npt.ArrayLike): The unit rotation axis.\n        angle (float): The rotation angle (in radians).\n        in_place (bool, optional): Whether to modify the current layer in place or create new\n            layer. Defaults to False (i.e. create a new layer).\n\n    Returns:\n        result (Layer): The layer object with transform component updated.\n    \"\"\"\n    l = self.__get_working_layer(in_place)\n    v = np.array(axis, dtype=np.float64)\n    I = np.eye(3)\n    H = np.outer(v, v)\n    S = np.cross(I, v)\n    M = I * np.cos(angle) + S * np.sin(angle) + H * (1 - np.cos(angle))\n    if l._spec.transform is None:\n        l._spec.transform = Affine(M)\n    else:\n        l._spec.transform *= Affine(M)\n    return l\n</code></pre>"},{"location":"api/layer/#hakowan.grammar.layer.layer.Layer.scale","title":"<code>scale(factor, in_place=False)</code>","text":"<p>Update the transform component of the current layer by applying uniform scaling.</p> <p>Parameters:</p> Name Type Description Default <code>factor</code> <code>float</code> <p>The scaling factor.</p> required <code>in_place</code> <code>bool</code> <p>Whether to modify the current layer in place or create new layer. Defaults to False (i.e. create a new layer).</p> <code>False</code> <p>Returns:</p> Name Type Description <code>result</code> <code>Layer</code> <p>The layer object with transform component updated.</p> Source code in <code>hakowan/grammar/layer/layer.py</code> <pre><code>def scale(self, factor: float, in_place: bool = False) -&gt; \"Layer\":\n    \"\"\"Update the transform component of the current layer by applying uniform scaling.\n\n    Args:\n        factor (float): The scaling factor.\n        in_place (bool, optional): Whether to modify the current layer in place or create new\n            layer. Defaults to False (i.e. create a new layer).\n\n    Returns:\n        result (Layer): The layer object with transform component updated.\n    \"\"\"\n    l = self.__get_working_layer(in_place)\n    M = np.eye(4)\n    M[0, 0] = M[1, 1] = M[2, 2] = factor\n    if l._spec.transform is None:\n        l._spec.transform = Affine(M)\n    else:\n        l._spec.transform *= Affine(M)\n    return l\n</code></pre>"},{"location":"api/layer/#hakowan.grammar.layer.layer.Layer.transform","title":"<code>transform(transform, *, in_place=False)</code>","text":"<p>Overwrite the transform component of this layer.</p> <p>Parameters:</p> Name Type Description Default <code>transform</code> <code>Transform</code> <p>The new transform component.</p> required <code>in_place</code> <code>bool</code> <p>Whether to modify the current layer in place or create new layer. Defaults to False (i.e. create a new layer).</p> <code>False</code> <p>Returns:</p> Name Type Description <code>result</code> <code>Layer</code> <p>The layer object with transform component overwritten.</p> Source code in <code>hakowan/grammar/layer/layer.py</code> <pre><code>def transform(self, transform: Transform, *, in_place: bool = False) -&gt; \"Layer\":\n    \"\"\"Overwrite the transform component of this layer.\n\n    Args:\n        transform (Transform): The new transform component.\n        in_place (bool, optional): Whether to modify the current layer in place or create new\n            layer. Defaults to False (i.e. create a new layer).\n\n    Returns:\n        result (Layer): The layer object with transform component overwritten.\n    \"\"\"\n    l = self.__get_working_layer(in_place)\n    l._spec.transform = transform\n    return l\n</code></pre>"},{"location":"api/layer/#hakowan.grammar.layer.layer.Layer.translate","title":"<code>translate(offset, in_place=False)</code>","text":"<p>Update the transform component of the current layer by applying a translation.</p> <p>Parameters:</p> Name Type Description Default <code>offset</code> <code>ArrayLike</code> <p>The translation offset.</p> required <code>in_place</code> <code>bool</code> <p>Whether to modify the current layer in place or create new layer. Defaults to False (i.e. create a new layer).</p> <code>False</code> <p>Returns:</p> Name Type Description <code>result</code> <code>Layer</code> <p>The layer object with transform component updated.</p> Source code in <code>hakowan/grammar/layer/layer.py</code> <pre><code>def translate(self, offset: npt.ArrayLike, in_place: bool = False) -&gt; \"Layer\":\n    \"\"\"Update the transform component of the current layer by applying a translation.\n\n    Args:\n        offset (npt.ArrayLike): The translation offset.\n        in_place (bool, optional): Whether to modify the current layer in place or create new\n            layer. Defaults to False (i.e. create a new layer).\n\n    Returns:\n        result (Layer): The layer object with transform component updated.\n    \"\"\"\n    l = self.__get_working_layer(in_place)\n    M = np.eye(4)\n    M[:3, 3] = np.array(offset, dtype=np.float64)\n\n    if l._spec.transform is None:\n        l._spec.transform = Affine(M)\n    else:\n        l._spec.transform *= Affine(M)\n    return l\n</code></pre>"},{"location":"api/mark/","title":"Mark","text":"<p>This page contains classes defined in <code>hakowan.mark</code> module.</p>"},{"location":"api/mark/#hakowan.grammar.mark.mark.Curve","title":"<code>Curve = Mark.Curve</code>  <code>module-attribute</code>","text":"<p>Curve is a mark for visualizing data as a curve.</p>"},{"location":"api/mark/#hakowan.grammar.mark.mark.Point","title":"<code>Point = Mark.Point</code>  <code>module-attribute</code>","text":"<p>Point is a mark for visualizing data as a point.</p>"},{"location":"api/mark/#hakowan.grammar.mark.mark.Surface","title":"<code>Surface = Mark.Surface</code>  <code>module-attribute</code>","text":"<p>Surface is a mark for visualizing data as a surface.</p>"},{"location":"api/mark/#hakowan.grammar.mark.mark.Mark","title":"<code>Mark</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Mark represents the way data is visualized.</p> Source code in <code>hakowan/grammar/mark/mark.py</code> <pre><code>class Mark(Enum):\n    \"\"\"Mark represents the way data is visualized.\"\"\"\n\n    Point = 0\n    Curve = 1\n    Surface = 2\n</code></pre>"},{"location":"api/material/","title":"Material","text":"<p>This page contains classes defined in <code>hakowan.material</code> module.</p>"},{"location":"api/material/#hakowan.grammar.channel.material.material.Material","title":"<code>Material</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Channel</code></p> <p>Material base class.</p> <p>Attributes:</p> Name Type Description <code>two_sided</code> <code>bool</code> <p>Whether to render both sides of the surface (default: False).</p> Source code in <code>hakowan/grammar/channel/material/material.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Material(Channel):\n    \"\"\"Material base class.\n\n    Attributes:\n        two_sided: Whether to render both sides of the surface (default: False).\n    \"\"\"\n\n    two_sided: bool = False\n</code></pre>"},{"location":"api/material/#hakowan.grammar.channel.material.material.Diffuse","title":"<code>Diffuse</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Material</code></p> <p>Diffuse material.</p> <p>Attributes:</p> Name Type Description <code>reflectance</code> <code>TextureLike</code> <p>Diffuse reflectance (i.e. base color) texture (default: 0.5).</p> Source code in <code>hakowan/grammar/channel/material/material.py</code> <pre><code>@dataclass(slots=True)\nclass Diffuse(Material):\n    \"\"\"Diffuse material.\n\n    Attributes:\n        reflectance: Diffuse reflectance (i.e. base color) texture (default: 0.5).\n    \"\"\"\n\n    reflectance: TextureLike = 0.5\n</code></pre>"},{"location":"api/material/#hakowan.grammar.channel.material.material.Conductor","title":"<code>Conductor</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Material</code></p> <p>Conductor material.</p> <p>Attributes:</p> Name Type Description <code>material</code> <code>str</code> <p>Conductor material name based on Mitsuba preset.</p> Source code in <code>hakowan/grammar/channel/material/material.py</code> <pre><code>@dataclass(slots=True)\nclass Conductor(Material):\n    \"\"\"Conductor material.\n\n    Attributes:\n        material: Conductor material name based on [Mitsuba preset](https://mitsuba.readthedocs.io/en/stable/src/generated/plugins_bsdfs.html#conductor-ior-list).\n    \"\"\"\n\n    material: str\n</code></pre>"},{"location":"api/material/#hakowan.grammar.channel.material.material.RoughConductor","title":"<code>RoughConductor</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Conductor</code></p> <p>Rough conductor material.</p> <p>Attributes:</p> Name Type Description <code>distribution</code> <code>str</code> <p>Microfacet distribution (default: \"beckmann\").</p> <code>alpha</code> <code>Texture | float</code> <p>Roughness value (default: 0.1).</p> Source code in <code>hakowan/grammar/channel/material/material.py</code> <pre><code>@dataclass(slots=True)\nclass RoughConductor(Conductor):\n    \"\"\"Rough conductor material.\n\n    Attributes:\n        distribution: Microfacet distribution (default: \"beckmann\").\n        alpha: Roughness value (default: 0.1).\n    \"\"\"\n\n    distribution: str = \"beckmann\"\n    alpha: Texture | float = 0.1\n</code></pre>"},{"location":"api/material/#hakowan.grammar.channel.material.material.Plastic","title":"<code>Plastic</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Material</code></p> <p>Plastic material.</p> <p>Attributes:</p> Name Type Description <code>diffuse_reflectance</code> <code>TextureLike</code> <p>Diffuse reflectance (i.e. base color) texture (default: 0.5).</p> <code>specular_reflectance</code> <code>Texture | float</code> <p>Specular reflectance texture (default: 1.0).</p> Source code in <code>hakowan/grammar/channel/material/material.py</code> <pre><code>@dataclass(slots=True)\nclass Plastic(Material):\n    \"\"\"Plastic material.\n\n    Attributes:\n        diffuse_reflectance: Diffuse reflectance (i.e. base color) texture (default: 0.5).\n        specular_reflectance: Specular reflectance texture (default: 1.0).\n    \"\"\"\n\n    diffuse_reflectance: TextureLike = 0.5\n    specular_reflectance: Texture | float = 1.0\n</code></pre>"},{"location":"api/material/#hakowan.grammar.channel.material.material.RoughPlastic","title":"<code>RoughPlastic</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Plastic</code></p> <p>Rough plastic material.</p> <p>Attributes:</p> Name Type Description <code>distribution</code> <code>str</code> <p>Microfacet distribution (default: \"beckmann\").</p> <code>alpha</code> <code>float</code> <p>Roughness value (default: 0.1).</p> Source code in <code>hakowan/grammar/channel/material/material.py</code> <pre><code>@dataclass(slots=True)\nclass RoughPlastic(Plastic):\n    \"\"\"Rough plastic material.\n\n    Attributes:\n        distribution: Microfacet distribution (default: \"beckmann\").\n        alpha: Roughness value (default: 0.1).\n    \"\"\"\n\n    distribution: str = \"beckmann\"\n    alpha: float = 0.1\n</code></pre>"},{"location":"api/material/#hakowan.grammar.channel.material.material.Principled","title":"<code>Principled</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Material</code></p> <p>Principled material.</p> <p>Attributes:</p> Name Type Description <code>color</code> <code>TextureLike</code> <p>Base color texture (default: 0.5).</p> <code>roughness</code> <code>Texture | float</code> <p>Roughness texture (default: 0.5).</p> <code>metallic</code> <code>Texture | float</code> <p>Metallic texture (default: 0.0).</p> Source code in <code>hakowan/grammar/channel/material/material.py</code> <pre><code>@dataclass(slots=True)\nclass Principled(Material):\n    \"\"\"Principled material.\n\n    Attributes:\n        color: Base color texture (default: 0.5).\n        roughness: Roughness texture (default: 0.5).\n        metallic: Metallic texture (default: 0.0).\n    \"\"\"\n\n    color: TextureLike = 0.5\n    roughness: Texture | float = 0.5\n    metallic: Texture | float = 0.0\n    anisotropic: float = 0.0\n    spec_trans: float = 0.0\n    eta: float = 1.5\n    spec_tint: float = 0.0\n    sheen: float = 0.0\n    sheen_tint: float = 0.0\n    flatness: float = 0.0\n</code></pre>"},{"location":"api/material/#hakowan.grammar.channel.material.material.ThinPrincipled","title":"<code>ThinPrincipled</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Principled</code></p> <p>Thin Principled material.</p> Source code in <code>hakowan/grammar/channel/material/material.py</code> <pre><code>@dataclass(slots=True)\nclass ThinPrincipled(Principled):\n    \"\"\"Thin Principled material.\"\"\"\n\n    diff_trans: float = 0.0\n</code></pre>"},{"location":"api/material/#hakowan.grammar.channel.material.material.Dielectric","title":"<code>Dielectric</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Material</code></p> <p>Dielectric material.</p> <p>Attributes:</p> Name Type Description <code>int_ior</code> <code>str | float</code> <p>Interior index of refraction (default: \"bk7\").</p> <code>ext_ior</code> <code>str | float</code> <p>Exterior index of refraction (default: \"air\").</p> <code>medium</code> <code>Medium | None</code> <p>Medium (default: None).</p> <code>specular_reflectance</code> <code>float</code> <p>Specular reflectance texture (default: 1.0).</p> Source code in <code>hakowan/grammar/channel/material/material.py</code> <pre><code>@dataclass(slots=True)\nclass Dielectric(Material):\n    \"\"\"Dielectric material.\n\n    Attributes:\n        int_ior: Interior index of refraction (default: \"bk7\").\n        ext_ior: Exterior index of refraction (default: \"air\").\n        medium: Medium (default: None).\n        specular_reflectance: Specular reflectance texture (default: 1.0).\n    \"\"\"\n\n    int_ior: str | float = \"bk7\"\n    ext_ior: str | float = \"air\"\n    medium: Medium | None = None\n    specular_reflectance: float = 1.0\n    specular_transmittance: float = 1.0\n</code></pre>"},{"location":"api/material/#hakowan.grammar.channel.material.material.ThinDielectric","title":"<code>ThinDielectric</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Dielectric</code></p> <p>Thin dielectric material.</p> Source code in <code>hakowan/grammar/channel/material/material.py</code> <pre><code>@dataclass(slots=True)\nclass ThinDielectric(Dielectric):\n    \"\"\"Thin dielectric material.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/material/#hakowan.grammar.channel.material.material.RoughDielectric","title":"<code>RoughDielectric</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Dielectric</code></p> <p>Rough dielectric material.</p> <p>Attributes:</p> Name Type Description <code>distribution</code> <code>str</code> <p>Microfacet distribution (default: \"beckmann\").</p> <code>alpha</code> <code>Texture | float</code> <p>Roughness value (default: 0.1).</p> Source code in <code>hakowan/grammar/channel/material/material.py</code> <pre><code>@dataclass(slots=True)\nclass RoughDielectric(Dielectric):\n    \"\"\"Rough dielectric material.\n\n    Attributes:\n        distribution: Microfacet distribution (default: \"beckmann\").\n        alpha: Roughness value (default: 0.1).\n    \"\"\"\n\n    distribution: str = \"beckmann\"\n    alpha: Texture | float = 0.1\n</code></pre>"},{"location":"api/material/#hakowan.grammar.channel.material.material.Hair","title":"<code>Hair</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Material</code></p> <p>Hair material.</p> <p>Attributes:</p> Name Type Description <code>eumelanin</code> <code>float</code> <p>Eumelanin (dark/brown pigment) concentration (default: 1.3).</p> <code>pheomelanin</code> <code>float</code> <p>Pheomelanin (reddish-yellow pigment) concentration (default: 0.2).</p> Source code in <code>hakowan/grammar/channel/material/material.py</code> <pre><code>@dataclass(slots=True)\nclass Hair(Material):\n    \"\"\"Hair material.\n\n    Attributes:\n        eumelanin: Eumelanin (dark/brown pigment) concentration (default: 1.3).\n        pheomelanin: Pheomelanin (reddish-yellow pigment) concentration (default: 0.2).\n    \"\"\"\n\n    eumelanin: float = 1.3\n    pheomelanin: float = 0.2\n</code></pre>"},{"location":"api/medium/","title":"Medium","text":""},{"location":"api/medium/#hakowan.grammar.channel.material.medium.Medium","title":"<code>Medium</code>  <code>dataclass</code>","text":"<p>Medium represents a volumetric material inside/outside of a shape.</p> <p>Attributes:</p> Name Type Description <code>albedo</code> <code>ColorLike) </code> <p>The albedo of the medium.</p> <code>scale</code> <code>float</code> <p>The scale of the medium.</p> Source code in <code>hakowan/grammar/channel/material/medium.py</code> <pre><code>@dataclass(slots=True)\nclass Medium:\n    \"\"\"Medium represents a volumetric material inside/outside of a shape.\n\n    Attributes:\n        albedo (ColorLike) : The albedo of the medium.\n        scale (float): The scale of the medium.\n    \"\"\"\n\n    albedo: ColorLike = 0.75\n    scale: float = 1.0\n</code></pre>"},{"location":"api/scale/","title":"Scale","text":"<p>This pages contains classes defined in <code>hakowan.scale</code> module.</p>"},{"location":"api/scale/#hakowan.grammar.scale.scale.ScaleLike","title":"<code>ScaleLike = float | Scale</code>  <code>module-attribute</code>","text":"<p>Type alias for scale-like objects.</p> <ul> <li>A scalar value will be converted to <code>Uniform</code> scale with the scalar value as the factor.</li> <li>A Scale object will be unchanged.</li> </ul>"},{"location":"api/scale/#hakowan.grammar.scale.scale.Affine","title":"<code>Affine</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Scale</code></p> <p>Scale the data using an affine transformation.</p> <p>Attributes:</p> Name Type Description <code>matrix</code> <code>NDArray</code> <p>The affine transformation matrix.</p> Source code in <code>hakowan/grammar/scale/scale.py</code> <pre><code>@dataclass(slots=True)\nclass Affine(Scale):\n    \"\"\"Scale the data using an affine transformation.\n\n    Attributes:\n        matrix: The affine transformation matrix.\n    \"\"\"\n\n    matrix: npt.NDArray\n</code></pre>"},{"location":"api/scale/#hakowan.grammar.scale.scale.Clip","title":"<code>Clip</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Scale</code></p> <p>Clip the data to the range [min, max].</p> <p>Attributes:</p> Name Type Description <code>domain</code> <code>tuple[float, float]</code> <p>The clip minimum and maximum values.</p> Source code in <code>hakowan/grammar/scale/scale.py</code> <pre><code>@dataclass(slots=True)\nclass Clip(Scale):\n    \"\"\"Clip the data to the range [min, max].\n\n    Attributes:\n        domain: The clip minimum and maximum values.\n    \"\"\"\n\n    domain: tuple[float, float]\n</code></pre>"},{"location":"api/scale/#hakowan.grammar.scale.scale.Custom","title":"<code>Custom</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Scale</code></p> <p>Scale the data using a custom function.</p> <p>Attributes:</p> Name Type Description <code>function</code> <code>Callable</code> <p>The scaling function. E.g. <code>lambda x: x ** 2</code> for squaring the data.</p> Source code in <code>hakowan/grammar/scale/scale.py</code> <pre><code>@dataclass(slots=True)\nclass Custom(Scale):\n    \"\"\"Scale the data using a custom function.\n\n    Attributes:\n        function: The scaling function. E.g. `lambda x: x ** 2` for squaring the data.\n    \"\"\"\n\n    function: Callable\n</code></pre>"},{"location":"api/scale/#hakowan.grammar.scale.scale.Log","title":"<code>Log</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Scale</code></p> <p>Logarithmic scale.</p> <p>Attributes:</p> Name Type Description <code>base</code> <code>float</code> <p>The base of the logarithm.</p> Source code in <code>hakowan/grammar/scale/scale.py</code> <pre><code>@dataclass(slots=True)\nclass Log(Scale):\n    \"\"\"Logarithmic scale.\n\n    Attributes:\n        base: The base of the logarithm.\n    \"\"\"\n\n    base: float = 10.0\n</code></pre>"},{"location":"api/scale/#hakowan.grammar.scale.scale.Normalize","title":"<code>Normalize</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Scale</code></p> <p>Normalize the data so that the box defined by <code>domain_min</code> and <code>domain_max</code> is scaled to the box defined by <code>range_min</code> and <code>range_max</code>.</p> <p>Attributes:</p> Name Type Description <code>range_min</code> <code>ArrayLike</code> <p>The minimum value of the output range.</p> <code>range_max</code> <code>ArrayLike</code> <p>The maximum value of the output range.</p> <code>domain_min</code> <code>ArrayLike | None</code> <p>The minimum value of the input range. If not specified, the minimum value of the input data will be used.</p> <code>domain_max</code> <code>ArrayLike | None</code> <p>The maximum value of the input range. If not specified, the maximum value of the input data will be used.</p> Source code in <code>hakowan/grammar/scale/scale.py</code> <pre><code>@dataclass(slots=True)\nclass Normalize(Scale):\n    \"\"\"Normalize the data so that the box defined by `domain_min` and `domain_max` is scaled to the box\n    defined by `range_min` and `range_max`.\n\n    Attributes:\n        range_min: The minimum value of the output range.\n        range_max: The maximum value of the output range.\n        domain_min: The minimum value of the input range. If not specified, the minimum value of the\n            input data will be used.\n        domain_max: The maximum value of the input range. If not specified, the maximum value of the\n            input data will be used.\n    \"\"\"\n\n    range_min: npt.ArrayLike\n    range_max: npt.ArrayLike\n    domain_min: npt.ArrayLike | None = None\n    domain_max: npt.ArrayLike | None = None\n</code></pre>"},{"location":"api/scale/#hakowan.grammar.scale.scale.Scale","title":"<code>Scale</code>  <code>dataclass</code>","text":"<p>Base class for all scales.</p> Source code in <code>hakowan/grammar/scale/scale.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Scale:\n    \"\"\"Base class for all scales.\"\"\"\n\n    _child: Optional[\"Scale\"] = None\n\n    def __imul__(self, other: \"Scale\") -&gt; \"Scale\":\n        \"\"\"Combine the current scale with the `other` scale in place. The current scale will be applied\n        before the `other` scale.\n        \"\"\"\n        s = self\n        while s._child is not None:\n            s = s._child\n        s._child = other\n        return self\n\n    def __mul__(self, other: \"Scale\") -&gt; \"Scale\":\n        \"\"\"Combine the current scale with the `other` scale in a new scale. Both the current and\n        the `other` scale is not modified. In the new scale, the current scale will be applied\n        before the `other` scale.\n        \"\"\"\n        r = copy.deepcopy(self)\n        r *= other\n        return r\n</code></pre>"},{"location":"api/scale/#hakowan.grammar.scale.scale.Scale.__imul__","title":"<code>__imul__(other)</code>","text":"<p>Combine the current scale with the <code>other</code> scale in place. The current scale will be applied before the <code>other</code> scale.</p> Source code in <code>hakowan/grammar/scale/scale.py</code> <pre><code>def __imul__(self, other: \"Scale\") -&gt; \"Scale\":\n    \"\"\"Combine the current scale with the `other` scale in place. The current scale will be applied\n    before the `other` scale.\n    \"\"\"\n    s = self\n    while s._child is not None:\n        s = s._child\n    s._child = other\n    return self\n</code></pre>"},{"location":"api/scale/#hakowan.grammar.scale.scale.Scale.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Combine the current scale with the <code>other</code> scale in a new scale. Both the current and the <code>other</code> scale is not modified. In the new scale, the current scale will be applied before the <code>other</code> scale.</p> Source code in <code>hakowan/grammar/scale/scale.py</code> <pre><code>def __mul__(self, other: \"Scale\") -&gt; \"Scale\":\n    \"\"\"Combine the current scale with the `other` scale in a new scale. Both the current and\n    the `other` scale is not modified. In the new scale, the current scale will be applied\n    before the `other` scale.\n    \"\"\"\n    r = copy.deepcopy(self)\n    r *= other\n    return r\n</code></pre>"},{"location":"api/scale/#hakowan.grammar.scale.scale.Uniform","title":"<code>Uniform</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Scale</code></p> <p>Scale the data uniformly by multiplying it with a factor.</p> <p>Attributes:</p> Name Type Description <code>factor</code> <code>float</code> <p>The scaling factor.</p> Source code in <code>hakowan/grammar/scale/scale.py</code> <pre><code>@dataclass(slots=True)\nclass Uniform(Scale):\n    \"\"\"Scale the data uniformly by multiplying it with a factor.\n\n    Attributes:\n        factor: The scaling factor.\n    \"\"\"\n\n    factor: float\n</code></pre>"},{"location":"api/scale/#hakowan.grammar.scale.offset.Offset","title":"<code>Offset</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Scale</code></p> <p>Offset the data by a constant.</p> <p>Attributes:</p> Name Type Description <code>offset</code> <code>Attribute</code> <p>The offset to apply to the data.</p> Source code in <code>hakowan/grammar/scale/offset.py</code> <pre><code>@dataclass(slots=True)\nclass Offset(Scale):\n    \"\"\"Offset the data by a constant.\n\n    Attributes:\n        offset (Attribute): The offset to apply to the data.\n    \"\"\"\n\n    offset: Attribute\n</code></pre>"},{"location":"api/texture/","title":"Texture","text":"<p>This page contains types/classes defined in <code>hakowan.texture</code> module.</p>"},{"location":"api/texture/#hakowan.grammar.texture.texture.TextureLike","title":"<code>TextureLike = ColorLike | Texture</code>  <code>module-attribute</code>","text":"<p>TextureLike is a type alias for a texture or color.</p>"},{"location":"api/texture/#hakowan.grammar.texture.texture.Texture","title":"<code>Texture</code>  <code>dataclass</code>","text":"<p>Texture provides the mapping from raw data to visual properties such as color.</p> Source code in <code>hakowan/grammar/texture/texture.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Texture:\n    \"\"\"Texture provides the mapping from raw data to visual properties such as color.\"\"\"\n\n    _uv: Attribute | None = None\n</code></pre>"},{"location":"api/texture/#hakowan.grammar.texture.texture.Uniform","title":"<code>Uniform</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Texture</code></p> <p>The uniform texture provides a constant color field.</p> <p>Attributes:</p> Name Type Description <code>color</code> <code>ColorLike</code> <p>The color of the uniform texture.</p> Source code in <code>hakowan/grammar/texture/texture.py</code> <pre><code>@dataclass(slots=True)\nclass Uniform(Texture):\n    \"\"\"The uniform texture provides a constant color field.\n\n    Attributes:\n        color (ColorLike): The color of the uniform texture.\n    \"\"\"\n\n    color: ColorLike\n</code></pre>"},{"location":"api/texture/#hakowan.grammar.texture.texture.Image","title":"<code>Image</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Texture</code></p> <p>The image texture uses a texture image to provide a color field.</p> <p>Attributes:</p> Name Type Description <code>filename</code> <code>PathLike</code> <p>The path to the texture image.</p> <code>uv</code> <code>AttributeLike</code> <p>The attribute to use as the texture coordinates.</p> <code>raw</code> <code>bool</code> <p>Whether to use the raw image data, i.e. use linear color transfer function. This should be set to True for normal maps.</p> Source code in <code>hakowan/grammar/texture/texture.py</code> <pre><code>@dataclass(slots=True)\nclass Image(Texture):\n    \"\"\"The image texture uses a texture image to provide a color field.\n\n    Attributes:\n        filename (PathLike): The path to the texture image.\n        uv (AttributeLike): The attribute to use as the texture coordinates.\n        raw (bool): Whether to use the raw image data, i.e. use linear color transfer function.\n            This should be set to True for normal maps.\n    \"\"\"\n\n    filename: PathLike\n    uv: AttributeLike | None = None\n    raw: bool = False\n</code></pre>"},{"location":"api/texture/#hakowan.grammar.texture.texture.Checkerboard","title":"<code>Checkerboard</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Texture</code></p> <p>The checkerboard texture provides a checkerboard color/value field.</p> <p>Attributes:</p> Name Type Description <code>uv</code> <code>AttributeLike</code> <p>The attribute to use as the texture coordinates.</p> <code>texture1</code> <code>TextureLike</code> <p>The texture to use for the first color/value.</p> <code>texture2</code> <code>TextureLike</code> <p>The texture to use for the second color/value.</p> <code>size</code> <code>int</code> <p>The size of the checkerboard (e.g. 8 means 8x8 checkerboard).</p> Source code in <code>hakowan/grammar/texture/texture.py</code> <pre><code>@dataclass(slots=True)\nclass Checkerboard(Texture):\n    \"\"\"The checkerboard texture provides a checkerboard color/value field.\n\n    Attributes:\n        uv (AttributeLike): The attribute to use as the texture coordinates.\n        texture1 (TextureLike): The texture to use for the first color/value.\n        texture2 (TextureLike): The texture to use for the second color/value.\n        size (int): The size of the checkerboard (e.g. 8 means 8x8 checkerboard).\n    \"\"\"\n\n    uv: AttributeLike | None = None\n    texture1: TextureLike = 0.8\n    texture2: TextureLike = 0.2\n    size: int = 8\n</code></pre>"},{"location":"api/texture/#hakowan.grammar.texture.texture.Isocontour","title":"<code>Isocontour</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Texture</code></p> <p>The isocontour texture provides a color/value field based on the isocontours of an attribute.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>AttributeLike</code> <p>The attribute used to generate the isocontours.</p> <code>ratio</code> <code>float</code> <p>The ratio of the isocontour thickness to non-isocontour thickness.</p> <code>texture1</code> <code>TextureLike</code> <p>The texture to use for the isocontour regions.</p> <code>texture2</code> <code>TextureLike</code> <p>The texture to use for the non-isocontour regions.</p> <code>num_contours</code> <code>int</code> <p>The number of isocontours to generate within a unit distance.</p> Source code in <code>hakowan/grammar/texture/texture.py</code> <pre><code>@dataclass(slots=True)\nclass Isocontour(Texture):\n    \"\"\"The isocontour texture provides a color/value field based on the isocontours of an attribute.\n\n    Attributes:\n        data (AttributeLike): The attribute used to generate the isocontours.\n        ratio (float): The ratio of the isocontour thickness to non-isocontour thickness.\n        texture1 (TextureLike): The texture to use for the isocontour regions.\n        texture2 (TextureLike): The texture to use for the non-isocontour regions.\n        num_contours (int): The number of isocontours to generate within a unit distance.\n    \"\"\"\n\n    data: AttributeLike\n    ratio: float = 0.1\n    texture1: TextureLike = 0.4\n    texture2: TextureLike = 0.2\n    num_contours: int = 8\n</code></pre>"},{"location":"api/texture/#hakowan.grammar.texture.texture.ScalarField","title":"<code>ScalarField</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Texture</code></p> <p>The scalar field texture converts an attribute to a either a value field or color field.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>AttributeLike</code> <p>The attribute to convert to a color field.</p> <code>colormap</code> <code>str | list[ColorLike]</code> <p>The name of the colormap to use or a list colors.</p> <code>domain</code> <code>tuple[float, float]</code> <p>The domain of the attribute to map to the colormap.</p> <code>range</code> <code>tuple[float, float]</code> <p>The range of the colormap to map the attribute to.</p> <code>categories</code> <code>bool</code> <p>Whether the attribute represents categorical data (i.e. discrete values).</p> Source code in <code>hakowan/grammar/texture/texture.py</code> <pre><code>@dataclass(slots=True)\nclass ScalarField(Texture):\n    \"\"\"The scalar field texture converts an attribute to a either a value field or color field.\n\n    Attributes:\n        data (AttributeLike): The attribute to convert to a color field.\n        colormap (str | list[ColorLike]): The name of the colormap to use or a list colors.\n        domain (tuple[float, float]): The domain of the attribute to map to the colormap.\n        range (tuple[float, float]): The range of the colormap to map the attribute to.\n        categories (bool): Whether the attribute represents categorical data (i.e. discrete values).\n    \"\"\"\n\n    data: AttributeLike\n    colormap: str | list[ColorLike] = \"viridis\"\n    domain: tuple[float, float] | None = None\n    range: tuple[float, float] | None = None\n    categories: bool = False\n</code></pre>"},{"location":"api/transform/","title":"Transform","text":"<p>This page contains classes defined in <code>hakowan.transform</code> module.</p>"},{"location":"api/transform/#hakowan.grammar.transform.transform.Transform","title":"<code>Transform</code>  <code>dataclass</code>","text":"<p>Transform is the base class of all transforms.</p> Source code in <code>hakowan/grammar/transform/transform.py</code> <pre><code>@dataclass(kw_only=True, slots=True)\nclass Transform:\n    \"\"\"Transform is the base class of all transforms.\"\"\"\n\n    _child: Optional[\"Transform\"] = None\n\n    def __imul__(self, other: \"Transform\") -&gt; \"Transform\":\n        \"\"\"In place update by applying another transform after the current transform.\n\n        Args:\n            other: The transform to apply after the current transform.\n        \"\"\"\n        # Because transform may be used in multiple places in the layer graph, and it may have a\n        # child in the future, it must be deep copied to avoid undesired side effects.\n        if self._child is None:\n            self._child = copy.deepcopy(other)\n        else:\n            t = self._child\n            while t._child is not None:\n                t = t._child\n            t._child = copy.deepcopy(other)\n        return self\n\n    def __mul__(self, other: \"Transform\") -&gt; \"Transform\":\n        \"\"\"Apply another transform, `other`, after the current transform.\n\n        Args:\n            other: The other transform.\n\n        Returns: A new transform that is the composition of the current transform and `other`.\n        \"\"\"\n        r = copy.deepcopy(self)\n        r *= other\n        return r\n</code></pre>"},{"location":"api/transform/#hakowan.grammar.transform.transform.Transform.__imul__","title":"<code>__imul__(other)</code>","text":"<p>In place update by applying another transform after the current transform.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Transform</code> <p>The transform to apply after the current transform.</p> required Source code in <code>hakowan/grammar/transform/transform.py</code> <pre><code>def __imul__(self, other: \"Transform\") -&gt; \"Transform\":\n    \"\"\"In place update by applying another transform after the current transform.\n\n    Args:\n        other: The transform to apply after the current transform.\n    \"\"\"\n    # Because transform may be used in multiple places in the layer graph, and it may have a\n    # child in the future, it must be deep copied to avoid undesired side effects.\n    if self._child is None:\n        self._child = copy.deepcopy(other)\n    else:\n        t = self._child\n        while t._child is not None:\n            t = t._child\n        t._child = copy.deepcopy(other)\n    return self\n</code></pre>"},{"location":"api/transform/#hakowan.grammar.transform.transform.Transform.__mul__","title":"<code>__mul__(other)</code>","text":"<p>Apply another transform, <code>other</code>, after the current transform.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Transform</code> <p>The other transform.</p> required <p>Returns: A new transform that is the composition of the current transform and <code>other</code>.</p> Source code in <code>hakowan/grammar/transform/transform.py</code> <pre><code>def __mul__(self, other: \"Transform\") -&gt; \"Transform\":\n    \"\"\"Apply another transform, `other`, after the current transform.\n\n    Args:\n        other: The other transform.\n\n    Returns: A new transform that is the composition of the current transform and `other`.\n    \"\"\"\n    r = copy.deepcopy(self)\n    r *= other\n    return r\n</code></pre>"},{"location":"api/transform/#hakowan.grammar.transform.transform.Filter","title":"<code>Filter</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Filter data based on a condition.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>AttributeLike | None</code> <p>The attribute to filter on. If None, the vertex position is used.</p> <code>condition</code> <code>Callable</code> <p>A callable that takes a single argument, the value of the attribute, and returns a boolean indicating whether the data should be kept.</p> Source code in <code>hakowan/grammar/transform/transform.py</code> <pre><code>@dataclass(slots=True)\nclass Filter(Transform):\n    \"\"\"Filter data based on a condition.\n\n    Attributes:\n        data: The attribute to filter on. If None, the vertex position is used.\n        condition: A callable that takes a single argument, the value of the attribute, and returns\n            a boolean indicating whether the data should be kept.\n    \"\"\"\n\n    data: AttributeLike | None = None\n    condition: Callable = field(default=_default_condition)\n</code></pre>"},{"location":"api/transform/#hakowan.grammar.transform.transform.UVMesh","title":"<code>UVMesh</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Extract UV mesh from data.</p> <p>Attributes:</p> Name Type Description <code>uv</code> <code>AttributeLike | None</code> <p>The attribute defining the UV coordinates. If None, automatically deetect the UV attribute from the data.</p> Source code in <code>hakowan/grammar/transform/transform.py</code> <pre><code>@dataclass(slots=True)\nclass UVMesh(Transform):\n    \"\"\"Extract UV mesh from data.\n\n    Attributes:\n        uv: The attribute defining the UV coordinates. If None, automatically deetect the UV\n            attribute from the data.\n    \"\"\"\n\n    uv: AttributeLike | None = None\n</code></pre>"},{"location":"api/transform/#hakowan.grammar.transform.transform.Affine","title":"<code>Affine</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Apply affine transformation to data.</p> <p>Attributes:</p> Name Type Description <code>matrix</code> <code>ArrayLike</code> <p>The 4x4 affine matrix to apply.</p> Source code in <code>hakowan/grammar/transform/transform.py</code> <pre><code>@dataclass(slots=True)\nclass Affine(Transform):\n    \"\"\"Apply affine transformation to data.\n\n    Attributes:\n        matrix: The 4x4 affine matrix to apply.\n    \"\"\"\n\n    matrix: npt.ArrayLike\n</code></pre>"},{"location":"api/transform/#hakowan.grammar.transform.transform.Compute","title":"<code>Compute</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Compute new attributes from the current data frame.</p> <p>Attributes:</p> Name Type Description <code>x</code> <code>str | None</code> <p>Extract the x coordinate as an attribute.</p> <code>y</code> <code>str | None</code> <p>Extract the y coordinate as an attribute.</p> <code>z</code> <code>str | None</code> <p>Extract the z coordinate as an attribute.</p> <code>normal</code> <code>str | None</code> <p>Compute the normal vector field as an attribute.</p> <code>vertex_normal</code> <code>str | None</code> <p>Compute the vertex normal vector field as an attribute.</p> <code>facet_normal</code> <code>str | None</code> <p>Compute the facet normal vector field as an attribute.</p> <code>component</code> <code>str | None</code> <p>Compute connected component ids.</p> Source code in <code>hakowan/grammar/transform/transform.py</code> <pre><code>@dataclass(slots=True, kw_only=True)\nclass Compute(Transform):\n    \"\"\"Compute new attributes from the current data frame.\n\n    Attributes:\n        x: Extract the x coordinate as an attribute.\n        y: Extract the y coordinate as an attribute.\n        z: Extract the z coordinate as an attribute.\n        normal: Compute the normal vector field as an attribute.\n        vertex_normal: Compute the vertex normal vector field as an attribute.\n        facet_normal: Compute the facet normal vector field as an attribute.\n        component: Compute connected component ids.\n    \"\"\"\n\n    x: str | None = None\n    y: str | None = None\n    z: str | None = None\n    normal: str | None = None\n    vertex_normal: str | None = None\n    facet_normal: str | None = None\n    component: str | None = None\n</code></pre>"},{"location":"api/transform/#hakowan.grammar.transform.transform.Explode","title":"<code>Explode</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Explode data into multiple pieces.</p> <p>Attributes:</p> Name Type Description <code>pieces</code> <code>AttributeLike</code> <p>The attribute defining the pieces.</p> <code>magnitude</code> <code>float</code> <p>The magnitude of the displacement.</p> Source code in <code>hakowan/grammar/transform/transform.py</code> <pre><code>@dataclass(slots=True)\nclass Explode(Transform):\n    \"\"\"Explode data into multiple pieces.\n\n    Attributes:\n        pieces: The attribute defining the pieces.\n        magnitude: The magnitude of the displacement.\n    \"\"\"\n\n    pieces: AttributeLike\n    magnitude: float = 1\n</code></pre>"},{"location":"api/transform/#hakowan.grammar.transform.transform.Norm","title":"<code>Norm</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Compute the row-wise norm of a given vector attribute.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>AttributeLike</code> <p>The vector attribute to compute the norm on.</p> <code>norm_attr_name</code> <code>str</code> <p>The name of the output norm attribute.</p> <code>order</code> <code>int</code> <p>The order of the norm. Default is 2, which is the L2 norm.</p> Source code in <code>hakowan/grammar/transform/transform.py</code> <pre><code>@dataclass(slots=True)\nclass Norm(Transform):\n    \"\"\"Compute the row-wise norm of a given vector attribute.\n\n    Attributes:\n        data: The vector attribute to compute the norm on.\n        norm_attr_name: The name of the output norm attribute.\n        order: The order of the norm. Default is 2, which is the L2 norm.\n    \"\"\"\n\n    data: AttributeLike\n    norm_attr_name: str\n    order: int = 2\n</code></pre>"},{"location":"api/transform/#hakowan.grammar.transform.transform.Boundary","title":"<code>Boundary</code>  <code>dataclass</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Compute the boundary of a mesh.</p> <p>Attributes:</p> Name Type Description <code>attributes</code> <code>list[str]</code> <p>The attributes to take into account when computing the boundary. i.e. discontinuities in these attributes will be considered as boundaries.</p> Source code in <code>hakowan/grammar/transform/transform.py</code> <pre><code>@dataclass(slots=True)\nclass Boundary(Transform):\n    \"\"\"Compute the boundary of a mesh.\n\n    Attributes:\n        attributes: The attributes to take into account when computing the boundary.\n            i.e. discontinuities in these attributes will be considered as boundaries.\n    \"\"\"\n\n    attributes: list[str] = field(default_factory=list)\n</code></pre>"},{"location":"examples/components/","title":"Components","text":"<p>This example illustrates the disconnected components of a given mesh.</p> <p> </p>"},{"location":"examples/components/#data","title":"Data","text":"<p>The data used in this example is from \"Anatomic Human Foot &amp; Lower Extremity Version 2.0\" designed by DrGlassDPM on on Thingiverse. The components can be computed via Lagrange:</p> <pre><code>mesh = lagrange.io.load_mesh(\"data/foot.msh\")\nlagrange.compute_components(mesh, output_attribute_name=\"comp\")\n</code></pre>"},{"location":"examples/components/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\nimport math\n\nbase = hkw.layer(\"data/foot.ply\")\nbase = base.material(\n    \"Principled\",\n    color=hkw.texture.ScalarField(\"comp\", colormap=\"set1\", categories=True),\n    roughness=0.2,\n).transform(hkw.transform.Compute(component=\"comp\"))\n\nfront_view = base.rotate(axis=[0, 1, 0], angle=math.pi)\ntop_view = base.rotate(axis=[1, 0, 0], angle=math.pi / 2)\nside_view = base.rotate(axis=[0, 1, 0], angle=math.pi / 2)\n\nconfig = hkw.config()\nconfig.sensor.location = [0, 0, 3.5]\n\nhkw.render(front_view, config, filename=\"results/foot_front.png\")\nhkw.render(top_view, config, filename=\"results/foot_top.png\")\nhkw.render(side_view, config, filename=\"results/foot_side.png\")\n</code></pre>"},{"location":"examples/deformation/","title":"Mesh deformation","text":"<p>This example aims to visualize the deformed surface that are k-harmonic with k=1,2,3 and 4. This example is inspired by figure 2 from the paper \"An Intuitive Framework for Real-Time Freeform Modeling\".</p> <p> </p>"},{"location":"examples/deformation/#data","title":"Data","text":"<p>The input cylinder is generate with Blender, and its deformed shapes are generated using the script deform.py.</p>"},{"location":"examples/deformation/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\n\n# Handle layer with rough plastic material.\nhandles = (\n    hkw.layer()\n    .material(\"RoughPlastic\", \"steelblue\")\n    .transform(hkw.transform.Filter(data=\"label\", condition=lambda x: x in [1, 2]))\n)\n\n# Deformed region with smooth conductor material.\ndeformed_region = (\n    hkw.layer()\n    .material(\"Conductor\", \"Hg\")\n    .transform(hkw.transform.Filter(data=\"label\", condition=lambda x: x == 0))\n)\n\n# Create four different layers with different inptu data.\nl1 = (handles + deformed_region).data(\"data/cylinder_1.msh\")\nl2 = (handles + deformed_region).data(\"data/cylinder_2.msh\")\nl3 = (handles + deformed_region).data(\"data/cylinder_3.msh\")\nl4 = (handles + deformed_region).data(\"data/cylinder_4.msh\")\n\n# Render the layers.\nconfig = hkw.config()\nconfig.z_up()\nconfig.sensor.location = (0, -3, 0)\nhkw.render(l1, config, filename=\"results/cylinder_1.png\")\nhkw.render(l2, config, filename=\"results/cylinder_2.png\")\nhkw.render(l3, config, filename=\"results/cylinder_3.png\")\nhkw.render(l4, config, filename=\"results/cylinder_4.png\")\n</code></pre>"},{"location":"examples/developable/","title":"Developability of Triangle Meshes","text":"<p>This example tries to replicte Figure 1 from the paper \"Developability of Triangle Meshes\".</p> <p> </p> <p> </p>"},{"location":"examples/developable/#data","title":"Data","text":"<p>The data used in this example is from the data released by the paper authors.</p>"},{"location":"examples/developable/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\n\nbase = (\n    hkw.layer()\n    .channel(normal=\"normal\")\n    .material(\n        \"Principled\", \"lightsteelblue\", roughness=0.5, metallic=0.8, two_sided=True\n    )\n    .transform(hkw.transform.Compute(facet_normal=\"normal\"))\n)\n\nl0 = base.data(\"data/mask_triangulated.obj\")\nl1 = base.data(\"data/mask_flow1.obj\")\nl2 = base.data(\"data/mask_flow2.obj\")\nl3 = base.data(\"data/mask_flow3.obj\")\n\nconfig = hkw.config()\nconfig.sensor.location = [-1.5, 0.8, 2.5]\n\nhkw.render(l0, config, filename=\"results/mask_0.png\")\nhkw.render(l1, config, filename=\"results/mask_1.png\")\nhkw.render(l2, config, filename=\"results/mask_2.png\")\nhkw.render(l3, config, filename=\"results/mask_3.png\")\n</code></pre>"},{"location":"examples/elevation/","title":"Topographic Map","text":"<p>This example aims to generate a 3D topographic map from elevation data provided by USGS.</p> <p> </p>"},{"location":"examples/elevation/#data","title":"Data","text":"<p>The input is height field image representing a tile of the US elevation map (N35 and W112) downloaded from USGS. It is converted to a dense quad mesh using this script.</p>"},{"location":"examples/elevation/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\nfrom image2mesh import image2mesh\n\n# Step 1: Generate a mesh from a heightmap.\nusgs_data = image2mesh(\"data/USGS_1_n35w112.tif\")\n\n# Step 2: Create a map layer that maps elevation to color.\n# Note that we use a custom colormap here.\nusgs_map = (\n    hkw.layer(usgs_data)\n    .material(\n        \"Principled\",\n        hkw.texture.ScalarField(\n            \"elevation\", colormap=[\"#15A887\", \"#8C4E37\", \"#E9ECF2\"]\n        ),\n    )\n    .transform(hkw.transform.Compute(z=\"elevation\"))\n)\n\n# Step 3: Render from two different angles.\nconfig = hkw.config()\nconfig.sensor.location = [0, 0, 3]\nhkw.render(usgs_map, config, filename=\"results/usgs_1_n35112.png\")\n\nconfig.sensor.location = [0, -2, 2]\nhkw.render(usgs_map, config, filename=\"results/usgs_1_n35112_side.png\")\n</code></pre>"},{"location":"examples/face/","title":"Face UV","text":"<p>This example visualizes the UV coordinates of a face model in two ways. The first way uses checkerboard texture to visualize UV. The second way visualize the UV mesh with the 3D normal field.</p> <p> </p>"},{"location":"examples/face/#data","title":"Data","text":"<p>The face mesh is the connonical face model released by Google as part of the MediaPipe project (Apache-2.0 license).</p>"},{"location":"examples/face/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\n\n# Step 1: Setup the configurtion for portrait.\nconfig = hkw.config()\nconfig.film.width = 800\nconfig.film.height = 1024\nconfig.sensor.location = [1.0, 0.5, 3]\n\n# Step 2: Render the 3D face mesh.\nface = hkw.layer(\"data/canonical_face_model.obj\")\nhkw.render(face, config, filename=\"results/face.png\")\n\n\n# Step 3: Render the 3D face mesh with checkerboard pattern.\nface_checkerboard = face.material(\n    \"Principled\",\n    color=hkw.texture.Checkerboard(size=8),\n    roughness=0.1,\n)\nhkw.render(face_checkerboard, config, filename=\"results/face_checkerboard.png\")\n\n# Step 4: Render the UV mesh with 3D normal field.\nface_uv = (\n    face.transform(hkw.transform.Compute(vertex_normal=\"normal\"))\n    .transform(hkw.transform.UVMesh())\n    .channel(normal=\"normal\")\n    .material(\"Diffuse\", \"ivory\")\n)\nconfig.film.width = 1024\nconfig.film.height = 800\nconfig.sensor = hkw.setup.sensor.Orthographic()\nhkw.render(face_uv, config, filename=\"results/face_uv.png\")\n</code></pre>"},{"location":"examples/fibers/","title":"Fibers","text":"<p>This example visualizes the fibers in a plain-knit fabric.</p> <p></p>"},{"location":"examples/fibers/#data","title":"Data","text":"<p>The data used in this visualization is generated using the plain-knit-yarn by Keenan Crane.</p>"},{"location":"examples/fibers/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\nfrom curve_io import load_curves\nimport lagrange\nfrom pathlib import Path\n\n# Step 1: Laod in the fibrers\nfibers = load_curves(Path(\"data/fibers.obj\"))\nfiber_ids = fibers.attribute(\"curve_id\").data\nfiber_set = lagrange.separate_by_facet_groups(fibers, fiber_ids)\n\n# Step 2: Create a layer for each fiber with different color.\nnum_fibers = len(fiber_set)\nroot_layer = hkw.layer()\ncolormap = hkw.common.colormap.named_colormaps.paired\nfor i, fiber in enumerate(fiber_set):\n    c = colormap(i / (num_fibers - 1)).data.tolist()\n    l = hkw.layer(fiber).mark(\"Curve\").channel(size=0.3).material(\"Plastic\", c)\n    root_layer.children.append(l)\n\n# Step 3: Render\nconfig = hkw.config()\nconfig.sensor.location = [0, 0, 3]\nhkw.render(root_layer, config, filename=\"results/fibers.png\")\n</code></pre>"},{"location":"examples/flow/","title":"Mean Curvature Flow","text":"<p>This example visualize the mean curvature flow of a bust sculpture. In addition to the shapes, we also visualize the distance to the origin mesh using color.</p> <p> </p> <p> </p>"},{"location":"examples/flow/#data","title":"Data","text":"<p>The bust sculpture used is design by Luke Chilson and published on Thingiverse.</p>"},{"location":"examples/flow/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\nimport hakowan as hkw\nimport copy\nimport numpy as np\n\nflow0 = hkw.layer(\"data/flow_00.ply\")\nflow2 = hkw.layer(\"data/flow_02.ply\")\nflow5 = hkw.layer(\"data/flow_05.ply\")\nflow9 = hkw.layer(\"data/flow_09.ply\")\n\ns = 0.3\nmat = hkw.material.Principled(\n    hkw.texture.ScalarField(\n        hkw.attribute(\n            \"dist\",\n            scale=hkw.scale.Normalize(\n                domain_min=-s, domain_max=s, range_min=0, range_max=1\n            ),\n        ),\n    ),\n    roughness=0.5,\n    metallic=0.2,\n)\n\ndist0 = flow0.channel(material=copy.deepcopy(mat))\ndist2 = flow2.channel(material=copy.deepcopy(mat))\ndist5 = flow5.channel(material=copy.deepcopy(mat))\ndist9 = flow9.channel(material=copy.deepcopy(mat))\n\nconfig = hkw.config()\nconfig.z_up()\nconfig.sensor.location = [0, -2.5, 0]\nconfig.film.width = 600\nconfig.film.height = 1024\n\nhkw.render(flow0, config, filename=\"results/bust_00.png\")\nhkw.render(flow2, config, filename=\"results/bust_02.png\")\nhkw.render(flow5, config, filename=\"results/bust_05.png\")\nhkw.render(flow9, config, filename=\"results/bust_09.png\")\n\nhkw.render(dist0, config, filename=\"results/bust_dist_00.png\")\nhkw.render(dist2, config, filename=\"results/bust_dist_02.png\")\nhkw.render(dist5, config, filename=\"results/bust_dist_05.png\")\nhkw.render(dist9, config, filename=\"results/bust_dist_09.png\")\n</code></pre>"},{"location":"examples/heat/","title":"The Heat Method","text":"<p>This example reproduced this figure from the paper \"The Heat Method for Distance Computation\".</p> <p> </p>"},{"location":"examples/heat/#data","title":"Data","text":"<p>The distance field is computed using <code>heat_geodesic</code> method from libigl. The field is stored as <code>dist</code> field in data/bunny_heat.ply.</p>"},{"location":"examples/heat/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\nimport math\n\n# Customized color map.\ncolormap = [\"#a69c65\", \"#9A9A07\", \"#983A06\", \"#7C070A\", \"#160507\", \"#060103\", \"#000000\"]\n\n# Step 1: Create a base layer.\nbase = hkw.layer(\"data/bunny_heat.ply\").material(\n    \"Principled\",\n    # We used isocontour texture to visualize the geodesic distance field both as color\n    # and as isocurves.\n    color=hkw.texture.Isocontour(\n        data=\"dist\",\n        texture1=hkw.texture.ScalarField(\"dist\", colormap=colormap),\n        texture2=\"lightgray\",\n        ratio=0.95,\n        num_contours=100,\n    ),\n    roughness=0.5,\n)\n\n# Step 2: Adjust camera position.\nconfig = hkw.config()\nconfig.sensor.location = [0, 1.2, 3]\n\n# Step 3: Render the image.\nhkw.render(base, config, filename=\"results/bunny_heat.png\")\n\n# Step 4: Render the back side.\nback_side = base.rotate(axis=[0, 1, 0], angle=math.pi)\nhkw.render(back_side, config, filename=\"results/bunny_heat_back.png\")\n</code></pre>"},{"location":"examples/ipc/","title":"Incremental Potential Contact","text":"<p>This example aims to reproduce Figure 22 from the paper \"Incremental Potential Contact: Intersection- and Inversion-free Large Deformation Dynamics\".</p> <p> </p> <p> </p> <p> </p> <p> </p>"},{"location":"examples/ipc/#data","title":"Data","text":"<p>The data were generated by compiling and running the original IPC code:</p> <p><pre><code>./IPC_bin -o out 100 ../input/paperExamples/22_squishyBall.txt out\n</code></pre> We used the output file 7.obj, 8.obj, 9.obj and 10.obj as data for this figure. The plate.obj file is generated by hand for visualization purposes.</p>"},{"location":"examples/ipc/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\nimport math\n\n# Step 1:\n# Create a ball layer. The ball geometry will be speicified later.\n# Approximate the original IPC figure with pinkish material.\n# Note that Hakowan supports any valid CSS color names as well as hex code codes.\n#\n# See [CSS colors](https://www.w3schools.com/cssref/css_colors.php).\n\nball = hkw.layer().material(\"RoughPlastic\", \"salmon\", alpha=0.02)\n\n# Step 2:\n# Create a plate layer containing the collision plate.\n# Use glass-like material so one can see the collision-induced deformation clearly.\n\nplate = hkw.layer(\"data/plate2.obj\").material(\"ThinDielectric\")\n\n# Step 3: Adjust configuration.\n# For this visualization, it is best to use orthographic projection and avoid perspective\n# distortion.\n\nconfig = hkw.config()\n# Use orthographic camera for better visualization of the collision.\nconfig.sensor = hkw.setup.sensor.Orthographic()\n# Use volume path integrator to reduce rendering noise.\nconfig.integrator = hkw.setup.integrator.VolPath()\n\n# Step 4: Render!\n# We have 4 different results sampled at different time during the simulation.\n# We will create two visualizations for each result: side view and back view.\n\nfor i in [7, 8, 9, 10]:\n    # Set the data component of the ball layer.\n    ball = ball.data(f\"data/{i}.obj\")\n\n    # The side view shows the ball-plate collision from the side.\n    side_view = ball + plate\n    hkw.render(side_view, config, filename=f\"results/ipc_side_{i}.png\")\n\n    # The back view shows the ball-plate collision from behind the plate.\n    # Rotation matrix to rotate around y-axis by 90 degrees.\n    back_view = (ball + plate).rotate(axis=[0, 1, 0], angle=-math.pi / 2)\n    hkw.render(back_view, config, filename=f\"results/ipc_back_{i}.png\")\n</code></pre>"},{"location":"examples/layout/","title":"Layout Embedding","text":"<p>This example aims to provide an alternative visualization for the results from the paper Layout Embedding via Combinatorial Optimization.</p> <p> </p>"},{"location":"examples/layout/#data","title":"Data","text":"<p>The data used in this example was generated by the official released code:</p> <pre><code>./pig_figure\n</code></pre>"},{"location":"examples/layout/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\nfrom data import load_data\n\n# Step 1: Preprocess data.\nref_mesh, chains_mesh = load_data()\n\n# Step 2: Generate layout layers.\nbase = hkw.layer(ref_mesh)\n\n# Mesh layer contains the base geometry.\n# Use chart attribute as scalar field texture.\nmesh_layer = base.material(\n    \"Principled\",\n    color=hkw.texture.ScalarField(\"chart\", colormap=\"set1\", categories=True),\n    roughness=0.0,\n    metallic=0.0,\n)\n\n# Chain layer contains the layout boundaries.\nchains_layer = (\n    hkw.layer(chains_mesh)\n    .mark(\"Curve\")\n    .material(\"Conductor\", \"Cr\")\n    .channel(size=0.02)\n)\n\n# Update camera location for better viewing angle.\nconfig = hkw.config()\nconfig.sensor.location = [3, 0, 0]\n\n# Step 3: Render the both layers.\nhkw.render(mesh_layer + chains_layer, config, filename=\"results/pig_embedded.png\")\n\n# Step 4: Render the mesh layer with glass material.\nmesh_layer = base.channel(material=hkw.material.ThinDielectric())\nhkw.render(mesh_layer + chains_layer, config, filename=\"results/pig_embedded_glass.png\")\n</code></pre>"},{"location":"examples/moon/","title":"Moon","text":"<p>This example aims to generate 3D visualization of both sides of the moon.</p> <p> </p>"},{"location":"examples/moon/#data","title":"Data","text":"<p>The data used in this example is from NASA's CGI Moon Kit.</p>"},{"location":"examples/moon/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\nimport pathlib\n\nconfig = hkw.config()\nconfig.z_up()\nconfig.emitters[0].rotation = -90\nconfig.sensor.location = [3, 0, 0]\n\n# Render with both color and bump map.\nbase = (\n    hkw.layer(\"data/moon.ply\")\n    .channel(\n        bump_map=hkw.channel.BumpMap(\n            hkw.texture.Image(\"data/ldem_16_uint.png\"), scale=0.1\n        ),\n    )\n    .material(\"Principled\", hkw.texture.Image(\"data/lroc_color_poles_8k.png\"))\n)\nhkw.render(base, config, filename=\"results/moon.png\")\n\n# Render back side.\nconfig.emitters[0].rotation = 90\nconfig.sensor.location = [-3, 0, 0]\nhkw.render(base, config, filename=\"results/moon_backside.png\")\n</code></pre>"},{"location":"examples/penny/","title":"Penny","text":"<p>This example visualizes the normal and depth fields of a reconstructed penny model.</p> <p> </p> <p> </p>"},{"location":"examples/penny/#data","title":"Data","text":"<p>The data used in this model is generated from depth map images from GIGAmacro. It is converted to mesh using project Lagrange.</p>"},{"location":"examples/penny/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\nimport mitsuba as mi\n\n# Step 1: Generate a base layer with normal and depth attributes.\nbase = hkw.layer(\"data/penny.glb\").transform(\n    hkw.transform.Compute(normal=\"normal\", z=\"depth\")\n)\nconfig = hkw.config()\nconfig.sensor.location = [0, 0, 3]\n\n# Step 2: Render with copper material.\nl0 = base.material(\"RoughConductor\", \"Cu\")\nhkw.render(l0, config, filename=\"results/penny.png\")\n\n# Step 3: Update config setting for albedo-only rendering.\nconfig.albedo_only = True\n\n# Step 4: Render with normal AOV.\nl1 = base.material(\"Principled\", hkw.texture.ScalarField(\"normal\", colormap=\"identity\"))\nhkw.render(l1, config, filename=\"results/penny_normal_aov.png\")\n\n# Step 5: Render with depth AOV.\nl2 = base.material(\"Principled\", hkw.texture.ScalarField(\"depth\", colormap=[0, 1]))\nhkw.render(l2, config, filename=\"results/penny_depth_aov.png\")\n\n# Step 6: Render with depth AOV using colormap.\nl3 = base.material(\"Principled\", color=hkw.texture.ScalarField(\"depth\"))\nhkw.render(l3, config, filename=\"results/penny_depth_aov_color.png\")\n</code></pre>"},{"location":"examples/powell-sabin/","title":"Powell-Sabin Subdivision","text":"<p>This exmaple visualizes the Powell-Sabin subdivision for tets. A similar figure can be found in Figure 2.1 and 2.2 in the paper \"A trivariate Powell-Sabin interpolant\".</p> <p> </p>"},{"location":"examples/powell-sabin/#data","title":"Data","text":"<p>The data were generated using this script.</p>"},{"location":"examples/powell-sabin/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\n\nbase = hkw.layer(\"data/powell_sabin.ply\").transform(\n    hkw.transform.Compute(component=\"comp_ids\", facet_normal=\"face_normal\")\n)\n\nvertices = (\n    base.mark(\"Point\")\n    .channel(size=0.015)\n    .material(\n        \"Principled\",\n        hkw.texture.ScalarField(\n            \"vertex_label\", colormap=[\"steelblue\", \"green\", \"yellow\", \"red\"]\n        ),\n        roughness=0,\n        metallic=0.3,\n    )\n)\nedges = base.mark(\"Curve\").material(\"Conductor\", \"Cr\").channel(size=0.005)\nsurface = base.mark(\"Surface\").material(\n    \"Principled\",\n    color=hkw.texture.ScalarField(\"comp_ids\", colormap=\"set1\", categories=True),\n)\n\nconfig = hkw.config()\nconfig.z_up()\nconfig.sensor.location = [2.5, -2.5, 0]\nhkw.render(vertices + edges + surface, config, filename=\"results/powell_sabin.png\")\n\nexploded_view = (vertices + edges + surface).transform(\n    hkw.transform.Explode(\"comp_ids\", magnitude=0.5)\n)\nconfig.sensor.location = [2.5, -2.5, 0]\nhkw.render(exploded_view, config, filename=\"results/powell_sabin_explode.png\")\n</code></pre>"},{"location":"examples/skeleton/","title":"Neural Skeleton","text":"<p>This example tries to reproduce skeleton visualization from the paper \"Neural skeleton: Implicit neural representation away from the surface\".</p> <p></p>"},{"location":"examples/skeleton/#data","title":"Data","text":"<p>The skeleton is computed with the official code released by the authors.</p>"},{"location":"examples/skeleton/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\nimport lagrange\nimport numpy as np\nimport math\n\n# Step 1: Load skeleton.\nskeleton = lagrange.io.load_mesh(\"data/fertility_skeleton.obj\")\nwith open(\"data/fertility_skeleton.obj\", \"r\") as fin:\n    for line in fin:\n        if line.startswith(\"l \"):\n            fields = line.split()\n            skeleton.add_polygon(np.array([int(fields[1]) - 1, int(fields[2]) - 1]))\n\n\n# Step 2: Load base mesh with glass like material.\nbase = hkw.layer(\"data/fertility.obj\").material(\"ThinDielectric\")\n\nskeleton_base = hkw.layer(skeleton).material(\"Conductor\", \"Cr\")\nskeleton_edges = skeleton_base.mark(\"Curve\").channel(size=0.01)\n\n# Step 3: Combine all layers\nall_layers = (base + skeleton_base + skeleton_edges).rotate(\n    axis=[0, 1, 0], angle=math.pi / 6\n)\n\n# Step 4: Adjust camera and render.\nconfig = hkw.config()\nconfig.sensor.location = [0, 0, 3]\nconfig.integrator = hkw.setup.integrator.VolPath()\nhkw.render(\n    all_layers,\n    config,\n    filename=\"results/fertility_skeleton.png\",\n)\n</code></pre>"},{"location":"examples/sketch/","title":"Lifting Freehand Concept Sketches into 3D","text":"<p>This example aims to visualize the 3D freehand sketches generated from the paper \"Lifting Freehand Concept Sketches into 3D\".</p> <p> </p>"},{"location":"examples/sketch/#data","title":"Data","text":"<p>The data used for this example comes from the officially released reconstruction results.</p>"},{"location":"examples/sketch/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\nimport lagrange\nimport math\nimport numpy as np\nimport pathlib\n\n\ndef draw(filename: pathlib.Path, config, rotate_angle):\n    sketch = lagrange.SurfaceMesh()\n\n    with open(filename, \"r\") as fin:\n        for line in fin:\n            if line.startswith(\"v \"):\n                fields = line.split()\n                v = [float(x) for x in fields[1:]]\n                sketch.add_vertex(v)\n            elif line.startswith(\"l \"):\n                fields = line.split()\n                l = np.array([int(x) - 1 for x in fields[1:]])\n                sketch.add_polygon(l)\n\n    base = (\n        hkw.layer(sketch)\n        .mark(hkw.mark.Curve)\n        .channel(size=0.0005)\n        .rotate([0, 1, 0], rotate_angle)\n    )\n\n    dark_line = base.channel(material=hkw.material.Plastic(\"#0C0609\"))\n    light_line = base.channel(material=hkw.material.Plastic(\"#CCCDD6\"))\n\n    stem = filename.stem\n    dark_output_filename = pathlib.Path(\"results\") / f\"{stem}_dark.png\"\n    light_output_filename = pathlib.Path(\"results\") / f\"{stem}_light.png\"\n\n    hkw.render(dark_line, config, filename=dark_output_filename)\n    hkw.render(light_line, config, filename=light_output_filename)\n\n\nconfig = hkw.config()\nconfig.z_up()\nconfig.sensor.location = [1.5, -1.5, 1.5]\ndraw(pathlib.Path(\"data/Prof2task2_guitar_01_rough.obj\"), config, 0)\n\nconfig.y_up()\nconfig.sensor.location = [1.75, 1.75, 1.75]\ndraw(pathlib.Path(\"data/designer2_guitar_01_rough.obj\"), config, math.pi)\n</code></pre>"},{"location":"examples/slim/","title":"Scalable Locally Injective Mappings","text":"<p>This example aims to reproduce Figure 3 and 10 from the paper Scalable Locally Injective Mappings.</p> <p> </p>"},{"location":"examples/slim/#data","title":"Data","text":"<p>The data used in this example is the official data released by the authors.</p>"},{"location":"examples/slim/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python3\n\nimport hakowan as hkw\nimport pathlib\nimport math\n\n# First, we define a base layer with the desired material+texture setup.\n# This base layer serves as a template, where we will extend it with different\n# data components later.\n#\n# Note that we are using image-based texture for color in this example.\n# The UV is scaled by 10 times to have more repetitions of the texture.\nbase = hkw.layer().material(\n    \"Principled\",\n    color=hkw.texture.Image(\n        filename=pathlib.Path(\"data/texture.png\"),\n        uv=hkw.attribute(\"texcoord\", scale=10),\n    ),\n    roughness=0.2,\n)\n\n# Figure 3\nfig3 = base.data(\"data/fig3.obj\").rotate(axis=[0, 1, 0], angle=math.pi)\n\n# Move the camera position closer.\nconfig = hkw.config()\nconfig.sensor.location = [0, 0, 3]\n\n# Render!\nhkw.render(fig3, config, filename=\"results/fig3.png\")\n\n# Figure 10\n\n# The input mesh comes at an odd orientation.\n# We apply two rotations to fix the orientation issue.\n# First, we rotate the mesh around the x-axis by -45 degrees.\n# Then, we rotate the mesh around the y-axis by 135 degrees.\nfig10 = (\n    base.data(\"data/fig10_uniform.obj\")\n    .rotate(axis=[1, 0, 0], angle=-math.pi / 4)\n    .rotate(axis=[0, 1, 0], angle=3 * math.pi / 4)\n)\n\n# Render!\nhkw.render(fig10, config, filename=\"results/fig10.png\")\n</code></pre>"},{"location":"examples/sph/","title":"Smoothed Particle Hydrodynamics","text":"<p>This example aims to reproduce Figure 9 from the paper \"Implicit Surface Tension for SPH Fluid Simulation\".</p> <p> </p> <p> </p> <p> </p> <p> </p>"},{"location":"examples/sph/#data","title":"Data","text":"<p>The data is genearted using the SPlisHSPlasH library which comes with the scene files used to generate the original figure:</p> <pre><code>SPHSimulate ../data/Scenes/SurfaceTension_WaterBell_JWL+23.json\n</code></pre>"},{"location":"examples/sph/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\nimport lagrange\nimport numpy as np\n\nconfig = hkw.config()\nconfig.sensor.location = [0, 0, 3]\n\nemitter = hkw.layer(\"data/emitter.msh\").channel(\n    material=hkw.material.RoughPlastic(\"Ivory\")\n)\n\nbox_min = [-1.223, -0.5, -1.226]\nbox_max = [1.224, 4.0, 1.222]\nroi_box = np.vstack([box_min, box_max])\nfor i in [10, 30, 60, 133]:\n    fluid = (\n        hkw.layer()\n        .data(f\"data/waterbell_{i:03}.msh\", roi_box=roi_box)\n        .mark(\"Point\")\n        .channel(size=0.01)\n        .material(\n            \"Principled\",\n            hkw.texture.ScalarField(\"speed\", domain=[0, 10]),\n        )\n    ).transform(hkw.transform.Norm(\"velocity\", \"speed\"))\n    hkw.render(fluid + emitter, config, filename=f\"results/waterbell_{i:03}_all.png\")\n\n    fluid = fluid.transform(hkw.transform.Filter(condition=lambda p: p[2] &lt;= 0))\n    hkw.render(fluid + emitter, config, filename=f\"results/waterbell_{i:03}.png\")\n</code></pre>"},{"location":"examples/tetwild/","title":"Tetrahedral Meshing in the Wild","text":"<p>This example tries to reproduce the rendering style used in the paper \"Tetrahedral Meshing in the Wild\". It shows the surface triangulation of a tet mesh as well as a cut-away view of the internal tet shapes.</p> <p> </p> <p></p>"},{"location":"examples/tetwild/#data","title":"Data","text":"<p>The data used in this example is with the TetWild code with default parameters.</p> <pre><code>./TetWild bust.obj bust.msh\n</code></pre> <p>The bust sculpture shape used is design by Luke Chilson and published on Thingiverse.</p>"},{"location":"examples/tetwild/#code","title":"Code","text":"<pre><code>#!/usr/bin/env python\n\nimport hakowan as hkw\nimport numpy as np\nimport lagrange\nfrom pathlib import Path\n\n# Note that the `mtet` package used in `tet_utils` has not been released yet. Stay tuned!\nfrom tet_utils import load_tet_mesh, extract_boundary, extract_clipped_boundary\n\n# Create a clipping function for cut-away view of the tet mesh.\nclip_coeff = [1, 1, 0.5, -30]\ncut_fn = (\n    lambda c: c[0] * clip_coeff[0]\n    + c[1] * clip_coeff[1]\n    + c[2] * clip_coeff[2]\n    + clip_coeff[3]\n    &gt; 0\n)\n\n# Extract the tet mesh data.\ntet_mesh = load_tet_mesh(Path(\"data/bust.msh\"))\nbd_mesh = extract_boundary(tet_mesh)\nclipped_mesh = extract_clipped_boundary(tet_mesh, cut_fn)\nclipped_mesh2 = extract_clipped_boundary(tet_mesh, lambda p: not cut_fn(p))\n\n# Create a surface and wire view of the data.\nsurface = (\n    hkw.layer()\n    .channel(normal=\"facet_normal\")\n    .material(\"Principled\", \"#FBCD50\", roughness=0.2)\n    .transform(hkw.transform.Compute(facet_normal=\"facet_normal\"))\n)\nwires = hkw.layer().mark(\"Curve\").channel(size=0.02).material(\"Diffuse\", \"black\")\n\n# Create boundary and clipped views.\nbd_view = (surface + wires).data(bd_mesh)\nsurface = surface.material(\n    \"Principled\",\n    hkw.texture.ScalarField(\"boundary_tag\", colormap=[\"#FBCD50\", \"#0FB2F2\"]),\n    roughness=0.2,\n)\nclipped_view = (surface + wires).data(clipped_mesh)\ncombined_view = bd_view + clipped_view.translate([30, 0, 0])\nclipped_view2 = hkw.layer(clipped_mesh2).material(\"ThinDielectric\") + clipped_view\n\n# Render the views.\nconfig = hkw.config()\nconfig.z_up()\nconfig.sensor.location = [0, -3, 0]\nconfig.film.width = 800\nconfig.film.height = 1024\nhkw.render(bd_view, config, filename=\"results/bust_bd.png\")\nhkw.render(clipped_view, config, filename=\"results/bust_clipped.png\")\nhkw.render(clipped_view2, config, filename=\"results/bust_clipped2.png\")\n\nconfig.film.width = 1024\nconfig.film.height = 800\nconfig.sensor.location = [0, -3, 0]\nhkw.render(combined_view, config, filename=\"results/bust.png\")\n</code></pre>"},{"location":"guide/attribute/","title":"Attribute","text":"<p>In Hakowan, an attribute specifies a specific \"column\" of the data (i.e. mesh attribute) that will be used to encode various visual channels and textures. Each attribute consists of a name and a scale. The name is the name of the mesh attribute used as data, and the scale defines a \"column\"-specific transformation applied to the attribute before mapping to visual channels.</p> <pre><code># To specify an attribute from name alone.\nBy default, scale is identity.\nattr = hkw.attribute(name=\"normal\")\n\n# To specify an attribute from both name and scale.\nattr = hkw.attribute(name=\"normal\", scale=hkw.scale.Uniform(factor=2))\n</code></pre>"},{"location":"guide/channel/","title":"Channels","text":"<p>A channel represents a specific visual quantity that can be used to encode data. For example, 2D data visualization often encodes data in position, color, shape and size channels. Similarly in 3D data visualization, we can encode data in position, normal, size and vector field channels. In addition, we have the freedom of inventing new visual channels thanks to the diverse material models that modern rendering engines support. We have a separate guide for material-based channels. In this guide, we will mainly focus on non-material channels.</p> <p></p> <p>In the simple landscape example<sup>1</sup> above, we use color (a visual channel defined in a material) to encode the height field attribute on the left, and use color + position to encode the same height field on the right.</p> <p>Channels can be specified via <code>Layer.channel()</code> function.</p> <pre><code># Assume `ch1` is a `Position` channel object,\n# and `ch2` is a `Normal` channel object.\nl = hkw.layer().channel(position=ch1, normal=ch2)\n</code></pre>"},{"location":"guide/channel/#position-channel","title":"Position channel","text":"<p><code>Position</code> channel represents the position of 3D marks. By default, the position channel will use the vertex positions stored in the data frame. It is especially useful when multiple sets of positions are available (e.g. animation or decimation).</p> Channel Type Description <code>data</code> [AttributeLike][hakowan.scale.attribute.AttributeLike] The position attribute <pre><code># To specify an attribute as the position channel data:\nch = hkw.channel.Position(data = hkw.attribute(name = \"attr_name\"))\n\n# A shorthand that is exactly the same as above.\nch = hkw.channel.Position(data = \"attr_name\")\n</code></pre>"},{"location":"guide/channel/#normal-channel","title":"Normal channel","text":"<p><code>Normal</code> channel represents the normal vector field of a 3D surface. It has significant influence on how the surface reflect lights. By default, normals will be computed from the 3D data frame. The <code>Normal</code> channel is only relevant for <code>Surface</code> mark.</p> <p>For example, a common technique to visualize UV is to show the 2D UV mesh along with the 3D normal field. The example<sup>2</sup> on the right illustrate this technique (right) as well as visualizing UV using checkerboard texture (left).</p> Channel Type Description <code>data</code> [AttributeLike][hakowan.scale.attribute.AttributeLike] The normal attribute <pre><code># To specify an attribute as the normal channel data:\nch = hkw.channel.Normal(data = hkw.attribute(name = \"attr_name\"))\n\n# Shorthand. Same as above\nch = hkw.channel.Normal(data = \"attr_name\")\n</code></pre>"},{"location":"guide/channel/#size-channel","title":"Size channel","text":"<p><code>Size</code> channel represents the size of 3D marks. It is only relevant to <code>Point</code> and <code>Curve</code> marks. For <code>Point</code> mark, size represents the radius of the point mark. For <code>Curve</code> mark, size represents the radius of the curves.</p> <p>On the simple star example to the right, the vertex valence of the graph is mapped to the size channel of the points. The edges are of uniform size.</p> Channel Type Description <code>data</code> [AttributeLike][hakowan.scale.attribute.AttributeLike] The size attribute <pre><code># To sepcify an attribute as the size channel data:\nch = hkw.channel.Size(data = hkw.attribute(name = \"attr_name\"))\n\n# Shorthand. Same as above\nch = hkw.channel.Size(data = \"attr_name\")\n\n# To assign constant size field\nch = hkw.channel.Size(data = 0.1)\n</code></pre> <p>Note that <code>Size</code> channel uses the same unit as the <code>Position</code> channel.</p>"},{"location":"guide/channel/#vector-field-channel","title":"Vector field channel","text":"<p><code>VectorField</code> channel defines the data used for a vector field visualization. This channel is only relevant when the mark is <code>Curve</code> as each vector is rendered using the curve geometry.</p> <p>The example<sup>3</sup> above shows the normal, tangent and bitangent vector field visualization in hair material.</p> Channel Type Description <code>data</code> [AttributeLike][hakowan.scale.attribute.AttributeLike] The attribute containing vector field data <p>Here is a snippet for creating a <code>VectorField</code> channel.</p> <pre><code># To specify an attribute as the vector field channel data.\nch = hkw.channel.VectorField(data = hkw.attribute(name = \"attr_name\"))\n\n# Shorthand, same as above.\nch = hkw.channel.VectorField(data = \"attr_name\")\n</code></pre> <p>Note that each vector in the vector field is visualized as a b-spline curve. The vector field's magnitude determines the curve length. The <code>Size</code> channel defines the thickness of the curve. Vector field channel also takes the following parameters.</p> Parameter Type Description <code>refinement_level</code> <code>int</code> The refinement level (default: 0) <code>end_type</code> <code>str</code> The end type of each vector (options: <code>point</code> (default), <code>flat</code>) <code>style</code> [CurveStyle][hakowan.channel.curvestyle.CurveStyle] The curve style to use (default: None) <ol> <li> <p>3D model generated with Blender's A.N.T.Landscape add-on.\u00a0\u21a9</p> </li> <li> <p>3D model source: Bust of Sappho \u21a9</p> </li> <li> <p>3D model generated with Blender.\u00a0\u21a9</p> </li> </ol>"},{"location":"guide/config/","title":"Configuration","text":"<p>The configuration class defines a number of scene-related settings that mapped directly from Mitsuba.</p> <ul> <li><code>sensor</code>: Camera-related settings.</li> <li><code>film</code>: The output image format.</li> <li><code>sampler</code>: Sampler settings.</li> <li><code>emitters</code>: An array of light settings.</li> <li><code>integrator</code>: Settings for different rendering techniques.</li> </ul> <p>The configuration object provides a number of handy functions for commonly used configurations. For example, the default scene using Y axis as the up direction. To change the up direction:</p> <pre><code>config = hkw.config()\n\nconfig.z_up() # Change the up direction to +Z axis.\nconfig.z_down() # Change the up direction to -Z axis.\nconfig.y_up() # Change the up direction to +Y axis.\nconfig.y_down() # Change the up direction to -Y axis.\n</code></pre> <p>Another useful feature is to enable albedo-only rendering:</p> <pre><code>config.albedo_only = True\n</code></pre> <p>See the Penny example for a usage of albedo-only rendering.</p>"},{"location":"guide/config/#sensor-settings","title":"Sensor settings","text":"<p>Sensor defines the camera setting. All sensors supports the following settings:</p> Setting Type Description <code>location</code> <code>NDArray</code> The camera location. (default: <code>[0, 0, 5]</code>) <code>target</code> <code>NDArray</code> The look-at location. (default: <code>[0, 0, 0]</code>) <code>up</code> <code>NDArray</code> The up direction. (default: <code>[0, 1, 0]</code>) <code>near_clip</code> <code>float</code> The near clipping plane (default: <code>1e-2</code>) <code>far_clip</code> <code>float</code> The far clipping plane (default: <code>1e4</code>) <p>Note that <code>location</code> and <code>target</code> are location after applying global transformation that put the bounding box of the scene within a unit sphere centered at the origin. Typically, only <code>location</code> needs to be changed based on need.</p>"},{"location":"guide/config/#perspective-sensor","title":"Perspective sensor","text":"<p>Perspective sensor models the traditional pin-hole camera. It support the following attributes.</p> Setting Type Description <code>fov</code> <code>float</code> The field of view in degrees. (default: 28.8415) <code>fov_axis</code> <code>str</code> The fox axis (default: <code>smaller</code>) <pre><code>config.sensor = hkw.setup.sensor.Perspective(fov=30)\n</code></pre>"},{"location":"guide/config/#orthographic-sensor","title":"Orthographic sensor","text":"<p>Orthographic sensor uses the orthographic projection. This sensor type does not produce foreshortening effect.</p> <pre><code>config.sensor = hkw.setup.sensor.Orthograpic()\n</code></pre> <p>See the Incremental Potential Contact example for an usage of orthographic sensor.</p>"},{"location":"guide/config/#thin-lens-sensor","title":"Thin lens sensor","text":"<p>This sensor models the thin lens camera model which allows rendering with a specific depth of field.</p> Setting Type Description <code>aperture_radius</code> <code>float</code> The aperture radius. (default: 0.1) <code>focus_distance</code> <code>float</code> The focus distance. (default: 0.0)"},{"location":"guide/config/#film-settings","title":"Film settings","text":"<p>Film settings provide output image specification.</p> Setting Type Description <code>width</code> <code>int</code> The output image width (default: 1024) <code>height</code> <code>int</code> The output image height (default: 800) <code>file_format</code> <code>str</code> The output image file format (default: <code>openexr</code>) <code>pixel_format</code> <code>str</code> The output image pixel format (default: <code>rgba</code>) <code>component_format</code> <code>str</code> The output image pixel format (default: <code>float16</code>) <code>crop_offset</code> <code>NDArray</code> The top left corner of the crop region (default: <code>None</code>) <code>crop_size</code> <code>NDArray</code> The size of the crop region (default: <code>None</code>) <p>Note that <code>crop_offset</code> and <code>crop_size</code> together define the crop region. Setting either to <code>None</code> indicate no cropping. <code>file_format</code>, <code>pixel_format</code> and <code>component_format</code> are for expert-usage only.</p> <pre><code># Generate 4K rendering.\nconfig.film.width = 3840\nconfig.film.height = 2160\n</code></pre>"},{"location":"guide/config/#sampler","title":"Sampler","text":"<p>Sampler defines the sample strategy used for rendering. It supports the following parameters:</p> Setting Type Description <code>sample_count</code> <code>int</code> Number of samples per pixel (default: 256) <code>seed</code> <code>int</code> Random number seed (default: 0) <p>Note that sampler settings typically do not need to be changed unless the rendered image is too noisy.</p> <pre><code>config.sampler.sample_count = 128 # Reduce sample count\n</code></pre>"},{"location":"guide/config/#emitter-settings","title":"Emitter settings","text":"<p>Emitters represent the light source in the scene. The emitting setting directly influence the shading and shadow of the scene. Multiple emitters can be used at the same time.</p>"},{"location":"guide/config/#point-emitter","title":"Point emitter","text":"<p>A point emitter is a point light source, which tends to generate share shadow boundaries.</p> <pre><code>l = hkw.setup.emitter.Point(position=[0, 0, 5], intensity=\"#FFEAC5\")\nconfig.emitters.append(l)\n</code></pre>"},{"location":"guide/config/#environment-emitter","title":"Environment emitter","text":"<p>A environment emitter defines image-based lighting (IBL). It is the preferred emitter setting in Hakowan. By default, we use \"At the Window\" environment map from Bernhard Vogl (free for non-commercial usage).</p> <pre><code>l = hkw.setup.emitter.Envmap(filename=\"envmap.exr\")\nconfig.emitters.append(l)\n</code></pre>"},{"location":"guide/config/#integrator-settings","title":"Integrator settings","text":"<p>Integrator settings defines the render technique used.</p> Setting Type Description <code>hide_emitters</code> <code>bool</code> Whether to render emitters (default: <code>False</code>)"},{"location":"guide/config/#path-integrator","title":"Path integrator","text":"<p>The <code>Path</code> integrator mirrors the Mitsuba's <code>Path</code> integrator. It is the default integrator used in Hakowan.</p>"},{"location":"guide/config/#aov-integrator","title":"AOV integrator","text":"<p>The <code>AOV</code> integrator mirrors the Mitsuba's <code>AOV</code> integrator. It is useful for visualizing specific attribute without shading.</p>"},{"location":"guide/config/#volpath-integrator","title":"VolPath integrator","text":"<p>The <code>VolPath</code> integrator mirrors the Mitsuba's <code>VolPath</code> integrator. It is useful for rendering scene with volumetric elements (e.g. with [Dielectric][hakowan.material.Dielectric] material).</p>"},{"location":"guide/data/","title":"Data","text":"<p>In 3D data visualization, we distinguish two types of 3D data: 3D geometry and data associated with 3D geometry.</p> <ul> <li>3D geometry as data: In this category, we are mainly interested in visualizing the shape/location of   the 3D geometry. For example, the shape of a deformed mesh or the location of points in a point   cloud.</li> <li>Data associated with 3D geometry: In this category, the data is a spatially varying field,   and we would like to visualize its value at different locations. For example, the Gaussian   curvature field on a curved surface, or the geodesic distance on a surface with respect to a   source surface point.</li> </ul> <p></p> <p>3D geometry are often represented as a mesh for visualization purposes. A mesh, such as the bunny model on the right<sup>1</sup>, consists of a set of vertices edges and facets. Data associated with 3D geometry are represented as an attribute of a mesh. Each attribute is defined for a specific element type (vertex, edge or facet).</p> <p>In Hakowan, we leverage Lagrange's SurfaceMesh data structure to represent both 3D geometry and store data associated with 3D geometry as mesh attributes. In a sense, the elements of a mesh defines the \"rows\" of a 3D data frame, and the attributes of a mesh defines the \"columns\" of a 3D data frame. In addition, Hakowan can also extract geometry and data associated with geometry from a number of common 3D file formats such as OBJ, PLY, GLTF and MSH.</p> <p>Here is a quick example demonstrating the various ways of specifying data in Hakowan: <pre><code># As argument to hkw.layer() method.\nl0 = hkw.layer(\"shape.obj\")\n\n# As argument to .data overwrite function.\nl1 = hkw.layer().data(\"shape.obj\")\n\n# Lagrange SurfaceMesh object can also be used instead of filename.\nmesh = lagrange.io.load_mesh(\"shape.obj\")\nl2 = hkw.layer(mesh)\nl3 = hkw.layer().data(mesh)\n</code></pre></p> <p>See the Mesh Deformation example for a use case of reusing the same layer specification with different data fields.</p>"},{"location":"guide/data/#region-of-interest","title":"Region of interest","text":"<p>When we specifying the data, we can optionally specify a region of interest. The region of interest is an axis-aligned box that defines the region in the center of the rendering.</p> <pre><code>l0 = hkw.layer().data(\"shape.obj\", roi_box=[[0, 0, 0], [1, 1, 1]])\n</code></pre> <p>See the Smoothed Particle Hydrodynamics example for a usage of region of interest.</p> <ol> <li> <p>3D model source: origamix rabbit \u21a9</p> </li> </ol>"},{"location":"guide/grammar/","title":"Grammar","text":""},{"location":"guide/grammar/#grammar-overview","title":"Grammar Overview","text":"<p>The grammar of a language provides a set of structural rules to combine words together to form semantically meaningful statements. Similarly, from the data visualization community, the seminal work of The Grammar of Graphics from Leland Wilkinson proposed a structured way to systematically decompose a graphic (i.e. chart) into a set of visual and mathematical components. Much like the recipe of a dish, each component is independent, and together they provide a complete specification of a chart. The grammar of graphics is a highly flexible way of describing the desired chart while abstracting away much of the tedious details related to chart drawing.</p> <p></p> <p>Hakowan is a 3D data visualization grammar based on the concept of the grammar of graphics. It identifies 4 key components in 3D data visualization: data, mark, channels and transform.</p> <p>Data consists of a set of mesh attributes defined over mesh elements. Attributes are the \"columns\" in our data, and they can be mapped to different visual channels. Each attribute can optionally be associated with a scale transformation. A mark defines the basic types of visualization elements (e.g. point, curve, surface). A channel represent some form of visual property used to encode data. Hakowan supports various materials, where each material may expose multiple visual channels. The mapping from an attribute to a material channel is defined by a texture. A transform represents a set of global transformations (e.g. adding/removing geometry and/or attributes) applied to the data before visualization.</p> <p>A complete specification of data, mark, channel and transform components forms a layer in the visualization. Each component of a layer can be overwrite, and multiple layers can be combined together to generate composite visualization.</p>"},{"location":"guide/grammar/#api-overview","title":"API Overview","text":"<p>For the rest of this document, we will assume the <code>hakowan</code> package has been imported as the alias <code>hkw</code>.</p> <pre><code>import hakowan as hkw\n</code></pre>"},{"location":"guide/grammar/#create-a-layer","title":"Create a layer","text":"<p>Layer is the most fundamental object within Hakowan as it contains the complete specification of all 4 key components. The following snippet shows how to create an empty layer.</p> <pre><code>base = hkw.layer()\n</code></pre> <p>In an empty layer, all 4 components are <code>None</code>. In order for a layer to be render-able, data should specified. The other 3 components will fall back to default values if not specified.</p>"},{"location":"guide/grammar/#specify-data","title":"Specify data","text":"<p>Given a <code>base</code> layer, we use the <code>.data</code> method to specify data.</p> <pre><code># Specify data from file\nl = base.data(\"filename.obj\")\n\n# Specify data from lagrange.SurfaceMesh object\nl = base.data(mesh)\n</code></pre>"},{"location":"guide/grammar/#specify-mark","title":"Specify mark","text":"<p>Mark can be specified with <code>.mark</code> method of layer object.</p> <pre><code>l = base.mark(hkw.mark.Point)\n</code></pre>"},{"location":"guide/grammar/#specify-channel","title":"Specify channel","text":"<p>Similarly, channels can be specified with <code>.channel</code> method.</p> <pre><code>l = base.channel(\n    position=hkw.channel.Position(data=\"my_position\"),\n    normal=hkw.channel.Normal(data=\"my_normal\")\n)\n</code></pre> <p>In the above example, we specify two channels in the same <code>.channel</code> call. In each specification, we created the corresponding <code>Position</code> or <code>Normal</code> channel objects. The <code>data</code> parameter here specifies the associated attribute to use for channel encoding.</p> <p>Material can also be specified with <code>.channel</code> method.</p> <pre><code>l = base.channel(\n    material=hkw.material.Diffuse(reflectance=\"grey\")\n)\n</code></pre> <p>Here, we simply assign a uniform color to the reflectance channel of the <code>Diffuse</code> material. To use mesh attribute to encode material channel, we need to use a texture.</p> <pre><code>l = base.channel(\n    material=hkw.material.Diffuse(\n        reflectance=hkw.texture.ScalarField(\n            data=\"attr_name\"\n        )\n    )\n)\n</code></pre>"},{"location":"guide/grammar/#specify-transform","title":"Specify transform","text":"<p>We use the <code>.transform</code> method of a layer object to specify transform.</p> <pre><code>l = base.transform(\n    hkw.transform.Filter(\n        data=\"attr_name\",\n        condition=lambda p:p[0] &gt; 0\n    )\n)\n</code></pre>"},{"location":"guide/grammar/#layer-composition","title":"Layer composition","text":"<p>Let <code>l0</code> and <code>l1</code> be two layers, we can use addition to combine them together.</p> <pre><code>combined_layer = l0 + l1\n</code></pre>"},{"location":"guide/layer/","title":"Layer Overview","text":"<p>Layer is a concept that holds the specification of the 4 key components: data, mark, channels and transform. A layer may be complete if all its associated components are not <code>None</code>, or partial if one or more component is <code>None</code>. A layer is created with the <code>hkw.layer</code> method.</p> <pre><code>l0 = hkw.layer()\n</code></pre> <p>Here we have created an empty layer, where all of data, mark, channels and transform are None.</p> <p>An empty layer cannot be rendered because the data component is required for rendering. Fortunately, it is very easy to build on top of an existing layer with a set of overwrite functions. For example,</p> <pre><code>l1 = l0.data(\"shape.obj\")\n</code></pre> <p>where <code>l1</code> is a new layer created from <code>l0</code> layer with the data component set to <code>shape.obj</code>. The method <code>.data</code> is an example of such overwrite functions. The other overwrite functions are <code>.mark</code>, <code>.channel</code> and <code>.transform</code>. These overwrite functions can be chained together based on the fluent interface design pattern.</p> <pre><code>l2 = l0.data(\"shape.obj\").mark(hkw.mark.Point)\n</code></pre> <p>Note that the overwrite functions does not change the caller object (i.e. <code>l0</code> in the above example). This design allows the base layer <code>l0</code> to be reused over and over again. Here is a more complex example.</p> <pre><code>mesh = lagrange.io.load_mesh(\"shape.obj\")\nposition_attr_name = mesh.attr_name_vertex_to_position\n\nbase = (\n    hkw.layer()\n    .data(mesh)\n    .mark(hkw.mark.Point)\n    .channel(size=0.1)\n    .transform(\n        hkw.transform.Filter(\n            data=position_attr_name, condition=lambda p: p[0] &gt; 0\n        )\n    )\n)\n</code></pre> <p>This visualization shows all vertices of the input mesh with positive X coordinate as spheres with radius 0.1. Note that, in addition to filename, <code>.data</code> method can also take an actual Lagrange <code>SurfaceMesh</code> object.</p> <p>Lastly, it is also possible to directly specify the components as arguments to <code>hkw.layer</code> method. <pre><code>base = hkw.layer(\"shape.obj\", mark=hkw.mark.Point)\n</code></pre></p>"},{"location":"guide/layer/#layer-composition","title":"Layer composition","text":"<p>In the following example, we will demonstrate the idea of layer composition.</p> <pre><code>base = hkw.layer(\"shape.obj\")\n\nsurface_view = base.mark(hkw.mark.Surface)\npoint_view = base.mark(hkw.mark.Point)\nedge_view = base.mark(hkw.mark.Curve)\n\ncomposite_view = surface_view + point_view + edge_view\n</code></pre> <p>Here, <code>surface_view</code> is a visualization of the surface geometry, while <code>point_view</code> and <code>edge_view</code> are the visualizations of vertices and edges of the geometry. The addition operations combines all three views together to form a composite view that visualizes all three elements. TODO: Show an example.</p>"},{"location":"guide/mark/","title":"Mark","text":"<p>Mark defines the type of geometry a visualization should use. Currently mark can be either <code>hkw.mark.Surface</code>, <code>hkw.mark.Curve</code> or <code>hkw.mark.Point</code>.</p> <ul> <li>Surface: The surface mark indicates the geometry represents a 3D surface.</li> <li>Curve: The curve mark indicates the geometry represents a set of 3D curves.</li> <li>Point: The point mark indices the geometry represents a set of 3D points.</li> </ul> <p></p> <p>Here is an example of specifying the mark.</p> <pre><code># As arguement to hkw.layer method.\nl = hkw.layer(mark = hkw.mark.Surface)\n\n# Or use .mark overwrite method.\nl = hkw.layer().mark(hkw.mark.Surface)\n\n# Mark can also be specified via string.\nl = hkw.layer().mark(\"Surface\")\n</code></pre>"},{"location":"guide/material/","title":"Material","text":"<p>In 3D data visualization, material is the new color! By assigning a material to the 3D geometry, we can not only achieve more photorealistic visual quality but also encode data in more channels than just RGB. Hakowan leverages Mitsuba's material support to provide a number of material-based visual channels.</p> <p>All materials support the following parameters:</p> Parameter Type Description <code>two_sided</code> <code>bool</code> Wheter the material is two-sided. (default: false) <p>A material can be specified via the <code>Layer.channel()</code> method. <pre><code># Assume `m` is a `Material` object\nl = hkw.layer().channel(material=m)\n</code></pre></p> <p>Hakowan also provides the shortcut method <code>Layer.material()</code> to specify material directly. <pre><code>l = hkw.layer().material(\"Diffuse\", \"orange\", two_sided=True)\nl = hkw.layer().material(\"Principled\", \"ivory\", roughness=0.2, metallic=0.8)\n</code></pre></p>"},{"location":"guide/material/#diffuse-material","title":"Diffuse material","text":"<p><code>Diffuse</code> material provides a matte shading to the shape. It is good for visualizing scalar field data without any interference from specular highlight.</p> Channel Type Description <code>reflectance</code> [TextureLike][hakowan.texture.TextureLike] Base color of the material (default: 0.5) <p>Here is a simple example of creating a <code>Diffuse</code> material.</p> <pre><code>m = hkw.material.Diffuse(\"ivory\")\n</code></pre> <p>Here, we assign a uniform color, \"blue\", to the <code>reflectance</code> channel. To encode actual data, we need to assign a texture to the <code>reflectance</code> channel.</p> <pre><code>m = hkw.material.Diffuse(hkw.texture.ScalarField(data = \"attr_name\"))\n</code></pre> <p>Check the Mitsuba doc for more details.</p>"},{"location":"guide/material/#conductor-material","title":"Conductor material","text":"<p><code>Conductor</code> material gives the geometry a metallic look and feel. It takes a <code>material</code> parameter as input, but it cannot be used to encode any data.</p> Parameter Type Description <code>material</code> <code>str</code> Material type (see supported material types) <p>Here is a snippet to create a <code>Conductor</code> material of type <code>Al</code>.</p> <pre><code>m = hkw.material.Conductor(material=\"Al\")\n</code></pre> <p>Check the Mitsuba doc for more details.</p>"},{"location":"guide/material/#rough-conductor-material","title":"Rough conductor material","text":"<p><code>RoughConductor</code> material gives the geometry a matte metallic look and feel. It takes a <code>material</code> parameter just like <code>Conductor</code>. In addition, it also takes a <code>distribution</code> parameter and a <code>alpha</code> channel.</p> Channel Type Description <code>alpha</code> [Texture][hakowan.texture.Texture] or <code>float</code> Roughness value from 0 (smooth) to 1 (rough) (default: 0.1) Parameter Type Description <code>material</code> <code>str</code> Material type (see supported material types) <code>distribution</code> <code>str</code> Microfacet normal distribution: <code>ggx</code> or <code>beckmann</code> (default) <p>Here is a simple example of using <code>RoughConductor</code>.</p> <pre><code>m = hkw.material.RoughConductor(material = \"Cu\")\n</code></pre> <p>Here is a more complex example where we map an attribute to the alpha channel:</p> <pre><code>m = hkw.material.RoughConductor(\n    material=\"Cu\", alpha=hkw.texture.ScalarField(data=\"attr_name\")\n)\n</code></pre> <p>Note that <code>alpha</code>=0.1 is relatively rough, and <code>alpha</code> from 0.3 to 0.7 is very rough. Beyond 0.7, the result does not look very realistic.</p> <p>Check out the Mitsuba doc for more details.</p>"},{"location":"guide/material/#plastic-material","title":"Plastic material","text":"<p><code>Plastic</code> material provides a smooth plastic look and feel. Hakowan exposes two visual channels in this material:</p> Channel Type Description <code>diffuse_reflectance</code> [TextureLike][hakowan.texture.TextureLike] Base color of the material (default: 0.5) <code>specular_reflectance</code> [Texture][hakowan.texture.Texture] or <code>float</code> Specular reflectance component (default: 1.0) <p>Here is a snippet to create a <code>Plastic</code> material:</p> <pre><code>m = hkw.material.Plastic(\n    diffuse_reflecctance=hkw.texture.ScalarField(data=\"attr_name\"),\n    specular_reflectance=hkw.texture.ScalarField(data=\"attr2_name\")\n)\n</code></pre> <p>Check out the Mitsuba doc for more details.</p>"},{"location":"guide/material/#rough-plastic-material","title":"Rough plastic material","text":"<p>Similar to <code>RoughConductor</code>, the <code>distribution</code> parameter controls the microfacet normal distribution, and its valid values are <code>ggx</code> and <code>beckmann</code> (default). The <code>alpha</code> parameter control the roughness of the material.</p> Channel Type Description <code>diffuse_reflectance</code> [TextureLike][hakowan.texture.TextureLike] Base color of the material (default: 0.5) <code>specular_reflectance</code> [Texture][hakowan.texture.Texture] or <code>float</code> Specular reflectance component (default: 1.0) <p>Addition to the above visual channels, this material also expose the following parameters.</p> Parameter Type Description <code>distribution</code> <code>str</code> Microfacet normal distribution: <code>ggx</code> or <code>beckmann</code> (default) <code>alpha</code> <code>float</code> Roughness value from 0 (smooth) to 1 (rough) (default: 0.1) <p>Here is a snippet to create a <code>RoughPlastic</code> material:</p> <pre><code>m = hkw.material.RoughPlastic(\n    diffuse_reflecctance=hkw.texture.ScalarField(data=\"attr_name\"),\n    specular_reflectance=hkw.texture.ScalarField(data=\"attr2_name\"),\n    alpha=0.1\n)\n</code></pre> <p>Note that <code>alpha</code>=0.1 is relatively rough, and <code>alpha</code> from 0.3 to 0.7 is very rough. Beyond 0.7, the result does not look very realistic.</p> <p>Check out the Mitsuba doc for more details.</p>"},{"location":"guide/material/#principled-material","title":"Principled material","text":"<p><code>Principled</code> material is the most versatile material. It is based on paper \"Physically Based Shading\" and its extension. It can be used to approximate almost all other materials.</p> Channel Type Description <code>color</code> [TextureLike][hakowan.texture.TextureLike] Base color of the material (default: 0.5) <code>roughness</code> [Texture][hakowan.texture.Texture] or <code>float</code> Roughness value from 0 (smooth) to 1 (rough) (default: 0.5) <code>metallic</code> [Texture][hakowan.texture.Texture] or <code>float</code> Metallic value from 0 (not metallic) to 1 (very metallic) (default: 0.0) <p>As a rule of thumb, <code>roughness</code> and <code>metallic</code> are effective at encoding binary categorical data, but not very effective for quantitative data.</p> <p>Here is a snippet to create a <code>Principled</code> material:</p> <pre><code>m = hkw.material.Principled(\n    color=hkw.texture.ScalarField(data=\"attr_name\"),\n    roughness=hkw.texture.ScalarField(data=\"attr_name2\"),\n    metallic=hkw.texture.ScalarField(data=\"attr_name3\"),\n)\n</code></pre> <p>Here is another example where the color, roughness and metallic channels are uniform across the entire shape.</p> <pre><code>m = hkw.material.Principled(color=\"#252525\", roughness=0.2, metallic=0.8)\n</code></pre> <p>Check out the Mitsuba doc for more details.</p>"},{"location":"guide/material/#dielectric-material","title":"Dielectric material","text":"<p><code>Dielectric</code> material provides a smooth glossy look and feel. This material exposes no visual channels and have the following parameters.</p> Parameter Type Description <code>int_ior</code> <code>str</code> or <code>float</code> Interior index of refraction (default: <code>bk7</code>, see supported ior list) <code>ext_ior</code> <code>str</code> or <code>float</code> Exterior index of refraction (default: <code>air</code>, see supported ior list) <code>medium</code> <code>Medium</code> Medium of the enclosed material (default: <code>None</code>) <p>Note that by default, <code>Dielectric</code> material does not expose a color channel. Color is specified indirectly through the <code>medium</code> parameter. Medium describes the material/medium enclosed by the shape. It can provide fancy effects such as sub-surface scattering. However, <code>medium</code> setting requires the <code>volpath</code> integrator.</p> <p>Here is a snippet for creating a <code>Dielectric</code> material.</p> <pre><code>m = hkw.material.Dieletric(int_ior=\"water\")\n</code></pre> <p>Check out the Mitsuba doc for more details.</p>"},{"location":"guide/material/#rough-dielectric-material","title":"Rough dielectric material","text":"<p><code>RoughDielectric</code> material provides a matte glass look and feel. Similar to the <code>RoughConductor</code> material, This material exposes an <code>alpha</code> visual channel.</p> Channel Type Description <code>alpha</code> [Texture][hakowan.texture.Texture] or <code>float</code> Roughness value from 0 (smooth) to 1 (rough) (default: 0.1) <p>Although <code>alpha</code> channel is available to encode data, based on our experiments, its effect is somewhat limited. Here are the parameters of this material.</p> Parameter Type Description <code>int_ior</code> <code>str</code> or <code>float</code> Interior index of refraction (default: <code>bk7</code>, see supported ior list) <code>ext_ior</code> <code>str</code> or <code>float</code> Exterior index of refraction (default: <code>air</code>, see supported ior list) <code>medium</code> <code>Medium</code> Medium of the enclosed material (default: <code>None</code>) <code>distribution</code> <code>str</code> Microfacet normal distribution: <code>ggx</code> or <code>beckmann</code> (default) <p>Here is a snippet for creating a <code>RoughDielectric</code> material.</p> <pre><code>m = hkw.material.RoughDielectric(int_ior=\"water\")\n</code></pre>"},{"location":"guide/material/#thin-dielectric-material","title":"Thin dielectric material","text":"<p><code>ThinDielectric</code> material provides a thin glossy shell look and feel for a given shape. It does not expose any visual channels.</p> Parameter Type Description <code>int_ior</code> <code>str</code> or <code>float</code> Interior index of refraction (default: <code>bk7</code>, see supported ior list) <code>ext_ior</code> <code>str</code> or <code>float</code> Exterior index of refraction (default: <code>air</code>, see supported ior list) <code>medium</code> <code>Medium</code> Medium of the enclosed material (default: <code>None</code>) <p>Here is a snippet for creating a <code>ThinDielectric</code> material.</p> <pre><code>m = hkw.material.ThinDielectric(int_ior=\"water\")\n</code></pre>"},{"location":"guide/material/#hair-material","title":"Hair material","text":"<p><code>Hair</code> material from Mitsuba provides a hair-like look and feel. This material is designed to specifically work with curve mark. It does not provide any channels for encoding data.</p> Parameter Type Description eumelanin <code>float</code> The amount of dark/black/brown pigments (default: 1.3) pheomelanin <code>float</code> The amount of red/yellow pigments (default: 0.2) <p>Here is a snippet for creating a <code>Hair</code> material.</p> <pre><code>m = hkw.material.Hair(eumelanin=0.3, pheomelanin=0.1)\n</code></pre> <p>Check out the Mitsuba doc for more details.</p>"},{"location":"guide/material/#two-sided-material","title":"Two-sided material","text":"<p>Sometimes, the mesh we have may not be correctly oriented. Inverted facets will appear to be black. To avoid such artifact, all material classes support an optional <code>two_sided</code> parameter to enabled two-sided normals.</p> <pre><code>m = hkw.material.Diffuse(\"salmon\", two_sided=True)\n</code></pre>"},{"location":"guide/material/#bump-mapped-material","title":"Bump mapped material","text":"<p>A bump map can be applied to any material by setting the <code>bump_map</code> texture and <code>bump_scale</code> parameter. The former parameters defines the raw bump map texture where the latter defines the multiplicative factor to scale the bump magnitude.</p> <p><pre><code>m = hkw.material.Diffuse(\n    \"salmon\",\n    bump_map=hkw.texture.Image(\"bump_map.png\"),\n    bump_scale=0.5,\n)\n</code></pre> See the Moon example for an application of bump map.</p>"},{"location":"guide/scale/","title":"Scale","text":"<p>A scale specifies an attribute-specific transformation that should be carried out before mapping it to various visual channels. Note that a scale can be associated with one or more Attributes.</p>"},{"location":"guide/scale/#uniform-scale","title":"Uniform scale","text":"<p><code>Uniform</code> scale rescale the attribute uniformly based on the specified factor.</p> <pre><code>s = hkw.scale.Uniform(factor = 2)\n</code></pre>"},{"location":"guide/scale/#log-scale","title":"Log scale","text":"<p>It is quite common that we want to visualize the log of the data. The <code>Log</code> scale provides this capability.</p> <pre><code>s = hkw.scale.Log(base = 2)\n</code></pre> <p>In this example, we have created a log scale with base 2.</p>"},{"location":"guide/scale/#clip-scale","title":"Clip scale","text":"<p><code>Clip</code> scale truncates the data with the specified domain. Data values below the domain minimum will be set to the domain minimum, and vice versa for the maximum.</p> <pre><code>s = hkw.scale.Clip(domain=[0, 1])\n</code></pre>"},{"location":"guide/scale/#normalize-scale","title":"Normalize scale","text":"<p><code>Normalize</code> scale rescales the attribute such that the specified domain maps to the specified range. For example,</p> <pre><code>s = hkw.scale.Normalize(range_min=0, range_max=1, domain_min=-10, domain_max=10)\n</code></pre> <p>The scale <code>s</code> will rescale a attribute such that the data within [-10, 10] is now within [0, 1]. If the domain is not specified, the maximum and minimum value of the attribute will be used as the domain.</p> <pre><code>s = hkw.scale.Normalize(range_min=np.zeros(3), range_max=np.ones(3))\n</code></pre> <p>In this example, we are rescaling a vector attribute so that it fits within the box from [0, 0, 0] to [1, 1, 1].</p>"},{"location":"guide/scale/#affine-scale","title":"Affine scale","text":"<p><code>Affine</code> scale applies a affine transformation to a vector-valued attribute.</p> <pre><code>s = hkw.scale.Affine(matrix = np.eye(3) * 2)\n</code></pre>"},{"location":"guide/scale/#offset-scale","title":"Offset scale","text":"<p><code>Offset</code> scale offsets the current attribute by another attribute. It is useful for showing deformed data where the rest position and displacement field are stored in separate attributes.</p> <pre><code>s = hkw.scale.Offset(offset=hkw.attribute(\"displacement\"))\n</code></pre>"},{"location":"guide/scale/#custom-scale","title":"Custom scale","text":"<p><code>Custom</code> scale allows one to use arbitrary scaling function. The function should take a single data value (either a scalar or a vector) as input and output the scaled data value. For example, one can reproduce the effect of uniform scaling by 2 using the following custom scale.</p> <pre><code>s = hkw.scale.Custom(function = lambda x : x * 2)\n</code></pre>"},{"location":"guide/scale/#combining-multiple-scales","title":"Combining multiple scales","text":"<p>It is often necessary to apply multiple scales on an attribute. Hakowan provides an easy way of combining scales together.</p> <pre><code>s1 = hkw.scale.Log(base = 2)\ns2 = hkw.scale.Uniform(factor = 2)\n\n# Chain s1 and s2 together. s1 will be applied before s2.\ns = s1 * s2\n</code></pre>"},{"location":"guide/texture/","title":"Texture","text":"<p>In 3D data visualization, texture defines the mapping from a 3D element to colors or values.</p>"},{"location":"guide/texture/#uniform-texture","title":"Uniform texture","text":"<p><code>Uniform</code> texture maps all 3D elements to the same value.</p> <pre><code>t = hkw.texture.Uniform(color=\"ivory\")\n</code></pre>"},{"location":"guide/texture/#image-texture","title":"Image texture","text":"<p><code>Image</code> texture maps a 3D element to color based on the UV coordinates and an image texture.</p> <pre><code>t = hkw.texture.Image(uv=\"uv_attr_name\", filename=\"texture.png\")\n</code></pre>"},{"location":"guide/texture/#scalar-field-texture","title":"Scalar field texture","text":"<p>One of the most common use case of texture is to map a scalar field to a color field.</p> Field Type Meaning data AttributeLike The attribute defining the scalar field colormap str The colormap to use domain tuple The domain of the attribute range tuple The range of colormap categories bool Whether the data represents categories (i.e. discrete values) <pre><code>t = hkw.texture.ScalarField(data=\"attr_name\")\n</code></pre> <p>See the Heat Method and the Components examples for application of the scalar field texture.</p>"},{"location":"guide/texture/#checkerboard-texture","title":"Checkerboard texture","text":"<p><code>CheckerBoard</code> texture maps 3D elements to one of two possible sub-textures based on a checkerboard pattern.</p> <pre><code>t = hkw.texture.CheckBoard(\n    uv=\"uv_attr_name\",\n    texture1=hkw.texture.Uniform(color=0.2),\n    texture2=hkw.texture.Uniform(color=0.8),\n)\n</code></pre>"},{"location":"guide/texture/#isocontour-texture","title":"Isocontour texture","text":"<p><code>Isocontour</code> texture maps 3D elements to one of two possible sub-textures based on the iso-contour of a given scalar field.</p> <pre><code>t = hkw.texture.Isocontour(\n    data=\"attr_name\",\n    ratio=0.2,\n    texture1=hkw.texture.Uniform(color=0.2),\n    texture2=hkw.texture.Uniform(color=0.8),\n)\n</code></pre> <p>See the Heat Method example for an application of the isocontour texture.</p>"},{"location":"guide/transform/","title":"Transform","text":"<p>Transform is applied to the entire data frame as a pre-processing step. It is useful to modify the geometry and/or computing new attributes from existing attributes.</p>"},{"location":"guide/transform/#filter-transform","title":"Filter transform","text":"<p>Filter transform extracts a subset of the 3D elements based on a user provided condition.</p> <pre><code>tr = hkw.transform.Filter(data=\"attr_name\", condition=lambda value: value &gt; 0)\n</code></pre> <p>Note that if <code>data</code> parameter is <code>None</code>, the mesh vertex position attribute will be used by default. See the Smoothed Particle Hydrodynamics example for an actual usage of the filter transform.</p>"},{"location":"guide/transform/#uvmesh-transform","title":"UVMesh transform","text":"<p>UVMesh transform extract the corresponding UV mesh from a given 3D mesh.</p> <pre><code>tr = hkw.transform.UVMesh(uv=\"attr_name\")\n</code></pre>"},{"location":"guide/transform/#affine-transform","title":"Affine transform","text":"<p>Affine transform applies an affine transformation to the given 3D mesh.</p> <pre><code>tr = hkw.transform.Affine(matrix=np.eye(4))\n</code></pre> <p>Because affine transform is a very common operation, Hakowan provide the following shortcuts:</p> <pre><code># Assume `v` is a offset vector.\nl = hkw.layer().translate(v)\n\n# Assume `s` is a scaling factor.\nl = hkw.layer().scale(s)\n\n# Assume `axis` is a vector representing rotational axis,\n# and `theta` is the rotation angle in radian.\nl = hkw.layer().rotate(v, theta)\n</code></pre>"},{"location":"guide/transform/#compute-transform","title":"Compute transform","text":"<p>Compute transform is designed to compute a set of commonly used attributes from the data frame. Currently, the following attributes can be computed:</p> <ul> <li>X|Y|Z coordinates</li> <li>Normal</li> <li>Component</li> </ul> <pre><code># Add per-facet component id attribute named \"comp\"\ntr = hkw.transform.Compute(component=\"comp\")\n</code></pre> <p>See the Penny example for an actual usage of the compute transform.</p>"},{"location":"guide/transform/#explode-transform","title":"Explode transform","text":"<p>Explode transform breaks a mesh into pieces based on the specified <code>pieces</code> attribute. A piece is defined as a set of facets that has the same value of the <code>pieces</code> attribute. Each piece will be moved away from the input bounding box center by an amount scaled by the <code>magnitude</code> parameter.</p> <pre><code>tr = hkw.transform.Explode(pieces=\"comp_id\", magnitude=2)\n</code></pre> <p>Please see the Powell-Sabin example for an actual use case of the explode transform.</p>"},{"location":"guide/transform/#norm-transform","title":"Norm transform","text":"<p>Norm transform computes the row-wise norm of a given vector attribute.</p> <pre><code># Compute speed from a velocity vector field.\ntr = hkw.transform.Norm(data=\"velocity\", norm_attr_name=\"speed\")\n</code></pre> <p>See the Smoothed Particle Hydrodynamics example for an example usage of the norm transform.</p>"},{"location":"guide/transform/#combining-multiple-transforms","title":"Combining multiple transforms","text":"<p>Multiple transforms can be chained together using <code>*</code> operator.</p> <pre><code># Add per-facet component id attribute named \"comp\"\ncompute_tr = hkw.transform.Compute(component=\"comp\")\n\n# Filter transform to select the first component.\nfilter_tr = hkw.transform.Filter(data=\"comp\", condition=lambda id: id==0)\n\n# Transforms are carried out from left to right.\ntr = component * filter_tr\n</code></pre> <p>When specifying transformation via <code>Layer.transform()</code> methods, the transforms are applied in the order of the specification.</p> <pre><code># Transform `tr1` is applied before `tr2`.\nhkw.layer().transform(tr1).transform(tr2)\n</code></pre>"}]}